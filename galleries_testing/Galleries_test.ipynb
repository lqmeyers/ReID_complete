{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmeyers/anaconda3/envs/mlenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-13 03:31:26.910323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-13 03:31:27.894438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pytorch_models import build_model\n",
    "from pytorch_data import *\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and time when this experiment was started: 23-10-13 03:31\n",
      "Date and time when this experiment was started: 23-10-13 03:31\n",
      "Data Settings:\n",
      "{'dataset': 'summer_2023_color_detect', 'split_type': 'closed', 'fname_col': 'filename', 'label_col': 'color_num', 'cropped': False, 'crop_top': None, 'crop_left': None, 'crop_height': None, 'crop_width': None, 'input_size': [250, 250], 'batch_size': 64, 'aug_p': 0.3, 'datafiles': {'train': '/home/lmeyers/ReID_complete/summer_2023_reid_train_closed.csv', 'valid': '/home/lmeyers/ReID_complete/summer_2023_reid_valid_closed.csv', 'test': '/home/lmeyers/ReID_complete/summer_2023_reid_test_closed.csv', 'reference': '/home/lmeyers/ReID_complete/summer_2023_reid_train_closed.csv', 'query': '/home/lmeyers/ReID_complete/summer_2023_reid_test_closed.csv', 'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv'}, 'n_distractors': 9, 'image_id_col': 'image_id', 'gallery_id': 'gallery_id', 'iteration_id': 'iteration_id'}\n",
      "Train Settings:\n",
      "{'learning_rate': 0.001, 'num_epochs': 250, 'margin': 0.2, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_project_name': 'Summer_data_reid'}\n",
      "Model Settings:\n",
      "{'model_class': 'resnet50_conv3', 'num_labels': 64, 'latent_dim': 128, 'model_path': './summer_color_code_reid.pth'}\n"
     ]
    }
   ],
   "source": [
    "#load config file params:\n",
    "config_file = '/home/lmeyers/ReID_complete/summer_data_closed_reid_color_code.yml'\n",
    "verbose = True\n",
    "\n",
    "try:\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    model_config = config['model_settings'] # settings for model building\n",
    "    train_config = config['train_settings'] # settings for model training\n",
    "    data_config = config['data_settings'] # settings for data loading\n",
    "    eval_config = config['eval_settings'] # settings for evaluation\n",
    "    torch_seed = config['torch_seed']\n",
    "    verbose = config['verbose']\n",
    "except Exception as e:\n",
    "    print('ERROR - unable to open experiment config file. Terminating.')\n",
    "    print('Exception msg:',e)\n",
    "if verbose:\n",
    "    # ADD PRINT OF DATE AND TIME\n",
    "    now = datetime.now() # current date and time\n",
    "    dt = now.strftime(\"%y-%m-%d %H:%M\")\n",
    "    print(f'Date and time when this experiment was started: {dt}')\n",
    "    print(f'Date and time when this experiment was started: {dt}')\n",
    "    print(\"Data Settings:\")\n",
    "    print(data_config)\n",
    "    print(\"Train Settings:\")\n",
    "    print(train_config)\n",
    "    print(\"Model Settings:\")\n",
    "    print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_config['datafiles']['gallery'] = '/home/lmeyers/ReID_complete/galleries_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# FUNCTION TO PERFORM CMC GALLERY EVALUATION\n",
    "#\n",
    "# INPUTS\n",
    "# 1) model: a Pytorch model\n",
    "# 2) model_type: string, specifies model type ('SCL', 'UCL', 'MTL')\n",
    "# 3) data_config: dictionary, contains necessary parameters to load images, including 'gallery_fname', 'fname_col', 'gallery_id',\n",
    "#                             'iteration_id', 'image_id_col' and 'n_distractors'\n",
    "# 4) verbose: bool, whether print out comments\n",
    "#\n",
    "# OUTPUTS\n",
    "# 1) ranks: float list, cmc scores from top-1 to top-k\n",
    "#\n",
    "def evaluate_cmc(model_config,eval_config, data_config, verbose=False):\n",
    "\n",
    "    # load model\n",
    "    model = build_model(model_config)\n",
    "    model = torch.load(model_config['model_path'])\n",
    "    model.eval()\n",
    "\n",
    "    if verbose:\n",
    "        print('Getting gallery images')\n",
    "    df = pd.read_csv(data_config['datafiles']['gallery'])\n",
    "    # get the first n_distractors plus anchor and positive (data frame can have more distractors)\n",
    "    df = df[df[data_config['image_id_col']] < data_config['n_distractors'] + 2]\n",
    "    # get images\n",
    "    dataloader = get_galleries(data_config)\n",
    "    # get embeddings for images\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "                images = data['image']\n",
    "                outputs = model(images.to(device))\n",
    "                predictions.append(outputs.detach().cpu().numpy())\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    if verbose:\n",
    "        print('Finished embedding images')\n",
    "\n",
    "    query_gallery_size = df[data_config['image_id_col']].max() + 1\n",
    "    n_distractors = query_gallery_size - 2\n",
    "    query_gallery_size, n_distractors\n",
    "\n",
    "    # calculate total num of galleries across all iterations\n",
    "    galleries_per_iteraration = len(df[data_config['gallery_id']].unique())\n",
    "    iterations = df[data_config['iteration_id']].max() + 1\n",
    "    total_galleries =  galleries_per_iteraration * iterations\n",
    "    galleries_per_iteraration, iterations, total_galleries\n",
    "\n",
    "    # get queries embedding (i % query_gallery_size == 0)\n",
    "    queries_emb = predictions[::query_gallery_size]\n",
    "    print(queries_emb.size)\n",
    "    # get the gallery embeddings, i.e. everything other than the query embeddings\n",
    "    pred_idx = np.arange(0, len(predictions))\n",
    "    print(pred_idx.shape)\n",
    "    galleries_emb = predictions[np.mod(pred_idx, query_gallery_size) != 0]\n",
    "    print(galleries_emb.shape)\n",
    "\n",
    "\n",
    "    # for each gallery, one query of shape 128\n",
    "    queries_emb = queries_emb.reshape(total_galleries, 1, -1)\n",
    "    # for each gallery, n_distractors + P images of shape n_embedding\n",
    "    galleries_emb = galleries_emb.reshape(total_galleries, n_distractors + 1, -1 )\n",
    "    galleries_emb = galleries_emb.transpose((0, 2, 1))\n",
    "\n",
    "\n",
    "    # Calculate distance\n",
    "    cos_dist = np.dot(queries_emb, galleries_emb.T)\n",
    "    euclid_dist = -(cos_dist - 1)\n",
    "\n",
    "    # Calculate Rank\n",
    "    r = np.argmin(np.argsort(euclid_dist), axis=2)\n",
    "    r = np.squeeze(r)\n",
    "    ranks = np.zeros(n_distractors)\n",
    "    for i in range(n_distractors):\n",
    "        ranks[i] = np.mean(r < (i + 1))\n",
    "\n",
    "    return ranks\n",
    "###################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting gallery images\n",
      "Finished embedding images\n",
      "1280000\n",
      "(110000,)\n",
      "(100000, 128)\n",
      "[0.10004968 0.20016592 0.30025013 0.400309   0.50033644 0.60027885\n",
      " 0.70019559 0.80011335 0.90010365]\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_cmc(model_config,eval_config,data_config,verbose=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
