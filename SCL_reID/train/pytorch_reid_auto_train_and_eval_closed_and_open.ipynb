{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df272772",
   "metadata": {},
   "source": [
    "# A Notebook to iterate through a set of training CSV's and train a SCL ReID model, evaluate model, and save results to a line in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7158d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Necessary Imports\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2caf0d4",
   "metadata": {},
   "source": [
    "## Correct filepaths in csvs (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7c985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = '/home/gsantiago/all_data_csvs/closed*'\n",
    "# # closed_set_directory = '/home/gsantiago/summer_bee_data/closed_test_'\n",
    "# closed_test = \"/home/gsantiago/summer_bee_data/closed_test_\"\n",
    "file_to_replace = \"/home/gsantiago/summer_bee_data/summer_bee_data/\"\n",
    "file_destination = \"/home/gsantiago/move_andrea_to_split/summer_bee_data/\"\n",
    "\n",
    "for path in glob(directory):\n",
    "    print(path)\n",
    "    csv_directory = path+'/*'\n",
    "\n",
    "    for csv in glob(csv_directory):\n",
    "        #print(csv)\n",
    "        csv_frame = pd.read_csv(csv)\n",
    "        #print(csv_frame.head())\n",
    "        csv_frame['filepath']=csv_frame['filepath'].apply(lambda x: x.replace(file_to_replace,file_destination))\n",
    "        print(csv_frame.head())\n",
    "        csv_frame.to_csv(csv, index=False)\n",
    "open_sets_directory = '/home/gsantiago/all_data_csvs/open_sets/*'\n",
    "for path in glob(open_sets_directory):\n",
    "\n",
    "    #print(path)\n",
    "    csv_directory = path+'/*'\n",
    "    \n",
    "    for csv in glob(csv_directory):\n",
    "        print(csv)\n",
    "        csv_frame = pd.read_csv(csv)\n",
    "        print(csv_frame.head())\n",
    "        csv_frame['filepath']=csv_frame['filepath'].apply(lambda x: x.replace(file_to_replace,file_destination))\n",
    "        csv_frame.to_csv(csv, index=False)\n",
    "\n",
    "# for data_setting in config['data_settings']['datafiles'].values():\n",
    "    \n",
    "#     if(data_setting is None):\n",
    "#         continue\n",
    "#     csv_frame = pd.read_csv(data_setting)\n",
    "    \n",
    "#     print(csv_frame)\n",
    "#     csv_frame['filepath']=csv_frame['filepath'].apply(lambda x: x.replace('/home/gsantiago/move_andrea_to_split/summer_bee_data','/home/gsantiago/move_andrea_to_split/summer_bee_data/') )\n",
    "    \n",
    "#     csv_frame.to_csv(data_setting, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569dcdfd",
   "metadata": {},
   "source": [
    "# Iterate through training files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd184456",
   "metadata": {},
   "source": [
    "### Specify Training and Evaluation Files \n",
    "This method iterates through a folder of training csvs and evaluates them on the same test (query) file using the same reference file each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34eba983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir containing training csvs to start working with \n",
    "dir = '/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2'\n",
    "\n",
    "test_file = '/home/gsantiago/summer_bee_data/closed_test_batch1/summer_bee_dataset_closed_test_bee_sample_num_None.csv'\n",
    "#test on all of batch 2 (open set) gonna also test on all of batch 1 \n",
    "\n",
    "valid_file = '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'\n",
    "# run valid on smaller subset of test_set to speed training \n",
    "\n",
    "#reference knn on smaller subset of batch 1\n",
    "reference_file = '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'\n",
    "\n",
    "\n",
    "results_file = '../yml_and_csv_files/Few_shot_expirament_results_tracking.csv'\n",
    "\n",
    "file_paths = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f8a08",
   "metadata": {},
   "source": [
    "#### Get list of training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fe7c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2/summer_bee_dataset_closed_train_bee_4_ids_batch2_sample_num_4.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2/summer_bee_dataset_closed_train_bee_4_ids_batch2_sample_num_8.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2/summer_bee_dataset_closed_train_bee_4_ids_batch2_sample_num_16.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2/summer_bee_dataset_closed_train_bee_4_ids_batch2_sample_num_20.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2/summer_bee_dataset_closed_train_bee_4_ids_batch2_sample_num_max.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2/summer_bee_dataset_closed_train_bee_4_ids_batch2_sample_num_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Get file list \n",
    "for root, dirs, files in os.walk(dir):\n",
    "    files = files\n",
    "for f in files:\n",
    "    print(root+r'/'+f)\n",
    "    train_file = root+r'/'+f\n",
    "    file_paths.append(train_file)\n",
    "#     continue\n",
    "\n",
    "#files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF setting two folders to train at once: \n",
    "\n",
    "# dir2 = '/home/gsantiago/summer_bee_data/closed_sets_8_ids_monocolor_batch2'\n",
    "# files2 = []\n",
    "# for root2, dirs2, files2 in os.walk(dir2):\n",
    "#     files2 = files2\n",
    "# for f2 in files2:\n",
    "#     #print(root+r'/'+f2)\n",
    "#     train_file2 = root2+r'/'+f2\n",
    "#     file_paths.append(train_file2)\n",
    "# #     continue\n",
    "\n",
    "# print(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375cea6",
   "metadata": {},
   "source": [
    "## Loop through files, train and eval model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c923c",
   "metadata": {},
   "source": [
    "Code may need to be modified for differnt training sets such as\n",
    "* run_str parsing to include important variables such as num_ids\n",
    "* the path to your template yml config file\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745415dc-6f87-4521-ae3a-f1492eb39356",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64.csv','/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_64.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fe0480",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels  64\n",
      "2024-09-12 12:34:08.135839: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-12 12:34:09.040529: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/contrastive_learning_new_training/64_ids_batch1_sample_num_64/wandb/run-20240912_123412-0glrglqb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-tree-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/vit_baselines_test64_ids_batch1_sample_num_64\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/vit_baselines_test64_ids_batch1_sample_num_64/runs/0glrglqb\u001b[0m\n",
      "Date and time when this experiment was started: 24-09-12 12:34\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_max.csv', 'reference': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_02.csv', 'test': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_max.csv', 'train': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64.csv', 'valid': ''}, 'dataset': 'summer_2023', 'fname_col': 'new_filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'ID', 'n_distractors': 9, 'percent_valid': 0.2, 'sample_reference': True, 'sample_valid': True, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'early_stop_consecutive_epochs': 1000, 'early_stopping': True, 'gpu': 1, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/contrastive_learning_new_training/64_ids_batch1_sample_num_64/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'vit_baselines_test64_ids_batch1_sample_num_64', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'vit_reid', 'model_path': '/home/lmeyers/contrastive_learning_new_training/64_ids_batch1_sample_num_64/64_ids_batch1_sample_num_64.pth', 'num_labels': '64'}\n",
      "Using GPU 1\n",
      "Creating train and valid dataloaders...\n",
      "Using 778 samples for validation set\n",
      "3113 total training samples\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Downloading config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 502/502 [00:00<00:00, 35.3kB/s]\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 346M/346M [00:08<00:00, 40.4MB/s]\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Getting ViT feature extractor...\n",
      "Downloading (‚Ä¶)rocessor_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [00:00<00:00, 58.6kB/s]\n",
      "/home/lmeyers/anaconda3/envs/mlenv/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "[1,    49] train_loss: 0.6045 | val_loss: 0.1200\n",
      "[2,    49] train_loss: 0.6280 | val_loss: 0.1240\n",
      "[3,    49] train_loss: 0.6084 | val_loss: 0.1202\n",
      "[4,    49] train_loss: 0.5960 | val_loss: 0.1195\n",
      "[5,    49] train_loss: 0.5987 | val_loss: 0.1198\n",
      "[6,    49] train_loss: 0.6064 | val_loss: 0.1271\n",
      "[7,    49] train_loss: 0.6026 | val_loss: 0.1244\n",
      "[8,    49] train_loss: 0.6091 | val_loss: 0.1303\n",
      "[9,    49] train_loss: 0.5988 | val_loss: 0.1230\n",
      "[10,    49] train_loss: 0.6008 | val_loss: 0.1246\n",
      "[11,    49] train_loss: 0.6143 | val_loss: 0.1182\n",
      "[12,    49] train_loss: 0.5970 | val_loss: 0.1185\n",
      "[13,    49] train_loss: 0.6079 | val_loss: 0.1278\n",
      "[14,    49] train_loss: 0.6222 | val_loss: 0.1180\n",
      "[15,    49] train_loss: 0.5941 | val_loss: 0.1239\n",
      "[16,    49] train_loss: 0.6122 | val_loss: 0.1190\n",
      "[17,    49] train_loss: 0.6043 | val_loss: 0.1211\n",
      "[18,    49] train_loss: 0.5894 | val_loss: 0.1254\n",
      "[19,    49] train_loss: 0.5922 | val_loss: 0.1208\n",
      "[20,    49] train_loss: 0.5958 | val_loss: 0.1274\n",
      "[21,    49] train_loss: 0.6063 | val_loss: 0.1203\n",
      "[22,    49] train_loss: 0.5843 | val_loss: 0.1191\n",
      "[23,    49] train_loss: 0.5898 | val_loss: 0.1251\n",
      "[24,    49] train_loss: 0.6102 | val_loss: 0.1230\n",
      "[25,    49] train_loss: 0.5926 | val_loss: 0.1232\n",
      "[26,    49] train_loss: 0.6052 | val_loss: 0.1221\n",
      "[27,    49] train_loss: 0.6014 | val_loss: 0.1285\n",
      "[28,    49] train_loss: 0.6038 | val_loss: 0.1223\n",
      "[29,    49] train_loss: 0.5931 | val_loss: 0.1214\n",
      "[30,    49] train_loss: 0.5999 | val_loss: 0.1302\n",
      "[31,    49] train_loss: 0.6014 | val_loss: 0.1280\n",
      "[32,    49] train_loss: 0.6132 | val_loss: 0.1239\n",
      "[33,    49] train_loss: 0.6046 | val_loss: 0.1186\n",
      "[34,    49] train_loss: 0.5937 | val_loss: 0.1215\n",
      "[35,    49] train_loss: 0.5869 | val_loss: 0.1164\n",
      "[36,    49] train_loss: 0.5894 | val_loss: 0.1217\n",
      "[37,    49] train_loss: 0.5909 | val_loss: 0.1157\n",
      "[38,    49] train_loss: 0.5726 | val_loss: 0.1202\n",
      "[39,    49] train_loss: 0.5957 | val_loss: 0.1199\n",
      "[40,    49] train_loss: 0.5623 | val_loss: 0.1160\n",
      "[41,    49] train_loss: 0.6011 | val_loss: 0.1212\n",
      "[42,    49] train_loss: 0.5989 | val_loss: 0.1246\n",
      "[43,    49] train_loss: 0.5885 | val_loss: 0.1219\n",
      "[44,    49] train_loss: 0.5887 | val_loss: 0.1169\n",
      "[45,    49] train_loss: 0.5766 | val_loss: 0.1178\n",
      "[46,    49] train_loss: 0.5874 | val_loss: 0.1184\n",
      "[47,    49] train_loss: 0.5569 | val_loss: 0.1117\n",
      "[48,    49] train_loss: 0.5394 | val_loss: 0.1095\n",
      "[49,    49] train_loss: 0.5336 | val_loss: 0.1075\n",
      "[50,    49] train_loss: 0.5356 | val_loss: 0.1086\n",
      "Saving checkpoint 50\n",
      "[51,    49] train_loss: 0.5350 | val_loss: 0.1088\n",
      "[52,    49] train_loss: 0.5308 | val_loss: 0.1082\n",
      "[53,    49] train_loss: 0.5385 | val_loss: 0.1117\n",
      "[54,    49] train_loss: 0.5348 | val_loss: 0.1092\n",
      "[55,    49] train_loss: 0.5362 | val_loss: 0.1119\n",
      "[56,    49] train_loss: 0.5360 | val_loss: 0.1099\n",
      "[57,    49] train_loss: 0.5325 | val_loss: 0.1085\n",
      "[58,    49] train_loss: 0.5332 | val_loss: 0.1087\n",
      "[59,    49] train_loss: 0.5328 | val_loss: 0.1078\n",
      "[60,    49] train_loss: 0.5329 | val_loss: 0.1086\n",
      "[61,    49] train_loss: 0.5348 | val_loss: 0.1090\n",
      "[62,    49] train_loss: 0.5279 | val_loss: 0.1074\n",
      "[63,    49] train_loss: 0.5248 | val_loss: 0.1069\n",
      "[64,    49] train_loss: 0.5286 | val_loss: 0.1082\n",
      "[65,    49] train_loss: 0.5251 | val_loss: 0.1081\n",
      "[66,    49] train_loss: 0.5283 | val_loss: 0.1096\n",
      "[67,    49] train_loss: 0.5283 | val_loss: 0.1066\n",
      "[107,    49] train_loss: 0.5150 | val_loss: 0.1063\n",
      "[108,    49] train_loss: 0.5167 | val_loss: 0.1052\n",
      "[109,    49] train_loss: 0.5100 | val_loss: 0.1040\n",
      "[110,    49] train_loss: 0.5116 | val_loss: 0.1052\n",
      "[111,    49] train_loss: 0.5126 | val_loss: 0.1073\n",
      "[112,    49] train_loss: 0.5078 | val_loss: 0.1045\n",
      "[113,    49] train_loss: 0.5158 | val_loss: 0.1051\n",
      "[114,    49] train_loss: 0.5164 | val_loss: 0.1052\n",
      "[115,    49] train_loss: 0.5136 | val_loss: 0.1068\n",
      "[116,    49] train_loss: 0.5131 | val_loss: 0.1033\n",
      "[117,    49] train_loss: 0.5126 | val_loss: 0.1053\n",
      "[118,    49] train_loss: 0.5181 | val_loss: 0.1046\n",
      "[119,    49] train_loss: 0.5161 | val_loss: 0.1053\n",
      "[766,    49] train_loss: 0.5010 | val_loss: 0.1020\n",
      "[767,    49] train_loss: 0.5005 | val_loss: 0.1028\n",
      "[768,    49] train_loss: 0.5072 | val_loss: 0.1028\n",
      "[769,    49] train_loss: 0.5051 | val_loss: 0.1022\n",
      "[770,    49] train_loss: 0.5005 | val_loss: 0.1015\n",
      "[771,    49] train_loss: 0.5011 | val_loss: 0.1021\n",
      "[772,    49] train_loss: 0.5045 | val_loss: 0.1030\n",
      "[773,    49] train_loss: 0.5037 | val_loss: 0.1022\n",
      "[774,    49] train_loss: 0.5047 | val_loss: 0.1020\n",
      "[775,    49] train_loss: 0.5053 | val_loss: 0.1017\n",
      "[776,    49] train_loss: 0.5029 | val_loss: 0.1019\n",
      "[777,    49] train_loss: 0.4989 | val_loss: 0.1042\n",
      "[778,    49] train_loss: 0.5046 | val_loss: 0.1031\n",
      "[779,    49] train_loss: 0.5039 | val_loss: 0.1016\n",
      "[780,    49] train_loss: 0.5034 | val_loss: 0.1034\n",
      "[781,    49] train_loss: 0.4986 | val_loss: 0.1028\n",
      "[782,    49] train_loss: 0.5065 | val_loss: 0.1021\n",
      "[783,    49] train_loss: 0.4995 | val_loss: 0.1018\n",
      "[784,    49] train_loss: 0.4991 | val_loss: 0.1022\n",
      "[785,    49] train_loss: 0.5009 | val_loss: 0.1016\n",
      "[786,    49] train_loss: 0.5020 | val_loss: 0.1033\n",
      "[787,    49] train_loss: 0.5031 | val_loss: 0.1026\n",
      "[788,    49] train_loss: 0.5016 | val_loss: 0.1032\n",
      "[789,    49] train_loss: 0.5030 | val_loss: 0.1011\n",
      "[790,    49] train_loss: 0.5011 | val_loss: 0.1032\n",
      "[791,    49] train_loss: 0.5014 | val_loss: 0.1023\n",
      "[792,    49] train_loss: 0.5022 | val_loss: 0.1018\n",
      "[793,    49] train_loss: 0.5000 | val_loss: 0.1012\n",
      "[794,    49] train_loss: 0.5002 | val_loss: 0.1022\n",
      "[795,    49] train_loss: 0.4981 | val_loss: 0.1022\n",
      "[796,    49] train_loss: 0.5015 | val_loss: 0.1034\n",
      "[797,    49] train_loss: 0.5023 | val_loss: 0.1031\n",
      "[798,    49] train_loss: 0.4989 | val_loss: 0.1034\n",
      "[799,    49] train_loss: 0.5035 | val_loss: 0.1007\n",
      "[800,    49] train_loss: 0.5035 | val_loss: 0.1010\n",
      "Saving checkpoint 800\n",
      "[801,    49] train_loss: 0.5020 | val_loss: 0.1023\n",
      "[802,    49] train_loss: 0.4988 | val_loss: 0.1018\n",
      "[803,    49] train_loss: 0.5018 | val_loss: 0.1011\n",
      "[804,    49] train_loss: 0.5064 | val_loss: 0.1017\n",
      "[805,    49] train_loss: 0.4993 | val_loss: 0.1023\n",
      "[806,    49] train_loss: 0.4999 | val_loss: 0.1025\n",
      "[807,    49] train_loss: 0.5007 | val_loss: 0.1020\n",
      "[808,    49] train_loss: 0.5030 | val_loss: 0.1013\n",
      "[809,    49] train_loss: 0.5081 | val_loss: 0.1033\n",
      "[810,    49] train_loss: 0.5030 | val_loss: 0.1028\n",
      "[811,    49] train_loss: 0.4995 | val_loss: 0.1020\n",
      "[812,    49] train_loss: 0.4981 | val_loss: 0.1027\n",
      "[813,    49] train_loss: 0.4994 | val_loss: 0.1014\n",
      "[814,    49] train_loss: 0.5017 | val_loss: 0.1020\n",
      "[815,    49] train_loss: 0.5052 | val_loss: 0.1022\n",
      "[816,    49] train_loss: 0.5024 | val_loss: 0.1034\n",
      "[817,    49] train_loss: 0.5008 | val_loss: 0.1036\n",
      "[818,    49] train_loss: 0.5009 | val_loss: 0.1032\n",
      "[819,    49] train_loss: 0.5031 | val_loss: 0.1038\n",
      "[820,    49] train_loss: 0.4975 | val_loss: 0.1030\n",
      "[821,    49] train_loss: 0.4999 | val_loss: 0.1018\n",
      "[822,    49] train_loss: 0.4987 | val_loss: 0.1013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "[823,    49] train_loss: 0.5022 | val_loss: 0.1025\n",
      "[824,    49] train_loss: 0.5048 | val_loss: 0.1021\n",
      "[825,    49] train_loss: 0.5009 | val_loss: 0.1010\n",
      "[826,    49] train_loss: 0.5028 | val_loss: 0.1010\n",
      "[827,    49] train_loss: 0.5035 | val_loss: 0.1024\n",
      "[828,    49] train_loss: 0.5049 | val_loss: 0.1022\n",
      "[829,    49] train_loss: 0.5005 | val_loss: 0.1029\n",
      "[830,    49] train_loss: 0.5024 | val_loss: 0.1020\n",
      "[831,    49] train_loss: 0.5013 | val_loss: 0.1035\n",
      "[832,    49] train_loss: 0.5004 | val_loss: 0.1019\n",
      "[833,    49] train_loss: 0.5009 | val_loss: 0.1025\n",
      "[834,    49] train_loss: 0.4992 | val_loss: 0.1020\n",
      "[835,    49] train_loss: 0.5029 | val_loss: 0.1017\n",
      "[836,    49] train_loss: 0.5014 | val_loss: 0.1007\n",
      "[837,    49] train_loss: 0.4970 | val_loss: 0.1023\n",
      "[838,    49] train_loss: 0.5025 | val_loss: 0.1024\n",
      "[839,    49] train_loss: 0.4994 | val_loss: 0.1025\n",
      "[840,    49] train_loss: 0.5036 | val_loss: 0.1034\n",
      "[841,    49] train_loss: 0.4992 | val_loss: 0.1019\n",
      "[842,    49] train_loss: 0.5010 | val_loss: 0.1032\n",
      "[843,    49] train_loss: 0.4996 | val_loss: 0.1030\n",
      "[844,    49] train_loss: 0.5018 | val_loss: 0.1025\n",
      "[845,    49] train_loss: 0.4994 | val_loss: 0.1006\n",
      "[846,    49] train_loss: 0.5011 | val_loss: 0.1017\n",
      "[847,    49] train_loss: 0.5073 | val_loss: 0.1049\n",
      "[848,    49] train_loss: 0.5046 | val_loss: 0.1029\n",
      "[849,    49] train_loss: 0.5027 | val_loss: 0.1033\n",
      "[850,    49] train_loss: 0.5009 | val_loss: 0.1043\n",
      "Saving checkpoint 850\n",
      "[851,    49] train_loss: 0.4984 | val_loss: 0.1035\n",
      "[852,    49] train_loss: 0.5026 | val_loss: 0.1016\n",
      "[853,    49] train_loss: 0.5010 | val_loss: 0.1022\n",
      "[854,    49] train_loss: 0.5018 | val_loss: 0.1018\n",
      "[855,    49] train_loss: 0.5021 | val_loss: 0.1022\n",
      "[856,    49] train_loss: 0.5034 | val_loss: 0.1028\n",
      "[857,    49] train_loss: 0.5006 | val_loss: 0.1021\n",
      "[858,    49] train_loss: 0.5002 | val_loss: 0.1014\n",
      "[859,    49] train_loss: 0.5059 | val_loss: 0.1033\n",
      "[860,    49] train_loss: 0.5000 | val_loss: 0.1032\n",
      "[861,    49] train_loss: 0.4984 | val_loss: 0.1027\n",
      "[862,    49] train_loss: 0.5020 | val_loss: 0.1020\n",
      "[863,    49] train_loss: 0.5001 | val_loss: 0.1020\n",
      "[864,    49] train_loss: 0.5040 | val_loss: 0.1025\n",
      "[865,    49] train_loss: 0.4983 | val_loss: 0.1018\n",
      "[866,    49] train_loss: 0.5010 | val_loss: 0.1024\n",
      "[867,    49] train_loss: 0.5020 | val_loss: 0.1016\n",
      "[868,    49] train_loss: 0.4992 | val_loss: 0.1021\n",
      "[869,    49] train_loss: 0.5014 | val_loss: 0.1008\n",
      "[870,    49] train_loss: 0.5026 | val_loss: 0.1032\n",
      "[871,    49] train_loss: 0.5001 | val_loss: 0.1019\n",
      "[872,    49] train_loss: 0.5023 | val_loss: 0.1023\n",
      "[873,    49] train_loss: 0.5008 | val_loss: 0.1015\n",
      "[874,    49] train_loss: 0.4993 | val_loss: 0.1020\n",
      "[875,    49] train_loss: 0.4977 | val_loss: 0.1031\n",
      "[876,    49] train_loss: 0.4978 | val_loss: 0.1020\n",
      "[877,    49] train_loss: 0.4967 | val_loss: 0.1023\n",
      "[878,    49] train_loss: 0.5011 | val_loss: 0.1030\n",
      "[879,    49] train_loss: 0.4964 | val_loss: 0.1035\n",
      "[880,    49] train_loss: 0.4983 | val_loss: 0.1029\n",
      "[881,    49] train_loss: 0.5028 | val_loss: 0.1015\n",
      "[882,    49] train_loss: 0.5038 | val_loss: 0.1016\n",
      "[883,    49] train_loss: 0.4978 | val_loss: 0.1019\n",
      "[884,    49] train_loss: 0.5044 | val_loss: 0.1020\n",
      "[885,    49] train_loss: 0.4974 | val_loss: 0.1041\n",
      "[886,    49] train_loss: 0.5012 | val_loss: 0.1024\n",
      "[887,    49] train_loss: 0.5024 | val_loss: 0.1018\n",
      "[888,    49] train_loss: 0.5017 | val_loss: 0.1030\n",
      "[889,    49] train_loss: 0.4983 | val_loss: 0.1016\n",
      "[890,    49] train_loss: 0.5017 | val_loss: 0.1006\n",
      "[891,    49] train_loss: 0.5031 | val_loss: 0.1027\n",
      "[892,    49] train_loss: 0.5021 | val_loss: 0.1040\n",
      "[893,    49] train_loss: 0.5016 | val_loss: 0.1023\n",
      "[894,    49] train_loss: 0.5029 | val_loss: 0.1014\n",
      "[895,    49] train_loss: 0.5011 | val_loss: 0.1026\n",
      "[896,    49] train_loss: 0.4985 | val_loss: 0.1018\n",
      "[897,    49] train_loss: 0.4988 | val_loss: 0.1020\n",
      "[898,    49] train_loss: 0.5043 | val_loss: 0.1013\n",
      "[899,    49] train_loss: 0.5017 | val_loss: 0.1031\n",
      "[900,    49] train_loss: 0.5006 | val_loss: 0.1029\n",
      "Saving checkpoint 900\n",
      "[901,    49] train_loss: 0.5037 | val_loss: 0.1039\n",
      "[902,    49] train_loss: 0.4985 | val_loss: 0.1036\n",
      "[903,    49] train_loss: 0.5051 | val_loss: 0.1016\n",
      "[904,    49] train_loss: 0.4969 | val_loss: 0.1022\n",
      "[905,    49] train_loss: 0.5032 | val_loss: 0.1018\n",
      "[906,    49] train_loss: 0.4953 | val_loss: 0.1027\n",
      "[907,    49] train_loss: 0.5037 | val_loss: 0.1041\n",
      "[908,    49] train_loss: 0.5023 | val_loss: 0.1010\n",
      "[909,    49] train_loss: 0.5033 | val_loss: 0.1019\n",
      "[910,    49] train_loss: 0.4999 | val_loss: 0.1022\n",
      "[911,    49] train_loss: 0.4977 | val_loss: 0.1027\n",
      "[912,    49] train_loss: 0.5081 | val_loss: 0.1021\n",
      "[913,    49] train_loss: 0.4991 | val_loss: 0.1030\n",
      "[914,    49] train_loss: 0.5000 | val_loss: 0.1023\n",
      "[915,    49] train_loss: 0.4982 | val_loss: 0.1038\n",
      "[916,    49] train_loss: 0.4995 | val_loss: 0.1016\n",
      "[917,    49] train_loss: 0.5004 | val_loss: 0.1022\n",
      "[918,    49] train_loss: 0.5023 | val_loss: 0.1042\n",
      "[919,    49] train_loss: 0.5041 | val_loss: 0.1028\n",
      "[920,    49] train_loss: 0.4995 | val_loss: 0.1016\n",
      "[921,    49] train_loss: 0.4983 | val_loss: 0.1004\n",
      "[922,    49] train_loss: 0.5005 | val_loss: 0.1032\n",
      "[923,    49] train_loss: 0.5025 | val_loss: 0.1035\n",
      "[924,    49] train_loss: 0.5020 | val_loss: 0.1034\n",
      "[925,    49] train_loss: 0.4995 | val_loss: 0.1020\n",
      "[926,    49] train_loss: 0.5018 | val_loss: 0.1017\n",
      "[927,    49] train_loss: 0.5015 | val_loss: 0.1030\n",
      "[928,    49] train_loss: 0.5036 | val_loss: 0.1028\n",
      "[929,    49] train_loss: 0.4988 | val_loss: 0.1029\n",
      "[930,    49] train_loss: 0.4969 | val_loss: 0.1018\n",
      "[931,    49] train_loss: 0.4981 | val_loss: 0.1016\n",
      "[932,    49] train_loss: 0.5003 | val_loss: 0.1004\n",
      "[933,    49] train_loss: 0.5003 | val_loss: 0.1011\n",
      "[934,    49] train_loss: 0.5032 | val_loss: 0.1015\n",
      "[935,    49] train_loss: 0.5009 | val_loss: 0.1019\n",
      "[936,    49] train_loss: 0.4982 | val_loss: 0.1025\n",
      "[937,    49] train_loss: 0.4993 | val_loss: 0.1019\n",
      "[938,    49] train_loss: 0.5043 | val_loss: 0.1029\n",
      "[939,    49] train_loss: 0.4980 | val_loss: 0.1034\n",
      "[940,    49] train_loss: 0.4994 | val_loss: 0.1028\n",
      "[941,    49] train_loss: 0.4985 | val_loss: 0.1029\n",
      "[942,    49] train_loss: 0.5020 | val_loss: 0.1018\n",
      "[943,    49] train_loss: 0.5033 | val_loss: 0.1023\n",
      "[944,    49] train_loss: 0.4986 | val_loss: 0.1025\n",
      "[945,    49] train_loss: 0.5011 | val_loss: 0.1023\n",
      "[946,    49] train_loss: 0.5022 | val_loss: 0.1018\n",
      "[947,    49] train_loss: 0.4993 | val_loss: 0.1018\n",
      "[948,    49] train_loss: 0.5014 | val_loss: 0.1021\n",
      "[949,    49] train_loss: 0.5014 | val_loss: 0.1027\n",
      "[950,    49] train_loss: 0.5016 | val_loss: 0.1018\n",
      "Saving checkpoint 950\n",
      "[951,    49] train_loss: 0.4998 | val_loss: 0.1015\n",
      "[952,    49] train_loss: 0.5017 | val_loss: 0.1025\n",
      "[953,    49] train_loss: 0.4980 | val_loss: 0.1027\n",
      "[954,    49] train_loss: 0.5018 | val_loss: 0.1032\n",
      "[955,    49] train_loss: 0.5014 | val_loss: 0.1028\n",
      "[956,    49] train_loss: 0.4986 | val_loss: 0.1025\n",
      "[957,    49] train_loss: 0.5045 | val_loss: 0.1023\n",
      "[958,    49] train_loss: 0.5002 | val_loss: 0.1032\n",
      "[959,    49] train_loss: 0.4997 | val_loss: 0.1006\n",
      "[960,    49] train_loss: 0.5023 | val_loss: 0.1020\n",
      "[961,    49] train_loss: 0.5008 | val_loss: 0.1029\n",
      "[962,    49] train_loss: 0.5023 | val_loss: 0.1031\n",
      "[963,    49] train_loss: 0.5015 | val_loss: 0.1031\n",
      "[964,    49] train_loss: 0.4990 | val_loss: 0.1008\n",
      "[965,    49] train_loss: 0.5025 | val_loss: 0.1017\n",
      "[966,    49] train_loss: 0.5015 | val_loss: 0.1022\n",
      "[967,    49] train_loss: 0.5016 | val_loss: 0.1013\n",
      "[968,    49] train_loss: 0.4969 | val_loss: 0.1032\n",
      "[969,    49] train_loss: 0.5020 | val_loss: 0.1036\n",
      "[970,    49] train_loss: 0.5006 | val_loss: 0.1035\n",
      "[971,    49] train_loss: 0.5004 | val_loss: 0.1020\n",
      "[972,    49] train_loss: 0.5014 | val_loss: 0.1030\n",
      "[973,    49] train_loss: 0.4980 | val_loss: 0.1038\n",
      "[974,    49] train_loss: 0.5024 | val_loss: 0.1018\n",
      "[975,    49] train_loss: 0.5005 | val_loss: 0.1019\n",
      "[976,    49] train_loss: 0.5005 | val_loss: 0.1024\n",
      "[977,    49] train_loss: 0.5036 | val_loss: 0.1018\n",
      "[978,    49] train_loss: 0.5026 | val_loss: 0.1031\n",
      "[979,    49] train_loss: 0.4982 | val_loss: 0.1043\n",
      "[980,    49] train_loss: 0.5010 | val_loss: 0.1035\n",
      "[981,    49] train_loss: 0.5005 | val_loss: 0.1012\n",
      "[982,    49] train_loss: 0.4978 | val_loss: 0.1033\n",
      "[983,    49] train_loss: 0.5019 | val_loss: 0.1021\n",
      "[984,    49] train_loss: 0.5015 | val_loss: 0.1035\n",
      "[985,    49] train_loss: 0.4992 | val_loss: 0.1026\n",
      "[986,    49] train_loss: 0.5024 | val_loss: 0.1036\n",
      "[987,    49] train_loss: 0.5019 | val_loss: 0.1027\n",
      "[988,    49] train_loss: 0.4998 | val_loss: 0.1017\n",
      "[989,    49] train_loss: 0.5022 | val_loss: 0.1026\n",
      "[990,    49] train_loss: 0.5028 | val_loss: 0.1021\n",
      "[991,    49] train_loss: 0.4999 | val_loss: 0.1019\n",
      "[992,    49] train_loss: 0.5020 | val_loss: 0.1034\n",
      "[993,    49] train_loss: 0.5026 | val_loss: 0.1022\n",
      "[994,    49] train_loss: 0.5036 | val_loss: 0.1023\n",
      "[995,    49] train_loss: 0.4997 | val_loss: 0.1019\n",
      "[996,    49] train_loss: 0.5055 | val_loss: 0.1020\n",
      "[997,    49] train_loss: 0.4994 | val_loss: 0.1005\n",
      "[998,    49] train_loss: 0.5030 | val_loss: 0.1031\n",
      "[999,    49] train_loss: 0.5020 | val_loss: 0.1024\n",
      "[1000,    49] train_loss: 0.5001 | val_loss: 0.1017\n",
      "Saving checkpoint 1000\n",
      "[1001,    49] train_loss: 0.5013 | val_loss: 0.1017\n",
      "[1002,    49] train_loss: 0.5068 | val_loss: 0.1008\n",
      "[1003,    49] train_loss: 0.5008 | val_loss: 0.1008\n",
      "[1004,    49] train_loss: 0.5029 | val_loss: 0.1033\n",
      "[1005,    49] train_loss: 0.4995 | val_loss: 0.1032\n",
      "[1006,    49] train_loss: 0.5029 | val_loss: 0.1035\n",
      "[1007,    49] train_loss: 0.4999 | val_loss: 0.1025\n",
      "[1008,    49] train_loss: 0.5003 | val_loss: 0.1010\n",
      "[1009,    49] train_loss: 0.4993 | val_loss: 0.1023\n",
      "[1010,    49] train_loss: 0.5012 | val_loss: 0.1020\n",
      "[1011,    49] train_loss: 0.5014 | val_loss: 0.1028\n",
      "[1012,    49] train_loss: 0.4979 | val_loss: 0.1021\n",
      "[1013,    49] train_loss: 0.5014 | val_loss: 0.1026\n",
      "[1014,    49] train_loss: 0.4983 | val_loss: 0.1014\n",
      "[1015,    49] train_loss: 0.5016 | val_loss: 0.1019\n",
      "[1016,    49] train_loss: 0.5025 | val_loss: 0.1023\n",
      "[1017,    49] train_loss: 0.4991 | val_loss: 0.1035\n",
      "[1018,    49] train_loss: 0.4999 | val_loss: 0.1032\n",
      "[1019,    49] train_loss: 0.5018 | val_loss: 0.1009\n",
      "[1020,    49] train_loss: 0.4973 | val_loss: 0.1013\n",
      "[1021,    49] train_loss: 0.4986 | val_loss: 0.1029\n",
      "[1022,    49] train_loss: 0.5022 | val_loss: 0.1011\n",
      "[1023,    49] train_loss: 0.5014 | val_loss: 0.1029\n",
      "[1024,    49] train_loss: 0.5001 | val_loss: 0.1023\n",
      "[1025,    49] train_loss: 0.5019 | val_loss: 0.1033\n",
      "[1026,    49] train_loss: 0.5009 | val_loss: 0.1034\n",
      "[1027,    49] train_loss: 0.5022 | val_loss: 0.1023\n",
      "[1028,    49] train_loss: 0.5030 | val_loss: 0.1019\n",
      "[1029,    49] train_loss: 0.4985 | val_loss: 0.1024\n",
      "[1030,    49] train_loss: 0.5040 | val_loss: 0.1023\n",
      "[1031,    49] train_loss: 0.4999 | val_loss: 0.1013\n",
      "[1033,    49] train_loss: 0.5022 | val_loss: 0.1035\n",
      "[1034,    49] train_loss: 0.5032 | val_loss: 0.1043\n",
      "[1035,    49] train_loss: 0.4979 | val_loss: 0.1014\n",
      "[1036,    49] train_loss: 0.5015 | val_loss: 0.1021\n",
      "[1037,    49] train_loss: 0.4972 | val_loss: 0.1016\n",
      "[1038,    49] train_loss: 0.4998 | val_loss: 0.1022\n",
      "[1039,    49] train_loss: 0.5051 | val_loss: 0.1021\n",
      "[1040,    49] train_loss: 0.5021 | val_loss: 0.1019\n",
      "[1041,    49] train_loss: 0.5010 | val_loss: 0.1026\n",
      "[1042,    49] train_loss: 0.4979 | val_loss: 0.1017\n",
      "[1043,    49] train_loss: 0.4995 | val_loss: 0.1013\n",
      "[1044,    49] train_loss: 0.5045 | val_loss: 0.1016\n",
      "[1045,    49] train_loss: 0.5004 | val_loss: 0.1029\n",
      "[1046,    49] train_loss: 0.5048 | val_loss: 0.1026\n",
      "[1047,    49] train_loss: 0.5010 | val_loss: 0.1028\n",
      "[1048,    49] train_loss: 0.5005 | val_loss: 0.1020\n",
      "[1049,    49] train_loss: 0.4999 | val_loss: 0.1025\n",
      "[1050,    49] train_loss: 0.5033 | val_loss: 0.1017\n",
      "Saving checkpoint 1050\n",
      "[1051,    49] train_loss: 0.5025 | val_loss: 0.1022\n",
      "[1052,    49] train_loss: 0.5024 | val_loss: 0.1021\n",
      "[1053,    49] train_loss: 0.4999 | val_loss: 0.1014\n",
      "[1054,    49] train_loss: 0.5053 | val_loss: 0.1037\n",
      "[1055,    49] train_loss: 0.5026 | val_loss: 0.1022\n",
      "[1056,    49] train_loss: 0.5026 | val_loss: 0.1020\n",
      "[1057,    49] train_loss: 0.4991 | val_loss: 0.1023\n",
      "[1058,    49] train_loss: 0.4995 | val_loss: 0.1027\n",
      "[1059,    49] train_loss: 0.5028 | val_loss: 0.1029\n",
      "[1060,    49] train_loss: 0.4994 | val_loss: 0.1021\n",
      "[1061,    49] train_loss: 0.5003 | val_loss: 0.1015\n",
      "[1062,    49] train_loss: 0.5014 | val_loss: 0.1023\n",
      "[1063,    49] train_loss: 0.4997 | val_loss: 0.1029\n",
      "[1064,    49] train_loss: 0.5009 | val_loss: 0.1012\n",
      "[1065,    49] train_loss: 0.5009 | val_loss: 0.1018\n",
      "[1066,    49] train_loss: 0.5015 | val_loss: 0.1011\n",
      "[1067,    49] train_loss: 0.5013 | val_loss: 0.1024\n",
      "[1068,    49] train_loss: 0.5015 | val_loss: 0.1028\n",
      "[1069,    49] train_loss: 0.5026 | val_loss: 0.1021\n",
      "[1070,    49] train_loss: 0.5024 | val_loss: 0.1018\n",
      "[1071,    49] train_loss: 0.5009 | val_loss: 0.1024\n",
      "[1072,    49] train_loss: 0.5057 | val_loss: 0.1028\n",
      "[1073,    49] train_loss: 0.5015 | val_loss: 0.1041\n",
      "[1074,    49] train_loss: 0.5061 | val_loss: 0.1026\n",
      "[1075,    49] train_loss: 0.4971 | val_loss: 0.1011\n",
      "[1076,    49] train_loss: 0.5006 | val_loss: 0.1009\n",
      "[1077,    49] train_loss: 0.5014 | val_loss: 0.1025\n",
      "[1078,    49] train_loss: 0.5028 | val_loss: 0.1022\n",
      "[1079,    49] train_loss: 0.5023 | val_loss: 0.1030\n",
      "[1080,    49] train_loss: 0.5005 | val_loss: 0.1013\n",
      "[1081,    49] train_loss: 0.4996 | val_loss: 0.1018\n",
      "[1082,    49] train_loss: 0.5007 | val_loss: 0.1017\n",
      "[1083,    49] train_loss: 0.4998 | val_loss: 0.1024\n",
      "[1084,    49] train_loss: 0.4983 | val_loss: 0.1026\n",
      "[1085,    49] train_loss: 0.4996 | val_loss: 0.1025\n",
      "[1086,    49] train_loss: 0.4998 | val_loss: 0.1024\n",
      "[1087,    49] train_loss: 0.5021 | val_loss: 0.1014\n",
      "[1088,    49] train_loss: 0.5036 | val_loss: 0.1024\n",
      "[1089,    49] train_loss: 0.4973 | val_loss: 0.1022\n",
      "[1090,    49] train_loss: 0.5021 | val_loss: 0.1029\n",
      "[1091,    49] train_loss: 0.5017 | val_loss: 0.1024\n",
      "[1092,    49] train_loss: 0.4994 | val_loss: 0.1020\n",
      "[1093,    49] train_loss: 0.4992 | val_loss: 0.1023\n",
      "[1094,    49] train_loss: 0.5053 | val_loss: 0.1013\n",
      "[1095,    49] train_loss: 0.5026 | val_loss: 0.1025\n",
      "[1096,    49] train_loss: 0.5007 | val_loss: 0.1029\n",
      "[1097,    49] train_loss: 0.5009 | val_loss: 0.1025\n",
      "[1098,    49] train_loss: 0.5003 | val_loss: 0.1014\n",
      "[1099,    49] train_loss: 0.5029 | val_loss: 0.1020\n",
      "[1100,    49] train_loss: 0.5025 | val_loss: 0.1022\n",
      "Saving checkpoint 1100\n",
      "[1101,    49] train_loss: 0.5049 | val_loss: 0.1008\n",
      "[1102,    49] train_loss: 0.4995 | val_loss: 0.1014\n",
      "[1103,    49] train_loss: 0.5011 | val_loss: 0.1027\n",
      "[1104,    49] train_loss: 0.4995 | val_loss: 0.1028\n",
      "[1105,    49] train_loss: 0.4988 | val_loss: 0.1007\n",
      "[1106,    49] train_loss: 0.5011 | val_loss: 0.1050\n",
      "[1107,    49] train_loss: 0.5047 | val_loss: 0.1022\n",
      "[1108,    49] train_loss: 0.5029 | val_loss: 0.1011\n",
      "[1109,    49] train_loss: 0.4988 | val_loss: 0.1021\n",
      "[1110,    49] train_loss: 0.4985 | val_loss: 0.1025\n",
      "[1111,    49] train_loss: 0.5013 | val_loss: 0.1031\n",
      "[1112,    49] train_loss: 0.4961 | val_loss: 0.1016\n",
      "[1113,    49] train_loss: 0.4994 | val_loss: 0.1032\n",
      "[1114,    49] train_loss: 0.5011 | val_loss: 0.1030\n",
      "[1115,    49] train_loss: 0.4992 | val_loss: 0.1011\n",
      "[1116,    49] train_loss: 0.5031 | val_loss: 0.1023\n",
      "[1117,    49] train_loss: 0.5004 | val_loss: 0.1033\n",
      "[1118,    49] train_loss: 0.5000 | val_loss: 0.1017\n",
      "[1119,    49] train_loss: 0.4990 | val_loss: 0.1023\n",
      "[1120,    49] train_loss: 0.4977 | val_loss: 0.1042\n",
      "[1121,    49] train_loss: 0.4982 | val_loss: 0.1030\n",
      "[1122,    49] train_loss: 0.5021 | val_loss: 0.1019\n",
      "[1123,    49] train_loss: 0.5013 | val_loss: 0.1009\n",
      "[1124,    49] train_loss: 0.5009 | val_loss: 0.1029\n",
      "[1125,    49] train_loss: 0.5029 | val_loss: 0.1026\n",
      "[1126,    49] train_loss: 0.5033 | val_loss: 0.1012\n",
      "[1127,    49] train_loss: 0.5003 | val_loss: 0.1030\n",
      "[1128,    49] train_loss: 0.5003 | val_loss: 0.1050\n",
      "[1129,    49] train_loss: 0.4996 | val_loss: 0.1035\n",
      "[1130,    49] train_loss: 0.5003 | val_loss: 0.1016\n",
      "[1131,    49] train_loss: 0.4992 | val_loss: 0.1019\n",
      "[1132,    49] train_loss: 0.5001 | val_loss: 0.1020\n",
      "[1133,    49] train_loss: 0.5039 | val_loss: 0.1030\n",
      "[1134,    49] train_loss: 0.5031 | val_loss: 0.1019\n",
      "[1135,    49] train_loss: 0.5000 | val_loss: 0.1029\n",
      "[1136,    49] train_loss: 0.5032 | val_loss: 0.1031\n",
      "[1137,    49] train_loss: 0.5027 | val_loss: 0.1035\n",
      "[1138,    49] train_loss: 0.5027 | val_loss: 0.1013\n",
      "[1139,    49] train_loss: 0.5007 | val_loss: 0.1019\n",
      "[1140,    49] train_loss: 0.5034 | val_loss: 0.1025\n",
      "[1141,    49] train_loss: 0.4975 | val_loss: 0.1017\n",
      "[1142,    49] train_loss: 0.4965 | val_loss: 0.1011\n",
      "[1143,    49] train_loss: 0.5022 | val_loss: 0.1021\n",
      "[1144,    49] train_loss: 0.4991 | val_loss: 0.1025\n",
      "[1145,    49] train_loss: 0.4974 | val_loss: 0.1033\n",
      "[1146,    49] train_loss: 0.5007 | val_loss: 0.1013\n",
      "[1147,    49] train_loss: 0.5018 | val_loss: 0.1033\n",
      "[1148,    49] train_loss: 0.5019 | val_loss: 0.1018\n",
      "[1149,    49] train_loss: 0.5000 | val_loss: 0.1022\n",
      "[1150,    49] train_loss: 0.4994 | val_loss: 0.1026\n",
      "Saving checkpoint 1150\n",
      "[1151,    49] train_loss: 0.4991 | val_loss: 0.1006\n",
      "[1152,    49] train_loss: 0.5011 | val_loss: 0.1025\n",
      "[1153,    49] train_loss: 0.5043 | val_loss: 0.1013\n",
      "[1154,    49] train_loss: 0.4995 | val_loss: 0.1020\n",
      "[1155,    49] train_loss: 0.5028 | val_loss: 0.1019\n",
      "[1156,    49] train_loss: 0.5009 | val_loss: 0.1006\n",
      "[1157,    49] train_loss: 0.4982 | val_loss: 0.1015\n",
      "[1158,    49] train_loss: 0.5015 | val_loss: 0.1019\n",
      "[1159,    49] train_loss: 0.4994 | val_loss: 0.1026\n",
      "[1160,    49] train_loss: 0.5013 | val_loss: 0.1030\n",
      "[1161,    49] train_loss: 0.5008 | val_loss: 0.1020\n",
      "[1162,    49] train_loss: 0.5001 | val_loss: 0.1021\n",
      "[1163,    49] train_loss: 0.5003 | val_loss: 0.1028\n",
      "[1164,    49] train_loss: 0.5000 | val_loss: 0.1032\n",
      "[1165,    49] train_loss: 0.5006 | val_loss: 0.1019\n",
      "[1166,    49] train_loss: 0.4996 | val_loss: 0.1027\n",
      "[1167,    49] train_loss: 0.5050 | val_loss: 0.1053\n",
      "[1168,    49] train_loss: 0.5014 | val_loss: 0.1033\n",
      "[1169,    49] train_loss: 0.5021 | val_loss: 0.1031\n",
      "[1170,    49] train_loss: 0.5015 | val_loss: 0.1019\n",
      "[1171,    49] train_loss: 0.4991 | val_loss: 0.1030\n",
      "[1172,    49] train_loss: 0.4995 | val_loss: 0.1010\n",
      "[1173,    49] train_loss: 0.5032 | val_loss: 0.1026\n",
      "[1174,    49] train_loss: 0.5038 | val_loss: 0.1036\n",
      "[1175,    49] train_loss: 0.4993 | val_loss: 0.1024\n",
      "[1176,    49] train_loss: 0.5012 | val_loss: 0.1009\n",
      "[1177,    49] train_loss: 0.5001 | val_loss: 0.1028\n",
      "[1178,    49] train_loss: 0.5054 | val_loss: 0.1024\n",
      "[1179,    49] train_loss: 0.5004 | val_loss: 0.1017\n",
      "[1180,    49] train_loss: 0.4988 | val_loss: 0.1031\n",
      "[1181,    49] train_loss: 0.5006 | val_loss: 0.1028\n",
      "[1182,    49] train_loss: 0.5006 | val_loss: 0.1007\n",
      "[1183,    49] train_loss: 0.4998 | val_loss: 0.1011\n",
      "[1184,    49] train_loss: 0.5015 | val_loss: 0.1040\n",
      "[1185,    49] train_loss: 0.5040 | val_loss: 0.1011\n",
      "[1186,    49] train_loss: 0.4987 | val_loss: 0.1005\n",
      "[1187,    49] train_loss: 0.4995 | val_loss: 0.1018\n",
      "[1188,    49] train_loss: 0.4985 | val_loss: 0.1025\n",
      "[1189,    49] train_loss: 0.5011 | val_loss: 0.1016\n",
      "[1190,    49] train_loss: 0.5016 | val_loss: 0.1030\n",
      "[1191,    49] train_loss: 0.5023 | val_loss: 0.1030\n",
      "[1192,    49] train_loss: 0.4987 | val_loss: 0.1007\n",
      "[1193,    49] train_loss: 0.4997 | val_loss: 0.1008\n",
      "[1194,    49] train_loss: 0.5017 | val_loss: 0.1019\n",
      "[1195,    49] train_loss: 0.5000 | val_loss: 0.1028\n",
      "[1196,    49] train_loss: 0.5039 | val_loss: 0.1025\n",
      "[1197,    49] train_loss: 0.5017 | val_loss: 0.1011\n",
      "[1198,    49] train_loss: 0.5025 | val_loss: 0.1018\n",
      "[1199,    49] train_loss: 0.5038 | val_loss: 0.1033\n",
      "[1200,    49] train_loss: 0.5014 | val_loss: 0.1025\n",
      "Saving checkpoint 1200\n",
      "[1201,    49] train_loss: 0.5008 | val_loss: 0.1021\n",
      "[1202,    49] train_loss: 0.4985 | val_loss: 0.1023\n",
      "[1203,    49] train_loss: 0.5000 | val_loss: 0.1013\n",
      "[1204,    49] train_loss: 0.5008 | val_loss: 0.1017\n",
      "[1205,    49] train_loss: 0.5032 | val_loss: 0.1021\n",
      "[1206,    49] train_loss: 0.5012 | val_loss: 0.1006\n",
      "[1207,    49] train_loss: 0.5032 | val_loss: 0.1029\n",
      "[1208,    49] train_loss: 0.5007 | val_loss: 0.1019\n",
      "[1209,    49] train_loss: 0.5016 | val_loss: 0.1017\n",
      "[1210,    49] train_loss: 0.5015 | val_loss: 0.1012\n",
      "[1211,    49] train_loss: 0.4998 | val_loss: 0.1030\n",
      "[1212,    49] train_loss: 0.5041 | val_loss: 0.1028\n",
      "[1213,    49] train_loss: 0.5016 | val_loss: 0.1013\n",
      "[1214,    49] train_loss: 0.4994 | val_loss: 0.1013\n",
      "[1215,    49] train_loss: 0.5003 | val_loss: 0.1017\n",
      "[1216,    49] train_loss: 0.5020 | val_loss: 0.1037\n",
      "[1217,    49] train_loss: 0.5015 | val_loss: 0.1018\n",
      "[1218,    49] train_loss: 0.4972 | val_loss: 0.1022\n",
      "[1219,    49] train_loss: 0.4987 | val_loss: 0.1010\n",
      "[1220,    49] train_loss: 0.5041 | val_loss: 0.1025\n",
      "[1221,    49] train_loss: 0.5027 | val_loss: 0.1015\n",
      "[1222,    49] train_loss: 0.4982 | val_loss: 0.1014\n",
      "[1223,    49] train_loss: 0.5055 | val_loss: 0.1014\n",
      "[1224,    49] train_loss: 0.5002 | val_loss: 0.1026\n",
      "[1225,    49] train_loss: 0.4999 | val_loss: 0.1026\n",
      "[1226,    49] train_loss: 0.5041 | val_loss: 0.1034\n",
      "[1227,    49] train_loss: 0.4955 | val_loss: 0.1025\n",
      "[1228,    49] train_loss: 0.5014 | val_loss: 0.1026\n",
      "[1229,    49] train_loss: 0.5017 | val_loss: 0.1021\n",
      "[1230,    49] train_loss: 0.5012 | val_loss: 0.1027\n",
      "[1231,    49] train_loss: 0.5038 | val_loss: 0.1022\n",
      "[1232,    49] train_loss: 0.5012 | val_loss: 0.1019\n",
      "[1233,    49] train_loss: 0.5041 | val_loss: 0.1016\n",
      "[1234,    49] train_loss: 0.4986 | val_loss: 0.1014\n",
      "[1235,    49] train_loss: 0.4992 | val_loss: 0.1016\n",
      "[1236,    49] train_loss: 0.4994 | val_loss: 0.1028\n",
      "[1237,    49] train_loss: 0.5001 | val_loss: 0.1025\n",
      "[1238,    49] train_loss: 0.5016 | val_loss: 0.1008\n",
      "[1239,    49] train_loss: 0.4990 | val_loss: 0.1012\n",
      "[1240,    49] train_loss: 0.4993 | val_loss: 0.1013\n",
      "[1241,    49] train_loss: 0.5006 | val_loss: 0.1025\n",
      "[1242,    49] train_loss: 0.4983 | val_loss: 0.1021\n",
      "[1243,    49] train_loss: 0.4974 | val_loss: 0.1032\n",
      "[1244,    49] train_loss: 0.5022 | val_loss: 0.1023\n",
      "[1245,    49] train_loss: 0.5004 | val_loss: 0.1036\n",
      "[1246,    49] train_loss: 0.5024 | val_loss: 0.1028\n",
      "[1247,    49] train_loss: 0.4998 | val_loss: 0.1033\n",
      "[1248,    49] train_loss: 0.5004 | val_loss: 0.0993\n",
      "[1249,    49] train_loss: 0.5048 | val_loss: 0.1023\n",
      "[1250,    49] train_loss: 0.5003 | val_loss: 0.1034\n",
      "Saving checkpoint 1250\n",
      "[1251,    49] train_loss: 0.4973 | val_loss: 0.1019\n",
      "[1252,    49] train_loss: 0.5007 | val_loss: 0.1015\n",
      "[1253,    49] train_loss: 0.5004 | val_loss: 0.1011\n",
      "[1254,    49] train_loss: 0.5016 | val_loss: 0.1016\n",
      "[1255,    49] train_loss: 0.4996 | val_loss: 0.1023\n",
      "[1256,    49] train_loss: 0.5031 | val_loss: 0.1022\n",
      "[1257,    49] train_loss: 0.5029 | val_loss: 0.1024\n",
      "[1258,    49] train_loss: 0.4989 | val_loss: 0.1024\n",
      "[1259,    49] train_loss: 0.4989 | val_loss: 0.1011\n",
      "[1260,    49] train_loss: 0.4986 | val_loss: 0.1024\n",
      "[1261,    49] train_loss: 0.5025 | val_loss: 0.1013\n",
      "[1262,    49] train_loss: 0.4968 | val_loss: 0.1013\n",
      "[1263,    49] train_loss: 0.5027 | val_loss: 0.1012\n",
      "[1264,    49] train_loss: 0.5016 | val_loss: 0.1021\n",
      "[1265,    49] train_loss: 0.4968 | val_loss: 0.1023\n",
      "[1266,    49] train_loss: 0.4972 | val_loss: 0.1024\n",
      "[1267,    49] train_loss: 0.4970 | val_loss: 0.1029\n",
      "[1268,    49] train_loss: 0.5017 | val_loss: 0.1017\n",
      "[1269,    49] train_loss: 0.4994 | val_loss: 0.1038\n",
      "[1270,    49] train_loss: 0.5002 | val_loss: 0.1012\n",
      "[1271,    49] train_loss: 0.5016 | val_loss: 0.1005\n",
      "[1272,    49] train_loss: 0.5007 | val_loss: 0.1006\n",
      "[1273,    49] train_loss: 0.5010 | val_loss: 0.1034\n",
      "[1274,    49] train_loss: 0.4999 | val_loss: 0.1025\n",
      "[1275,    49] train_loss: 0.4985 | val_loss: 0.1023\n",
      "[1276,    49] train_loss: 0.5030 | val_loss: 0.1018\n",
      "[1277,    49] train_loss: 0.5010 | val_loss: 0.1014\n",
      "[1278,    49] train_loss: 0.4980 | val_loss: 0.1028\n",
      "[1279,    49] train_loss: 0.5031 | val_loss: 0.1021\n",
      "[1280,    49] train_loss: 0.5044 | val_loss: 0.1031\n",
      "[1281,    49] train_loss: 0.5018 | val_loss: 0.1000\n",
      "[1282,    49] train_loss: 0.5027 | val_loss: 0.1026\n",
      "[1283,    49] train_loss: 0.5009 | val_loss: 0.1028\n",
      "[1284,    49] train_loss: 0.4994 | val_loss: 0.1008\n",
      "[1285,    49] train_loss: 0.5037 | val_loss: 0.1014\n",
      "[1286,    49] train_loss: 0.5015 | val_loss: 0.1022\n",
      "[1287,    49] train_loss: 0.5031 | val_loss: 0.1006\n",
      "[1288,    49] train_loss: 0.4999 | val_loss: 0.1014\n",
      "[1289,    49] train_loss: 0.5017 | val_loss: 0.1029\n",
      "[1290,    49] train_loss: 0.5002 | val_loss: 0.1014\n",
      "[1291,    49] train_loss: 0.4998 | val_loss: 0.1032\n",
      "[1292,    49] train_loss: 0.5069 | val_loss: 0.1025\n",
      "[1293,    49] train_loss: 0.4982 | val_loss: 0.1013\n",
      "[1294,    49] train_loss: 0.5032 | val_loss: 0.1015\n",
      "[1295,    49] train_loss: 0.5017 | val_loss: 0.1027\n",
      "[1296,    49] train_loss: 0.5009 | val_loss: 0.1022\n",
      "[1297,    49] train_loss: 0.4983 | val_loss: 0.1001\n",
      "[1298,    49] train_loss: 0.5010 | val_loss: 0.1018\n",
      "[1299,    49] train_loss: 0.4976 | val_loss: 0.1016\n",
      "[1300,    49] train_loss: 0.5033 | val_loss: 0.1009\n",
      "Saving checkpoint 1300\n",
      "[1301,    49] train_loss: 0.4990 | val_loss: 0.1022\n",
      "[1302,    49] train_loss: 0.5041 | val_loss: 0.1029\n",
      "[1303,    49] train_loss: 0.4987 | val_loss: 0.1032\n",
      "[1304,    49] train_loss: 0.4993 | val_loss: 0.1028\n",
      "[1305,    49] train_loss: 0.5012 | val_loss: 0.1019\n",
      "[1306,    49] train_loss: 0.4989 | val_loss: 0.1021\n",
      "[1307,    49] train_loss: 0.5047 | val_loss: 0.1014\n",
      "[1308,    49] train_loss: 0.4972 | val_loss: 0.1019\n",
      "[1309,    49] train_loss: 0.4962 | val_loss: 0.1023\n",
      "[1310,    49] train_loss: 0.4985 | val_loss: 0.1034\n",
      "[1311,    49] train_loss: 0.5022 | val_loss: 0.1018\n",
      "[1312,    49] train_loss: 0.5000 | val_loss: 0.1039\n",
      "[1313,    49] train_loss: 0.4996 | val_loss: 0.1010\n",
      "[1314,    49] train_loss: 0.5007 | val_loss: 0.1004\n",
      "[1315,    49] train_loss: 0.4996 | val_loss: 0.1025\n",
      "[1316,    49] train_loss: 0.4988 | val_loss: 0.1032\n",
      "[1317,    49] train_loss: 0.4997 | val_loss: 0.1005\n",
      "[1318,    49] train_loss: 0.5028 | val_loss: 0.1003\n",
      "[1319,    49] train_loss: 0.4971 | val_loss: 0.1014\n",
      "[1320,    49] train_loss: 0.4980 | val_loss: 0.1015\n",
      "[1321,    49] train_loss: 0.5014 | val_loss: 0.1029\n",
      "[1322,    49] train_loss: 0.5028 | val_loss: 0.1024\n",
      "[1323,    49] train_loss: 0.4985 | val_loss: 0.1007\n",
      "[1324,    49] train_loss: 0.5012 | val_loss: 0.1010\n",
      "[1325,    49] train_loss: 0.4977 | val_loss: 0.1015\n",
      "[1326,    49] train_loss: 0.5031 | val_loss: 0.1043\n",
      "[1327,    49] train_loss: 0.5003 | val_loss: 0.1027\n",
      "[1328,    49] train_loss: 0.5017 | val_loss: 0.1011\n",
      "[1329,    49] train_loss: 0.5021 | val_loss: 0.1019\n",
      "[1330,    49] train_loss: 0.5026 | val_loss: 0.1015\n",
      "[1331,    49] train_loss: 0.5006 | val_loss: 0.1034\n",
      "[1332,    49] train_loss: 0.5018 | val_loss: 0.1019\n",
      "[1333,    49] train_loss: 0.5008 | val_loss: 0.1019\n",
      "[1334,    49] train_loss: 0.5007 | val_loss: 0.1024\n",
      "[1335,    49] train_loss: 0.5022 | val_loss: 0.1027\n",
      "[1336,    49] train_loss: 0.5034 | val_loss: 0.1016\n",
      "[1337,    49] train_loss: 0.4976 | val_loss: 0.1031\n",
      "[1338,    49] train_loss: 0.5012 | val_loss: 0.1035\n",
      "[1339,    49] train_loss: 0.4999 | val_loss: 0.1030\n",
      "[1340,    49] train_loss: 0.4970 | val_loss: 0.1006\n",
      "[1341,    49] train_loss: 0.5042 | val_loss: 0.1012\n",
      "[1342,    49] train_loss: 0.4994 | val_loss: 0.1013\n",
      "[1343,    49] train_loss: 0.4988 | val_loss: 0.1029\n",
      "[1344,    49] train_loss: 0.5029 | val_loss: 0.1020\n",
      "[1345,    49] train_loss: 0.5002 | val_loss: 0.1019\n",
      "[1346,    49] train_loss: 0.5033 | val_loss: 0.1028\n",
      "[1347,    49] train_loss: 0.4972 | val_loss: 0.1024\n",
      "[1348,    49] train_loss: 0.5000 | val_loss: 0.1025\n",
      "[1349,    49] train_loss: 0.5010 | val_loss: 0.1017\n",
      "[1350,    49] train_loss: 0.4994 | val_loss: 0.1026\n",
      "Saving checkpoint 1350\n",
      "[1351,    49] train_loss: 0.5049 | val_loss: 0.1029\n",
      "[1352,    49] train_loss: 0.5016 | val_loss: 0.1017\n",
      "[1353,    49] train_loss: 0.5014 | val_loss: 0.1033\n",
      "[1354,    49] train_loss: 0.4989 | val_loss: 0.1027\n",
      "[1355,    49] train_loss: 0.5013 | val_loss: 0.1021\n",
      "[1356,    49] train_loss: 0.4964 | val_loss: 0.1007\n",
      "[1357,    49] train_loss: 0.5004 | val_loss: 0.1028\n",
      "[1358,    49] train_loss: 0.5006 | val_loss: 0.1024\n",
      "[1359,    49] train_loss: 0.4994 | val_loss: 0.1009\n",
      "[1360,    49] train_loss: 0.5034 | val_loss: 0.1024\n",
      "[1361,    49] train_loss: 0.4992 | val_loss: 0.1027\n",
      "[1362,    49] train_loss: 0.4982 | val_loss: 0.1015\n",
      "[1363,    49] train_loss: 0.5019 | val_loss: 0.1007\n",
      "[1364,    49] train_loss: 0.5026 | val_loss: 0.1014\n",
      "[1365,    49] train_loss: 0.5074 | val_loss: 0.1024\n",
      "[1366,    49] train_loss: 0.5007 | val_loss: 0.1027\n",
      "[1367,    49] train_loss: 0.5010 | val_loss: 0.1017\n",
      "[1368,    49] train_loss: 0.5000 | val_loss: 0.1029\n",
      "[1369,    49] train_loss: 0.5040 | val_loss: 0.1015\n",
      "[1370,    49] train_loss: 0.4989 | val_loss: 0.1028\n",
      "[1371,    49] train_loss: 0.5008 | val_loss: 0.1012\n",
      "[1372,    49] train_loss: 0.5019 | val_loss: 0.1020\n",
      "[1373,    49] train_loss: 0.5017 | val_loss: 0.1021\n",
      "[1374,    49] train_loss: 0.5013 | val_loss: 0.1036\n",
      "[1375,    49] train_loss: 0.5041 | val_loss: 0.1022\n",
      "[1376,    49] train_loss: 0.5011 | val_loss: 0.1019\n",
      "[1377,    49] train_loss: 0.5002 | val_loss: 0.1021\n",
      "[1378,    49] train_loss: 0.5012 | val_loss: 0.1020\n",
      "[1379,    49] train_loss: 0.5038 | val_loss: 0.1015\n",
      "[1380,    49] train_loss: 0.4997 | val_loss: 0.1014\n",
      "[1381,    49] train_loss: 0.5011 | val_loss: 0.1023\n",
      "[1382,    49] train_loss: 0.5013 | val_loss: 0.1018\n",
      "[1383,    49] train_loss: 0.5009 | val_loss: 0.1019\n",
      "[1384,    49] train_loss: 0.5007 | val_loss: 0.1020\n",
      "[1385,    49] train_loss: 0.4994 | val_loss: 0.1029\n",
      "[1386,    49] train_loss: 0.5041 | val_loss: 0.1019\n",
      "[1387,    49] train_loss: 0.4987 | val_loss: 0.1030\n",
      "[1388,    49] train_loss: 0.4959 | val_loss: 0.1031\n",
      "[1389,    49] train_loss: 0.5004 | val_loss: 0.1026\n",
      "[1390,    49] train_loss: 0.4984 | val_loss: 0.1028\n",
      "[1391,    49] train_loss: 0.5044 | val_loss: 0.1014\n",
      "[1392,    49] train_loss: 0.5007 | val_loss: 0.1029\n",
      "[1393,    49] train_loss: 0.4988 | val_loss: 0.1015\n",
      "[1394,    49] train_loss: 0.5008 | val_loss: 0.1023\n",
      "[1395,    49] train_loss: 0.4999 | val_loss: 0.1034\n",
      "[1396,    49] train_loss: 0.4977 | val_loss: 0.1023\n",
      "[1397,    49] train_loss: 0.5001 | val_loss: 0.1022\n",
      "[1398,    49] train_loss: 0.5007 | val_loss: 0.1015\n",
      "[1399,    49] train_loss: 0.5006 | val_loss: 0.1028\n",
      "[1400,    49] train_loss: 0.5010 | val_loss: 0.1022\n",
      "Saving checkpoint 1400\n",
      "[1401,    49] train_loss: 0.5041 | val_loss: 0.1018\n",
      "[1402,    49] train_loss: 0.4992 | val_loss: 0.1019\n",
      "[1403,    49] train_loss: 0.5014 | val_loss: 0.1015\n",
      "[1404,    49] train_loss: 0.5039 | val_loss: 0.1020\n",
      "[1405,    49] train_loss: 0.5011 | val_loss: 0.1023\n",
      "[1406,    49] train_loss: 0.4987 | val_loss: 0.1010\n",
      "[1407,    49] train_loss: 0.4997 | val_loss: 0.1014\n",
      "[1408,    49] train_loss: 0.5017 | val_loss: 0.1012\n",
      "[1409,    49] train_loss: 0.5056 | val_loss: 0.1027\n",
      "[1410,    49] train_loss: 0.5018 | val_loss: 0.1012\n",
      "[1411,    49] train_loss: 0.5038 | val_loss: 0.1034\n",
      "[1412,    49] train_loss: 0.4963 | val_loss: 0.1005\n",
      "[1413,    49] train_loss: 0.5015 | val_loss: 0.1022\n",
      "[1414,    49] train_loss: 0.4990 | val_loss: 0.1024\n",
      "[1415,    49] train_loss: 0.5016 | val_loss: 0.1007\n",
      "[1416,    49] train_loss: 0.4982 | val_loss: 0.1007\n",
      "[1417,    49] train_loss: 0.4999 | val_loss: 0.1038\n",
      "[1418,    49] train_loss: 0.5007 | val_loss: 0.1026\n",
      "[1419,    49] train_loss: 0.5012 | val_loss: 0.1027\n",
      "[1420,    49] train_loss: 0.5026 | val_loss: 0.1020\n",
      "[1421,    49] train_loss: 0.5023 | val_loss: 0.1021\n",
      "[1422,    49] train_loss: 0.4985 | val_loss: 0.1010\n",
      "[1423,    49] train_loss: 0.5029 | val_loss: 0.1014\n",
      "[1424,    49] train_loss: 0.4966 | val_loss: 0.1023\n",
      "[1425,    49] train_loss: 0.5002 | val_loss: 0.1026\n",
      "[1426,    49] train_loss: 0.5028 | val_loss: 0.1033\n",
      "[1427,    49] train_loss: 0.4989 | val_loss: 0.1022\n",
      "[1428,    49] train_loss: 0.4992 | val_loss: 0.1043\n",
      "[1429,    49] train_loss: 0.5003 | val_loss: 0.1024\n",
      "[1430,    49] train_loss: 0.5008 | val_loss: 0.1032\n",
      "[1431,    49] train_loss: 0.5007 | val_loss: 0.1040\n",
      "[1432,    49] train_loss: 0.4981 | val_loss: 0.1032\n",
      "[1433,    49] train_loss: 0.5006 | val_loss: 0.1033\n",
      "[1434,    49] train_loss: 0.5019 | val_loss: 0.1021\n",
      "[1435,    49] train_loss: 0.4970 | val_loss: 0.1014\n",
      "[1436,    49] train_loss: 0.5041 | val_loss: 0.1014\n",
      "[1437,    49] train_loss: 0.4996 | val_loss: 0.1019\n",
      "[1438,    49] train_loss: 0.4988 | val_loss: 0.1034\n",
      "[1439,    49] train_loss: 0.5011 | val_loss: 0.1018\n",
      "[1440,    49] train_loss: 0.5013 | val_loss: 0.1032\n",
      "[1441,    49] train_loss: 0.4989 | val_loss: 0.1010\n",
      "[1442,    49] train_loss: 0.5036 | val_loss: 0.1008\n",
      "[1443,    49] train_loss: 0.4963 | val_loss: 0.1018\n",
      "[1444,    49] train_loss: 0.5013 | val_loss: 0.1017\n",
      "[1445,    49] train_loss: 0.4989 | val_loss: 0.1020\n",
      "[1446,    49] train_loss: 0.5011 | val_loss: 0.1029\n",
      "[1447,    49] train_loss: 0.4973 | val_loss: 0.1020\n",
      "[1448,    49] train_loss: 0.4997 | val_loss: 0.1009\n",
      "[1449,    49] train_loss: 0.5006 | val_loss: 0.1022\n",
      "[1450,    49] train_loss: 0.5022 | val_loss: 0.1024\n",
      "Saving checkpoint 1450\n",
      "[1451,    49] train_loss: 0.5018 | val_loss: 0.1016\n",
      "[1452,    49] train_loss: 0.4981 | val_loss: 0.1039\n",
      "[1453,    49] train_loss: 0.5025 | val_loss: 0.1029\n",
      "[1454,    49] train_loss: 0.5031 | val_loss: 0.1034\n",
      "[1455,    49] train_loss: 0.5020 | val_loss: 0.1026\n",
      "[1456,    49] train_loss: 0.4990 | val_loss: 0.1036\n",
      "[1457,    49] train_loss: 0.5070 | val_loss: 0.1028\n",
      "[1458,    49] train_loss: 0.5013 | val_loss: 0.1008\n",
      "[1459,    49] train_loss: 0.5017 | val_loss: 0.1020\n",
      "[1460,    49] train_loss: 0.5045 | val_loss: 0.1029\n",
      "[1461,    49] train_loss: 0.5004 | val_loss: 0.1036\n",
      "[1462,    49] train_loss: 0.4989 | val_loss: 0.1015\n",
      "[1463,    49] train_loss: 0.5035 | val_loss: 0.1011\n",
      "[1464,    49] train_loss: 0.4991 | val_loss: 0.1019\n",
      "[1465,    49] train_loss: 0.5010 | val_loss: 0.1016\n",
      "[1466,    49] train_loss: 0.5034 | val_loss: 0.1027\n",
      "[1467,    49] train_loss: 0.4987 | val_loss: 0.1033\n",
      "[1468,    49] train_loss: 0.4996 | val_loss: 0.1019\n",
      "[1469,    49] train_loss: 0.5014 | val_loss: 0.1028\n",
      "[1470,    49] train_loss: 0.5001 | val_loss: 0.1025\n",
      "[1471,    49] train_loss: 0.4990 | val_loss: 0.1027\n",
      "[1472,    49] train_loss: 0.4999 | val_loss: 0.1012\n",
      "[1473,    49] train_loss: 0.5021 | val_loss: 0.1019\n",
      "[1474,    49] train_loss: 0.5009 | val_loss: 0.1035\n",
      "[1475,    49] train_loss: 0.4982 | val_loss: 0.1009\n",
      "[1476,    49] train_loss: 0.4967 | val_loss: 0.1025\n",
      "[1477,    49] train_loss: 0.4981 | val_loss: 0.1028\n",
      "[1478,    49] train_loss: 0.5013 | val_loss: 0.1024\n",
      "[1479,    49] train_loss: 0.4996 | val_loss: 0.1014\n",
      "[1480,    49] train_loss: 0.4989 | val_loss: 0.1014\n",
      "[1481,    49] train_loss: 0.4981 | val_loss: 0.1016\n",
      "[1482,    49] train_loss: 0.5014 | val_loss: 0.1009\n",
      "[1483,    49] train_loss: 0.4956 | val_loss: 0.1026\n",
      "[1484,    49] train_loss: 0.5011 | val_loss: 0.1035\n",
      "[1485,    49] train_loss: 0.4999 | val_loss: 0.1032\n",
      "[1486,    49] train_loss: 0.5001 | val_loss: 0.1037\n",
      "[1487,    49] train_loss: 0.4971 | val_loss: 0.1024\n",
      "[1488,    49] train_loss: 0.5004 | val_loss: 0.1030\n",
      "[1489,    49] train_loss: 0.4982 | val_loss: 0.1010\n",
      "[1490,    49] train_loss: 0.4974 | val_loss: 0.1011\n",
      "[1491,    49] train_loss: 0.5016 | val_loss: 0.1015\n",
      "[1492,    49] train_loss: 0.5010 | val_loss: 0.1009\n",
      "[1493,    49] train_loss: 0.4971 | val_loss: 0.1028\n",
      "[1494,    49] train_loss: 0.5008 | val_loss: 0.1020\n",
      "[1495,    49] train_loss: 0.5014 | val_loss: 0.1022\n",
      "[1496,    49] train_loss: 0.5022 | val_loss: 0.1018\n",
      "[1497,    49] train_loss: 0.4955 | val_loss: 0.1030\n",
      "[1498,    49] train_loss: 0.4973 | val_loss: 0.1016\n",
      "[1499,    49] train_loss: 0.5002 | val_loss: 0.1003\n",
      "Saving checkpoint 1499\n",
      "[1500,    49] train_loss: 0.4979 | val_loss: 0.1017\n",
      "Total train time: 2417.3667735298473min\n",
      "Evaluating model...\n",
      "Using 2173 samples for validation set\n",
      "8693 total training samples\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lmeyers/ReID_complete/SCL_reID/train/pytorch_train_and_eval_reid_2.py\", line 396, in <module>\n",
      "    train_and_eval(args.config_file)\n",
      "  File \"/home/lmeyers/ReID_complete/SCL_reID/train/pytorch_train_and_eval_reid_2.py\", line 336, in train_and_eval\n",
      "    reference_embeddings, reference_labels, reference_loss = get_embeddings(model, reference_dataloader, loss_fn, miner, device, feature_extractor)\n",
      "UnboundLocalError: local variable 'reference_dataloader' referenced before assignment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: triplet_num ‚ñá‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train loss 0.09865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: triplet_num 115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid loss 0.10173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33msplendid-tree-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/vit_baselines_test64_ids_batch1_sample_num_64/runs/0glrglqb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/home/lmeyers/contrastive_learning_new_training/64_ids_batch1_sample_num_64/wandb/run-20240912_123412-0glrglqb/logs\u001b[0m\n",
      "Num labels  64\n",
      "2024-09-14 04:54:55.775022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-14 04:54:56.699847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/contrastive_learning_new_training/64_ids_batch2_sample_num_64/wandb/run-20240914_045459-8mp1hgly\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-valley-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/vit_baselines_test64_ids_batch2_sample_num_64\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/vit_baselines_test64_ids_batch2_sample_num_64/runs/8mp1hgly\u001b[0m\n",
      "Date and time when this experiment was started: 24-09-14 04:55\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_max.csv', 'reference': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_02.csv', 'test': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_max.csv', 'train': '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_64.csv', 'valid': ''}, 'dataset': 'summer_2023', 'fname_col': 'new_filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'ID', 'n_distractors': 9, 'percent_valid': 0.2, 'sample_reference': True, 'sample_valid': True, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'early_stop_consecutive_epochs': 1000, 'early_stopping': True, 'gpu': 1, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/contrastive_learning_new_training/64_ids_batch2_sample_num_64/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'vit_baselines_test64_ids_batch2_sample_num_64', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'vit_reid', 'model_path': '/home/lmeyers/contrastive_learning_new_training/64_ids_batch2_sample_num_64/64_ids_batch2_sample_num_64.pth', 'num_labels': '64'}\n",
      "Using GPU 1\n",
      "Creating train and valid dataloaders...\n",
      "Using 804 samples for validation set\n",
      "3215 total training samples\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Getting ViT feature extractor...\n",
      "/home/lmeyers/anaconda3/envs/mlenv/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "[1,    51] train_loss: 0.6112 | val_loss: 0.1241\n",
      "[2,    51] train_loss: 0.5899 | val_loss: 0.1392\n",
      "[3,    51] train_loss: 0.5959 | val_loss: 0.1181\n",
      "[4,    51] train_loss: 0.5936 | val_loss: 0.1242\n",
      "[5,    51] train_loss: 0.6057 | val_loss: 0.1269\n",
      "[6,    51] train_loss: 0.5733 | val_loss: 0.1301\n",
      "[7,    51] train_loss: 0.5777 | val_loss: 0.1208\n",
      "[8,    51] train_loss: 0.5818 | val_loss: 0.1261\n",
      "[9,    51] train_loss: 0.5884 | val_loss: 0.1225\n",
      "[10,    51] train_loss: 0.5893 | val_loss: 0.1274\n",
      "[11,    51] train_loss: 0.5937 | val_loss: 0.1292\n",
      "[12,    51] train_loss: 0.6026 | val_loss: 0.1338\n",
      "[13,    51] train_loss: 0.5871 | val_loss: 0.1207\n",
      "[14,    51] train_loss: 0.6403 | val_loss: 0.1325\n",
      "[15,    51] train_loss: 0.6320 | val_loss: 0.1321\n",
      "[16,    51] train_loss: 0.6180 | val_loss: 0.1303\n",
      "[17,    51] train_loss: 0.6414 | val_loss: 0.1392\n",
      "[18,    51] train_loss: 0.6400 | val_loss: 0.1363\n",
      "[19,    51] train_loss: 0.6125 | val_loss: 0.1337\n",
      "[20,    51] train_loss: 0.6176 | val_loss: 0.1288\n",
      "[21,    51] train_loss: 0.6517 | val_loss: 0.1350\n",
      "[22,    51] train_loss: 0.6172 | val_loss: 0.1433\n",
      "[23,    51] train_loss: 0.6298 | val_loss: 0.1286\n",
      "[24,    51] train_loss: 0.6225 | val_loss: 0.1253\n",
      "[25,    51] train_loss: 0.6180 | val_loss: 0.1317\n",
      "[26,    51] train_loss: 0.6250 | val_loss: 0.1326\n",
      "[27,    51] train_loss: 0.6335 | val_loss: 0.1321\n",
      "[28,    51] train_loss: 0.6191 | val_loss: 0.1258\n",
      "[29,    51] train_loss: 0.5957 | val_loss: 0.1313\n",
      "[30,    51] train_loss: 0.5977 | val_loss: 0.1382\n",
      "[31,    51] train_loss: 0.6331 | val_loss: 0.1279\n",
      "[32,    51] train_loss: 0.6191 | val_loss: 0.1258\n",
      "[33,    51] train_loss: 0.6383 | val_loss: 0.1336\n",
      "[34,    51] train_loss: 0.6227 | val_loss: 0.1331\n",
      "[35,    51] train_loss: 0.6146 | val_loss: 0.1296\n",
      "[36,    51] train_loss: 0.6139 | val_loss: 0.1271\n",
      "[37,    51] train_loss: 0.6123 | val_loss: 0.1364\n",
      "[38,    51] train_loss: 0.6273 | val_loss: 0.1366\n",
      "[39,    51] train_loss: 0.6354 | val_loss: 0.1325\n",
      "[40,    51] train_loss: 0.6167 | val_loss: 0.1289\n",
      "[41,    51] train_loss: 0.5985 | val_loss: 0.1334\n",
      "[42,    51] train_loss: 0.6152 | val_loss: 0.1335\n",
      "[43,    51] train_loss: 0.6303 | val_loss: 0.1338\n",
      "[44,    51] train_loss: 0.6167 | val_loss: 0.1384\n",
      "[45,    51] train_loss: 0.6302 | val_loss: 0.1320\n",
      "[46,    51] train_loss: 0.6196 | val_loss: 0.1328\n",
      "[47,    51] train_loss: 0.6076 | val_loss: 0.1336\n",
      "[48,    51] train_loss: 0.6342 | val_loss: 0.1373\n",
      "[49,    51] train_loss: 0.6209 | val_loss: 0.1297\n",
      "[50,    51] train_loss: 0.6079 | val_loss: 0.1297\n",
      "Saving checkpoint 50\n",
      "[51,    51] train_loss: 0.6312 | val_loss: 0.1347\n",
      "[52,    51] train_loss: 0.6263 | val_loss: 0.1306\n",
      "[53,    51] train_loss: 0.6255 | val_loss: 0.1356\n",
      "[54,    51] train_loss: 0.6254 | val_loss: 0.1334\n",
      "[55,    51] train_loss: 0.6084 | val_loss: 0.1314\n",
      "[56,    51] train_loss: 0.6221 | val_loss: 0.1306\n",
      "[57,    51] train_loss: 0.6077 | val_loss: 0.1318\n",
      "[58,    51] train_loss: 0.6227 | val_loss: 0.1326\n",
      "[59,    51] train_loss: 0.6346 | val_loss: 0.1391\n",
      "[60,    51] train_loss: 0.6339 | val_loss: 0.1311\n",
      "[61,    51] train_loss: 0.5980 | val_loss: 0.1287\n",
      "[62,    51] train_loss: 0.6012 | val_loss: 0.1322\n",
      "[63,    51] train_loss: 0.6064 | val_loss: 0.1332\n",
      "[64,    51] train_loss: 0.6089 | val_loss: 0.1335\n",
      "[65,    51] train_loss: 0.6241 | val_loss: 0.1258\n",
      "[66,    51] train_loss: 0.6141 | val_loss: 0.1287\n",
      "[67,    51] train_loss: 0.6131 | val_loss: 0.1312\n",
      "[68,    51] train_loss: 0.6192 | val_loss: 0.1267\n",
      "[69,    51] train_loss: 0.6020 | val_loss: 0.1299\n",
      "[70,    51] train_loss: 0.6192 | val_loss: 0.1320\n",
      "[71,    51] train_loss: 0.6064 | val_loss: 0.1330\n",
      "[72,    51] train_loss: 0.6129 | val_loss: 0.1320\n",
      "[73,    51] train_loss: 0.6098 | val_loss: 0.1303\n",
      "[74,    51] train_loss: 0.6082 | val_loss: 0.1333\n",
      "[75,    51] train_loss: 0.6067 | val_loss: 0.1296\n",
      "[76,    51] train_loss: 0.6213 | val_loss: 0.1279\n",
      "[77,    51] train_loss: 0.6046 | val_loss: 0.1329\n",
      "[78,    51] train_loss: 0.6120 | val_loss: 0.1303\n",
      "[79,    51] train_loss: 0.5960 | val_loss: 0.1279\n",
      "[80,    51] train_loss: 0.6056 | val_loss: 0.1330\n",
      "[81,    51] train_loss: 0.6189 | val_loss: 0.1289\n",
      "[82,    51] train_loss: 0.6201 | val_loss: 0.1339\n",
      "[83,    51] train_loss: 0.6192 | val_loss: 0.1282\n",
      "[84,    51] train_loss: 0.6250 | val_loss: 0.1365\n",
      "[85,    51] train_loss: 0.6240 | val_loss: 0.1314\n",
      "[86,    51] train_loss: 0.6209 | val_loss: 0.1283\n",
      "[87,    51] train_loss: 0.5971 | val_loss: 0.1339\n",
      "[88,    51] train_loss: 0.6263 | val_loss: 0.1328\n",
      "[89,    51] train_loss: 0.6236 | val_loss: 0.1300\n",
      "[90,    51] train_loss: 0.6121 | val_loss: 0.1277\n",
      "[91,    51] train_loss: 0.6291 | val_loss: 0.1299\n",
      "[92,    51] train_loss: 0.6313 | val_loss: 0.1349\n",
      "[93,    51] train_loss: 0.6172 | val_loss: 0.1302\n",
      "[94,    51] train_loss: 0.6205 | val_loss: 0.1354\n",
      "[95,    51] train_loss: 0.6241 | val_loss: 0.1376\n",
      "[96,    51] train_loss: 0.6278 | val_loss: 0.1302\n",
      "[97,    51] train_loss: 0.6161 | val_loss: 0.1359\n",
      "[98,    51] train_loss: 0.6341 | val_loss: 0.1300\n",
      "[99,    51] train_loss: 0.6428 | val_loss: 0.1349\n",
      "[100,    51] train_loss: 0.6127 | val_loss: 0.1331\n",
      "Saving checkpoint 100\n",
      "[101,    51] train_loss: 0.6094 | val_loss: 0.1352\n",
      "[102,    51] train_loss: 0.6190 | val_loss: 0.1348\n",
      "[103,    51] train_loss: 0.6256 | val_loss: 0.1268\n",
      "[104,    51] train_loss: 0.6334 | val_loss: 0.1311\n",
      "[105,    51] train_loss: 0.6137 | val_loss: 0.1335\n",
      "[106,    51] train_loss: 0.6144 | val_loss: 0.1310\n",
      "[107,    51] train_loss: 0.6001 | val_loss: 0.1331\n",
      "[108,    51] train_loss: 0.6159 | val_loss: 0.1305\n",
      "[109,    51] train_loss: 0.6081 | val_loss: 0.1289\n",
      "[110,    51] train_loss: 0.6034 | val_loss: 0.1293\n",
      "[111,    51] train_loss: 0.6055 | val_loss: 0.1269\n",
      "[112,    51] train_loss: 0.6071 | val_loss: 0.1274\n",
      "[113,    51] train_loss: 0.6077 | val_loss: 0.1259\n",
      "[114,    51] train_loss: 0.6012 | val_loss: 0.1258\n",
      "[115,    51] train_loss: 0.6031 | val_loss: 0.1273\n",
      "[116,    51] train_loss: 0.5760 | val_loss: 0.1227\n",
      "[117,    51] train_loss: 0.5936 | val_loss: 0.1250\n",
      "[118,    51] train_loss: 0.5794 | val_loss: 0.1232\n",
      "[119,    51] train_loss: 0.5667 | val_loss: 0.1205\n",
      "[120,    51] train_loss: 0.5666 | val_loss: 0.1217\n",
      "[121,    51] train_loss: 0.5754 | val_loss: 0.1190\n",
      "[122,    51] train_loss: 0.5776 | val_loss: 0.1226\n",
      "[123,    51] train_loss: 0.5756 | val_loss: 0.1209\n",
      "[124,    51] train_loss: 0.5764 | val_loss: 0.1199\n",
      "[125,    51] train_loss: 0.5557 | val_loss: 0.1186\n",
      "[126,    51] train_loss: 0.5613 | val_loss: 0.1211\n",
      "[127,    51] train_loss: 0.5491 | val_loss: 0.1196\n",
      "[128,    51] train_loss: 0.5650 | val_loss: 0.1182\n",
      "[129,    51] train_loss: 0.5665 | val_loss: 0.1160\n",
      "[130,    51] train_loss: 0.5557 | val_loss: 0.1183\n",
      "[131,    51] train_loss: 0.5616 | val_loss: 0.1194\n",
      "[132,    51] train_loss: 0.5634 | val_loss: 0.1208\n",
      "[133,    51] train_loss: 0.5611 | val_loss: 0.1187\n",
      "[134,    51] train_loss: 0.5709 | val_loss: 0.1192\n",
      "[135,    51] train_loss: 0.5567 | val_loss: 0.1163\n",
      "[136,    51] train_loss: 0.5542 | val_loss: 0.1203\n",
      "[137,    51] train_loss: 0.5818 | val_loss: 0.1171\n",
      "[138,    51] train_loss: 0.5411 | val_loss: 0.1175\n",
      "[139,    51] train_loss: 0.5552 | val_loss: 0.1183\n",
      "[140,    51] train_loss: 0.5396 | val_loss: 0.1136\n",
      "[141,    51] train_loss: 0.5399 | val_loss: 0.1169\n",
      "[142,    51] train_loss: 0.5531 | val_loss: 0.1176\n",
      "[143,    51] train_loss: 0.5468 | val_loss: 0.1154\n",
      "[144,    51] train_loss: 0.5425 | val_loss: 0.1162\n",
      "[145,    51] train_loss: 0.5402 | val_loss: 0.1153\n",
      "[146,    51] train_loss: 0.5425 | val_loss: 0.1151\n",
      "[147,    51] train_loss: 0.5439 | val_loss: 0.1159\n",
      "[148,    51] train_loss: 0.5353 | val_loss: 0.1159\n",
      "[149,    51] train_loss: 0.5430 | val_loss: 0.1150\n",
      "[150,    51] train_loss: 0.5395 | val_loss: 0.1153\n",
      "Saving checkpoint 150\n",
      "[151,    51] train_loss: 0.5413 | val_loss: 0.1163\n",
      "[152,    51] train_loss: 0.5476 | val_loss: 0.1156\n",
      "[153,    51] train_loss: 0.5522 | val_loss: 0.1164\n",
      "[154,    51] train_loss: 0.5430 | val_loss: 0.1146\n",
      "[155,    51] train_loss: 0.5394 | val_loss: 0.1161\n",
      "[156,    51] train_loss: 0.5441 | val_loss: 0.1152\n",
      "[157,    51] train_loss: 0.5431 | val_loss: 0.1161\n",
      "[158,    51] train_loss: 0.5450 | val_loss: 0.1163\n",
      "[159,    51] train_loss: 0.5352 | val_loss: 0.1155\n",
      "[160,    51] train_loss: 0.5400 | val_loss: 0.1156\n",
      "[161,    51] train_loss: 0.5405 | val_loss: 0.1162\n",
      "[162,    51] train_loss: 0.5444 | val_loss: 0.1147\n",
      "[163,    51] train_loss: 0.5469 | val_loss: 0.1155\n",
      "[164,    51] train_loss: 0.5405 | val_loss: 0.1135\n",
      "[165,    51] train_loss: 0.5321 | val_loss: 0.1161\n",
      "[166,    51] train_loss: 0.5423 | val_loss: 0.1139\n",
      "[167,    51] train_loss: 0.5455 | val_loss: 0.1157\n",
      "[168,    51] train_loss: 0.5398 | val_loss: 0.1139\n",
      "[169,    51] train_loss: 0.5388 | val_loss: 0.1147\n",
      "[170,    51] train_loss: 0.5531 | val_loss: 0.1138\n",
      "[171,    51] train_loss: 0.5480 | val_loss: 0.1150\n",
      "[172,    51] train_loss: 0.5370 | val_loss: 0.1150\n",
      "[173,    51] train_loss: 0.5401 | val_loss: 0.1126\n",
      "[174,    51] train_loss: 0.5332 | val_loss: 0.1153\n",
      "[175,    51] train_loss: 0.5414 | val_loss: 0.1128\n",
      "[176,    51] train_loss: 0.5375 | val_loss: 0.1150\n",
      "[177,    51] train_loss: 0.5405 | val_loss: 0.1134\n",
      "[178,    51] train_loss: 0.5387 | val_loss: 0.1140\n",
      "[179,    51] train_loss: 0.5415 | val_loss: 0.1145\n",
      "[180,    51] train_loss: 0.5356 | val_loss: 0.1128\n",
      "[181,    51] train_loss: 0.5262 | val_loss: 0.1142\n",
      "[182,    51] train_loss: 0.5364 | val_loss: 0.1139\n",
      "[183,    51] train_loss: 0.5266 | val_loss: 0.1149\n",
      "[184,    51] train_loss: 0.5269 | val_loss: 0.1147\n",
      "[185,    51] train_loss: 0.5407 | val_loss: 0.1137\n",
      "[186,    51] train_loss: 0.5416 | val_loss: 0.1137\n",
      "[187,    51] train_loss: 0.5246 | val_loss: 0.1143\n",
      "[188,    51] train_loss: 0.5386 | val_loss: 0.1148\n",
      "[189,    51] train_loss: 0.5411 | val_loss: 0.1148\n",
      "[190,    51] train_loss: 0.5425 | val_loss: 0.1146\n",
      "[191,    51] train_loss: 0.5270 | val_loss: 0.1134\n",
      "[192,    51] train_loss: 0.5258 | val_loss: 0.1126\n",
      "[193,    51] train_loss: 0.5403 | val_loss: 0.1133\n",
      "[194,    51] train_loss: 0.5409 | val_loss: 0.1137\n",
      "[195,    51] train_loss: 0.5410 | val_loss: 0.1128\n",
      "[196,    51] train_loss: 0.5399 | val_loss: 0.1141\n",
      "[197,    51] train_loss: 0.5388 | val_loss: 0.1132\n",
      "[198,    51] train_loss: 0.5332 | val_loss: 0.1142\n",
      "[199,    51] train_loss: 0.5346 | val_loss: 0.1135\n",
      "[200,    51] train_loss: 0.5351 | val_loss: 0.1155\n",
      "Saving checkpoint 200\n",
      "[201,    51] train_loss: 0.5257 | val_loss: 0.1143\n",
      "[202,    51] train_loss: 0.5389 | val_loss: 0.1146\n",
      "[203,    51] train_loss: 0.5481 | val_loss: 0.1130\n",
      "[204,    51] train_loss: 0.5342 | val_loss: 0.1138\n",
      "[205,    51] train_loss: 0.5417 | val_loss: 0.1142\n",
      "[206,    51] train_loss: 0.5363 | val_loss: 0.1126\n",
      "[207,    51] train_loss: 0.5274 | val_loss: 0.1157\n",
      "[208,    51] train_loss: 0.5429 | val_loss: 0.1125\n",
      "[209,    51] train_loss: 0.5354 | val_loss: 0.1144\n",
      "[210,    51] train_loss: 0.5356 | val_loss: 0.1124\n",
      "[211,    51] train_loss: 0.5248 | val_loss: 0.1148\n",
      "[212,    51] train_loss: 0.5347 | val_loss: 0.1127\n",
      "[213,    51] train_loss: 0.5371 | val_loss: 0.1134\n",
      "[214,    51] train_loss: 0.5366 | val_loss: 0.1122\n",
      "[215,    51] train_loss: 0.5366 | val_loss: 0.1129\n",
      "[216,    51] train_loss: 0.5340 | val_loss: 0.1130\n",
      "[217,    51] train_loss: 0.5309 | val_loss: 0.1146\n",
      "[218,    51] train_loss: 0.5362 | val_loss: 0.1132\n",
      "[219,    51] train_loss: 0.5358 | val_loss: 0.1122\n",
      "[220,    51] train_loss: 0.5233 | val_loss: 0.1141\n",
      "[221,    51] train_loss: 0.5315 | val_loss: 0.1123\n",
      "[222,    51] train_loss: 0.5236 | val_loss: 0.1132\n",
      "[223,    51] train_loss: 0.5328 | val_loss: 0.1137\n",
      "[224,    51] train_loss: 0.5230 | val_loss: 0.1142\n",
      "[225,    51] train_loss: 0.5402 | val_loss: 0.1135\n",
      "[226,    51] train_loss: 0.5337 | val_loss: 0.1129\n",
      "[227,    51] train_loss: 0.5218 | val_loss: 0.1126\n",
      "[228,    51] train_loss: 0.5444 | val_loss: 0.1128\n",
      "[229,    51] train_loss: 0.5258 | val_loss: 0.1133\n",
      "[230,    51] train_loss: 0.5342 | val_loss: 0.1129\n",
      "[231,    51] train_loss: 0.5365 | val_loss: 0.1116\n",
      "[232,    51] train_loss: 0.5328 | val_loss: 0.1113\n",
      "[233,    51] train_loss: 0.5276 | val_loss: 0.1129\n",
      "[234,    51] train_loss: 0.5353 | val_loss: 0.1133\n",
      "[235,    51] train_loss: 0.5316 | val_loss: 0.1131\n",
      "[236,    51] train_loss: 0.5302 | val_loss: 0.1140\n",
      "[237,    51] train_loss: 0.5332 | val_loss: 0.1139\n",
      "[238,    51] train_loss: 0.5241 | val_loss: 0.1124\n",
      "[239,    51] train_loss: 0.5276 | val_loss: 0.1118\n",
      "[240,    51] train_loss: 0.5349 | val_loss: 0.1139\n",
      "[241,    51] train_loss: 0.5357 | val_loss: 0.1129\n",
      "[242,    51] train_loss: 0.5195 | val_loss: 0.1122\n",
      "[243,    51] train_loss: 0.5302 | val_loss: 0.1139\n",
      "[244,    51] train_loss: 0.5400 | val_loss: 0.1143\n",
      "[245,    51] train_loss: 0.5205 | val_loss: 0.1126\n",
      "[246,    51] train_loss: 0.5303 | val_loss: 0.1132\n",
      "[247,    51] train_loss: 0.5321 | val_loss: 0.1138\n",
      "[248,    51] train_loss: 0.5368 | val_loss: 0.1128\n",
      "[249,    51] train_loss: 0.5332 | val_loss: 0.1143\n",
      "[250,    51] train_loss: 0.5317 | val_loss: 0.1139\n",
      "Saving checkpoint 250\n",
      "[251,    51] train_loss: 0.5404 | val_loss: 0.1130\n",
      "[252,    51] train_loss: 0.5320 | val_loss: 0.1140\n",
      "[253,    51] train_loss: 0.5291 | val_loss: 0.1149\n",
      "[254,    51] train_loss: 0.5300 | val_loss: 0.1141\n",
      "[255,    51] train_loss: 0.5340 | val_loss: 0.1128\n",
      "[256,    51] train_loss: 0.5361 | val_loss: 0.1114\n",
      "[257,    51] train_loss: 0.5352 | val_loss: 0.1140\n",
      "[258,    51] train_loss: 0.5303 | val_loss: 0.1139\n",
      "[259,    51] train_loss: 0.5378 | val_loss: 0.1149\n",
      "[260,    51] train_loss: 0.5289 | val_loss: 0.1135\n",
      "[261,    51] train_loss: 0.5319 | val_loss: 0.1134\n",
      "[262,    51] train_loss: 0.5266 | val_loss: 0.1134\n",
      "[263,    51] train_loss: 0.5350 | val_loss: 0.1125\n",
      "[264,    51] train_loss: 0.5283 | val_loss: 0.1140\n",
      "[265,    51] train_loss: 0.5337 | val_loss: 0.1137\n",
      "[266,    51] train_loss: 0.5298 | val_loss: 0.1127\n",
      "[267,    51] train_loss: 0.5406 | val_loss: 0.1129\n",
      "[268,    51] train_loss: 0.5375 | val_loss: 0.1156\n",
      "[269,    51] train_loss: 0.5258 | val_loss: 0.1128\n",
      "[270,    51] train_loss: 0.5314 | val_loss: 0.1120\n",
      "[271,    51] train_loss: 0.5352 | val_loss: 0.1135\n",
      "[272,    51] train_loss: 0.5374 | val_loss: 0.1130\n",
      "[273,    51] train_loss: 0.5304 | val_loss: 0.1155\n",
      "[274,    51] train_loss: 0.5366 | val_loss: 0.1141\n",
      "[275,    51] train_loss: 0.5209 | val_loss: 0.1141\n",
      "[276,    51] train_loss: 0.5375 | val_loss: 0.1131\n",
      "[277,    51] train_loss: 0.5317 | val_loss: 0.1131\n",
      "[278,    51] train_loss: 0.5333 | val_loss: 0.1113\n",
      "[279,    51] train_loss: 0.5426 | val_loss: 0.1152\n",
      "[280,    51] train_loss: 0.5340 | val_loss: 0.1149\n",
      "[281,    51] train_loss: 0.5318 | val_loss: 0.1123\n",
      "[282,    51] train_loss: 0.5238 | val_loss: 0.1098\n",
      "[283,    51] train_loss: 0.5367 | val_loss: 0.1131\n",
      "[284,    51] train_loss: 0.5354 | val_loss: 0.1126\n",
      "[285,    51] train_loss: 0.5269 | val_loss: 0.1128\n",
      "[286,    51] train_loss: 0.5394 | val_loss: 0.1135\n",
      "[287,    51] train_loss: 0.5298 | val_loss: 0.1123\n",
      "[288,    51] train_loss: 0.5235 | val_loss: 0.1131\n",
      "[289,    51] train_loss: 0.5309 | val_loss: 0.1146\n",
      "[290,    51] train_loss: 0.5335 | val_loss: 0.1145\n",
      "[291,    51] train_loss: 0.5355 | val_loss: 0.1133\n",
      "[292,    51] train_loss: 0.5337 | val_loss: 0.1134\n",
      "[293,    51] train_loss: 0.5212 | val_loss: 0.1115\n",
      "[294,    51] train_loss: 0.5318 | val_loss: 0.1113\n",
      "[295,    51] train_loss: 0.5253 | val_loss: 0.1133\n",
      "[296,    51] train_loss: 0.5259 | val_loss: 0.1121\n",
      "[297,    51] train_loss: 0.5373 | val_loss: 0.1132\n",
      "[298,    51] train_loss: 0.5259 | val_loss: 0.1118\n",
      "[299,    51] train_loss: 0.5315 | val_loss: 0.1133\n",
      "[300,    51] train_loss: 0.5191 | val_loss: 0.1146\n",
      "Saving checkpoint 300\n",
      "[301,    51] train_loss: 0.5303 | val_loss: 0.1121\n",
      "[302,    51] train_loss: 0.5347 | val_loss: 0.1146\n",
      "[303,    51] train_loss: 0.5317 | val_loss: 0.1134\n",
      "[304,    51] train_loss: 0.5371 | val_loss: 0.1123\n",
      "[305,    51] train_loss: 0.5321 | val_loss: 0.1140\n",
      "[306,    51] train_loss: 0.5323 | val_loss: 0.1122\n",
      "[307,    51] train_loss: 0.5236 | val_loss: 0.1110\n",
      "[308,    51] train_loss: 0.5297 | val_loss: 0.1132\n",
      "[309,    51] train_loss: 0.5227 | val_loss: 0.1123\n",
      "[310,    51] train_loss: 0.5188 | val_loss: 0.1119\n",
      "[311,    51] train_loss: 0.5226 | val_loss: 0.1110\n",
      "[312,    51] train_loss: 0.5340 | val_loss: 0.1141\n",
      "[313,    51] train_loss: 0.5257 | val_loss: 0.1130\n",
      "[314,    51] train_loss: 0.5309 | val_loss: 0.1125\n",
      "[315,    51] train_loss: 0.5318 | val_loss: 0.1140\n",
      "[316,    51] train_loss: 0.5359 | val_loss: 0.1139\n",
      "[317,    51] train_loss: 0.5313 | val_loss: 0.1117\n",
      "[318,    51] train_loss: 0.5373 | val_loss: 0.1145\n",
      "[319,    51] train_loss: 0.5294 | val_loss: 0.1155\n",
      "[320,    51] train_loss: 0.5284 | val_loss: 0.1112\n",
      "[321,    51] train_loss: 0.5309 | val_loss: 0.1123\n",
      "[322,    51] train_loss: 0.5282 | val_loss: 0.1139\n",
      "[323,    51] train_loss: 0.5300 | val_loss: 0.1130\n",
      "[324,    51] train_loss: 0.5448 | val_loss: 0.1127\n",
      "[325,    51] train_loss: 0.5265 | val_loss: 0.1155\n",
      "[326,    51] train_loss: 0.5313 | val_loss: 0.1114\n",
      "[327,    51] train_loss: 0.5282 | val_loss: 0.1122\n",
      "[328,    51] train_loss: 0.5199 | val_loss: 0.1141\n",
      "[329,    51] train_loss: 0.5328 | val_loss: 0.1122\n",
      "[330,    51] train_loss: 0.5298 | val_loss: 0.1127\n",
      "[331,    51] train_loss: 0.5239 | val_loss: 0.1128\n",
      "[332,    51] train_loss: 0.5318 | val_loss: 0.1126\n",
      "[333,    51] train_loss: 0.5346 | val_loss: 0.1129\n",
      "[334,    51] train_loss: 0.5305 | val_loss: 0.1135\n",
      "[335,    51] train_loss: 0.5332 | val_loss: 0.1142\n",
      "[336,    51] train_loss: 0.5259 | val_loss: 0.1134\n",
      "[337,    51] train_loss: 0.5364 | val_loss: 0.1119\n",
      "[338,    51] train_loss: 0.5201 | val_loss: 0.1148\n",
      "[339,    51] train_loss: 0.5319 | val_loss: 0.1130\n",
      "[340,    51] train_loss: 0.5327 | val_loss: 0.1122\n",
      "[341,    51] train_loss: 0.5284 | val_loss: 0.1116\n",
      "[342,    51] train_loss: 0.5367 | val_loss: 0.1125\n",
      "[343,    51] train_loss: 0.5228 | val_loss: 0.1110\n",
      "[344,    51] train_loss: 0.5184 | val_loss: 0.1138\n",
      "[345,    51] train_loss: 0.5270 | val_loss: 0.1129\n",
      "[346,    51] train_loss: 0.5310 | val_loss: 0.1129\n",
      "[347,    51] train_loss: 0.5187 | val_loss: 0.1128\n",
      "[348,    51] train_loss: 0.5264 | val_loss: 0.1135\n",
      "[349,    51] train_loss: 0.5335 | val_loss: 0.1114\n",
      "[350,    51] train_loss: 0.5341 | val_loss: 0.1147\n",
      "Saving checkpoint 350\n",
      "[351,    51] train_loss: 0.5336 | val_loss: 0.1120\n",
      "[352,    51] train_loss: 0.5307 | val_loss: 0.1133\n",
      "[353,    51] train_loss: 0.5352 | val_loss: 0.1120\n",
      "[354,    51] train_loss: 0.5339 | val_loss: 0.1139\n",
      "[355,    51] train_loss: 0.5319 | val_loss: 0.1129\n",
      "[356,    51] train_loss: 0.5225 | val_loss: 0.1129\n",
      "[357,    51] train_loss: 0.5295 | val_loss: 0.1140\n",
      "[358,    51] train_loss: 0.5251 | val_loss: 0.1136\n",
      "[359,    51] train_loss: 0.5357 | val_loss: 0.1134\n",
      "[360,    51] train_loss: 0.5297 | val_loss: 0.1120\n",
      "[361,    51] train_loss: 0.5323 | val_loss: 0.1101\n",
      "[362,    51] train_loss: 0.5289 | val_loss: 0.1118\n",
      "[363,    51] train_loss: 0.5427 | val_loss: 0.1125\n",
      "[364,    51] train_loss: 0.5136 | val_loss: 0.1128\n",
      "[365,    51] train_loss: 0.5337 | val_loss: 0.1116\n",
      "[366,    51] train_loss: 0.5341 | val_loss: 0.1126\n",
      "[367,    51] train_loss: 0.5364 | val_loss: 0.1136\n",
      "[368,    51] train_loss: 0.5329 | val_loss: 0.1144\n",
      "[369,    51] train_loss: 0.5265 | val_loss: 0.1114\n",
      "[370,    51] train_loss: 0.5164 | val_loss: 0.1128\n",
      "[371,    51] train_loss: 0.5332 | val_loss: 0.1134\n",
      "[372,    51] train_loss: 0.5324 | val_loss: 0.1152\n",
      "[373,    51] train_loss: 0.5314 | val_loss: 0.1125\n",
      "[374,    51] train_loss: 0.5370 | val_loss: 0.1130\n",
      "[375,    51] train_loss: 0.5275 | val_loss: 0.1128\n",
      "[376,    51] train_loss: 0.5233 | val_loss: 0.1117\n",
      "[377,    51] train_loss: 0.5271 | val_loss: 0.1157\n",
      "[378,    51] train_loss: 0.5327 | val_loss: 0.1116\n",
      "[379,    51] train_loss: 0.5279 | val_loss: 0.1139\n",
      "[380,    51] train_loss: 0.5332 | val_loss: 0.1151\n",
      "[381,    51] train_loss: 0.5312 | val_loss: 0.1144\n",
      "[382,    51] train_loss: 0.5302 | val_loss: 0.1118\n",
      "[383,    51] train_loss: 0.5397 | val_loss: 0.1143\n",
      "[384,    51] train_loss: 0.5319 | val_loss: 0.1124\n",
      "[385,    51] train_loss: 0.5208 | val_loss: 0.1119\n",
      "[386,    51] train_loss: 0.5329 | val_loss: 0.1118\n",
      "[387,    51] train_loss: 0.5366 | val_loss: 0.1136\n",
      "[388,    51] train_loss: 0.5281 | val_loss: 0.1110\n",
      "[389,    51] train_loss: 0.5362 | val_loss: 0.1119\n",
      "[390,    51] train_loss: 0.5313 | val_loss: 0.1147\n",
      "[391,    51] train_loss: 0.5282 | val_loss: 0.1145\n",
      "[392,    51] train_loss: 0.5310 | val_loss: 0.1132\n",
      "[393,    51] train_loss: 0.5260 | val_loss: 0.1139\n",
      "[394,    51] train_loss: 0.5341 | val_loss: 0.1141\n",
      "[395,    51] train_loss: 0.5307 | val_loss: 0.1147\n",
      "[396,    51] train_loss: 0.5371 | val_loss: 0.1120\n",
      "[397,    51] train_loss: 0.5160 | val_loss: 0.1143\n",
      "[398,    51] train_loss: 0.5181 | val_loss: 0.1140\n",
      "[399,    51] train_loss: 0.5322 | val_loss: 0.1130\n",
      "[400,    51] train_loss: 0.5336 | val_loss: 0.1111\n",
      "Saving checkpoint 400\n",
      "[401,    51] train_loss: 0.5322 | val_loss: 0.1122\n",
      "[402,    51] train_loss: 0.5233 | val_loss: 0.1132\n",
      "[403,    51] train_loss: 0.5327 | val_loss: 0.1152\n",
      "[404,    51] train_loss: 0.5323 | val_loss: 0.1150\n",
      "[405,    51] train_loss: 0.5315 | val_loss: 0.1141\n",
      "[406,    51] train_loss: 0.5314 | val_loss: 0.1128\n",
      "[407,    51] train_loss: 0.5294 | val_loss: 0.1134\n",
      "[408,    51] train_loss: 0.5293 | val_loss: 0.1117\n",
      "[409,    51] train_loss: 0.5281 | val_loss: 0.1126\n",
      "[410,    51] train_loss: 0.5323 | val_loss: 0.1131\n",
      "[411,    51] train_loss: 0.5323 | val_loss: 0.1114\n",
      "[412,    51] train_loss: 0.5267 | val_loss: 0.1129\n",
      "[413,    51] train_loss: 0.5337 | val_loss: 0.1117\n",
      "[414,    51] train_loss: 0.5225 | val_loss: 0.1124\n",
      "[415,    51] train_loss: 0.5283 | val_loss: 0.1130\n",
      "[416,    51] train_loss: 0.5304 | val_loss: 0.1135\n",
      "[417,    51] train_loss: 0.5250 | val_loss: 0.1148\n",
      "[418,    51] train_loss: 0.5329 | val_loss: 0.1137\n",
      "[419,    51] train_loss: 0.5386 | val_loss: 0.1129\n",
      "[420,    51] train_loss: 0.5203 | val_loss: 0.1138\n",
      "[421,    51] train_loss: 0.5366 | val_loss: 0.1131\n",
      "[422,    51] train_loss: 0.5322 | val_loss: 0.1135\n",
      "[423,    51] train_loss: 0.5182 | val_loss: 0.1125\n",
      "[424,    51] train_loss: 0.5234 | val_loss: 0.1141\n",
      "[425,    51] train_loss: 0.5312 | val_loss: 0.1137\n",
      "[426,    51] train_loss: 0.5303 | val_loss: 0.1128\n",
      "[427,    51] train_loss: 0.5353 | val_loss: 0.1111\n",
      "[428,    51] train_loss: 0.5297 | val_loss: 0.1130\n",
      "[429,    51] train_loss: 0.5228 | val_loss: 0.1122\n",
      "[430,    51] train_loss: 0.5354 | val_loss: 0.1118\n",
      "[431,    51] train_loss: 0.5303 | val_loss: 0.1123\n",
      "[432,    51] train_loss: 0.5292 | val_loss: 0.1131\n",
      "[433,    51] train_loss: 0.5175 | val_loss: 0.1132\n",
      "[434,    51] train_loss: 0.5228 | val_loss: 0.1128\n",
      "[435,    51] train_loss: 0.5386 | val_loss: 0.1150\n",
      "[436,    51] train_loss: 0.5354 | val_loss: 0.1135\n",
      "[437,    51] train_loss: 0.5250 | val_loss: 0.1119\n",
      "[438,    51] train_loss: 0.5230 | val_loss: 0.1141\n",
      "[439,    51] train_loss: 0.5307 | val_loss: 0.1133\n",
      "[440,    51] train_loss: 0.5200 | val_loss: 0.1115\n",
      "[441,    51] train_loss: 0.5269 | val_loss: 0.1141\n",
      "[442,    51] train_loss: 0.5224 | val_loss: 0.1141\n",
      "[443,    51] train_loss: 0.5221 | val_loss: 0.1122\n",
      "[444,    51] train_loss: 0.5322 | val_loss: 0.1119\n",
      "[445,    51] train_loss: 0.5269 | val_loss: 0.1132\n",
      "[446,    51] train_loss: 0.5363 | val_loss: 0.1127\n",
      "[447,    51] train_loss: 0.5298 | val_loss: 0.1145\n",
      "[448,    51] train_loss: 0.5170 | val_loss: 0.1132\n",
      "[449,    51] train_loss: 0.5314 | val_loss: 0.1132\n",
      "[450,    51] train_loss: 0.5268 | val_loss: 0.1144\n",
      "Saving checkpoint 450\n",
      "[451,    51] train_loss: 0.5352 | val_loss: 0.1152\n",
      "[452,    51] train_loss: 0.5391 | val_loss: 0.1155\n",
      "[453,    51] train_loss: 0.5304 | val_loss: 0.1142\n",
      "[454,    51] train_loss: 0.5297 | val_loss: 0.1128\n",
      "[455,    51] train_loss: 0.5293 | val_loss: 0.1124\n",
      "[456,    51] train_loss: 0.5351 | val_loss: 0.1141\n",
      "[457,    51] train_loss: 0.5271 | val_loss: 0.1107\n",
      "[458,    51] train_loss: 0.5283 | val_loss: 0.1118\n",
      "[459,    51] train_loss: 0.5188 | val_loss: 0.1133\n",
      "[460,    51] train_loss: 0.5309 | val_loss: 0.1120\n",
      "[461,    51] train_loss: 0.5332 | val_loss: 0.1127\n",
      "[462,    51] train_loss: 0.5305 | val_loss: 0.1123\n",
      "[463,    51] train_loss: 0.5282 | val_loss: 0.1111\n",
      "[464,    51] train_loss: 0.5319 | val_loss: 0.1124\n",
      "[465,    51] train_loss: 0.5180 | val_loss: 0.1123\n",
      "[466,    51] train_loss: 0.5183 | val_loss: 0.1133\n",
      "[467,    51] train_loss: 0.5324 | val_loss: 0.1127\n",
      "[468,    51] train_loss: 0.5337 | val_loss: 0.1114\n",
      "[469,    51] train_loss: 0.5322 | val_loss: 0.1116\n",
      "[470,    51] train_loss: 0.5289 | val_loss: 0.1134\n",
      "[471,    51] train_loss: 0.5272 | val_loss: 0.1132\n",
      "[472,    51] train_loss: 0.5286 | val_loss: 0.1120\n",
      "[473,    51] train_loss: 0.5213 | val_loss: 0.1131\n",
      "[474,    51] train_loss: 0.5372 | val_loss: 0.1138\n",
      "[475,    51] train_loss: 0.5290 | val_loss: 0.1118\n",
      "[476,    51] train_loss: 0.5280 | val_loss: 0.1126\n",
      "[477,    51] train_loss: 0.5276 | val_loss: 0.1131\n",
      "[478,    51] train_loss: 0.5342 | val_loss: 0.1126\n",
      "[479,    51] train_loss: 0.5314 | val_loss: 0.1119\n",
      "[480,    51] train_loss: 0.5343 | val_loss: 0.1123\n",
      "[481,    51] train_loss: 0.5281 | val_loss: 0.1125\n",
      "[482,    51] train_loss: 0.5283 | val_loss: 0.1147\n",
      "[483,    51] train_loss: 0.5224 | val_loss: 0.1112\n",
      "[484,    51] train_loss: 0.5321 | val_loss: 0.1125\n",
      "[485,    51] train_loss: 0.5278 | val_loss: 0.1121\n",
      "[486,    51] train_loss: 0.5331 | val_loss: 0.1129\n",
      "[487,    51] train_loss: 0.5311 | val_loss: 0.1135\n",
      "[488,    51] train_loss: 0.5379 | val_loss: 0.1129\n",
      "[489,    51] train_loss: 0.5273 | val_loss: 0.1130\n",
      "[490,    51] train_loss: 0.5244 | val_loss: 0.1123\n",
      "[491,    51] train_loss: 0.5204 | val_loss: 0.1133\n",
      "[492,    51] train_loss: 0.5306 | val_loss: 0.1120\n",
      "[493,    51] train_loss: 0.5208 | val_loss: 0.1123\n",
      "[494,    51] train_loss: 0.5313 | val_loss: 0.1127\n",
      "[495,    51] train_loss: 0.5368 | val_loss: 0.1127\n",
      "[496,    51] train_loss: 0.5215 | val_loss: 0.1127\n",
      "[497,    51] train_loss: 0.5274 | val_loss: 0.1154\n",
      "[498,    51] train_loss: 0.5283 | val_loss: 0.1125\n",
      "[499,    51] train_loss: 0.5213 | val_loss: 0.1110\n",
      "[500,    51] train_loss: 0.5354 | val_loss: 0.1132\n",
      "Saving checkpoint 500\n",
      "[501,    51] train_loss: 0.5262 | val_loss: 0.1133\n",
      "[502,    51] train_loss: 0.5341 | val_loss: 0.1115\n",
      "[503,    51] train_loss: 0.5329 | val_loss: 0.1138\n",
      "[504,    51] train_loss: 0.5319 | val_loss: 0.1129\n",
      "[505,    51] train_loss: 0.5305 | val_loss: 0.1122\n",
      "[506,    51] train_loss: 0.5331 | val_loss: 0.1128\n",
      "[507,    51] train_loss: 0.5273 | val_loss: 0.1124\n",
      "[508,    51] train_loss: 0.5285 | val_loss: 0.1142\n",
      "[509,    51] train_loss: 0.5294 | val_loss: 0.1137\n",
      "[510,    51] train_loss: 0.5216 | val_loss: 0.1142\n",
      "[511,    51] train_loss: 0.5250 | val_loss: 0.1130\n",
      "[512,    51] train_loss: 0.5201 | val_loss: 0.1117\n",
      "[513,    51] train_loss: 0.5338 | val_loss: 0.1137\n",
      "[514,    51] train_loss: 0.5301 | val_loss: 0.1120\n",
      "[515,    51] train_loss: 0.5300 | val_loss: 0.1118\n",
      "[516,    51] train_loss: 0.5255 | val_loss: 0.1114\n",
      "[517,    51] train_loss: 0.5298 | val_loss: 0.1111\n",
      "[518,    51] train_loss: 0.5226 | val_loss: 0.1131\n",
      "[519,    51] train_loss: 0.5293 | val_loss: 0.1113\n",
      "[520,    51] train_loss: 0.5327 | val_loss: 0.1129\n",
      "[521,    51] train_loss: 0.5326 | val_loss: 0.1118\n",
      "[522,    51] train_loss: 0.5293 | val_loss: 0.1121\n",
      "[523,    51] train_loss: 0.5304 | val_loss: 0.1114\n",
      "[524,    51] train_loss: 0.5171 | val_loss: 0.1127\n",
      "[525,    51] train_loss: 0.5302 | val_loss: 0.1126\n",
      "[526,    51] train_loss: 0.5341 | val_loss: 0.1131\n",
      "[527,    51] train_loss: 0.5360 | val_loss: 0.1122\n",
      "[528,    51] train_loss: 0.5351 | val_loss: 0.1121\n",
      "[529,    51] train_loss: 0.5336 | val_loss: 0.1113\n",
      "[530,    51] train_loss: 0.5349 | val_loss: 0.1139\n",
      "[531,    51] train_loss: 0.5325 | val_loss: 0.1121\n",
      "[532,    51] train_loss: 0.5281 | val_loss: 0.1117\n",
      "[533,    51] train_loss: 0.5322 | val_loss: 0.1108\n",
      "[534,    51] train_loss: 0.5304 | val_loss: 0.1133\n",
      "[535,    51] train_loss: 0.5261 | val_loss: 0.1121\n",
      "[536,    51] train_loss: 0.5193 | val_loss: 0.1152\n",
      "[537,    51] train_loss: 0.5358 | val_loss: 0.1138\n",
      "[538,    51] train_loss: 0.5250 | val_loss: 0.1135\n",
      "[539,    51] train_loss: 0.5272 | val_loss: 0.1130\n",
      "[540,    51] train_loss: 0.5289 | val_loss: 0.1140\n",
      "[541,    51] train_loss: 0.5284 | val_loss: 0.1140\n",
      "[542,    51] train_loss: 0.5273 | val_loss: 0.1130\n",
      "[543,    51] train_loss: 0.5251 | val_loss: 0.1137\n",
      "[544,    51] train_loss: 0.5260 | val_loss: 0.1118\n",
      "[545,    51] train_loss: 0.5276 | val_loss: 0.1146\n",
      "[546,    51] train_loss: 0.5296 | val_loss: 0.1115\n",
      "[547,    51] train_loss: 0.5280 | val_loss: 0.1121\n",
      "[548,    51] train_loss: 0.5309 | val_loss: 0.1111\n",
      "[549,    51] train_loss: 0.5199 | val_loss: 0.1130\n",
      "[550,    51] train_loss: 0.5325 | val_loss: 0.1130\n",
      "Saving checkpoint 550\n",
      "[551,    51] train_loss: 0.5368 | val_loss: 0.1126\n",
      "[552,    51] train_loss: 0.5318 | val_loss: 0.1140\n",
      "[553,    51] train_loss: 0.5285 | val_loss: 0.1122\n",
      "[554,    51] train_loss: 0.5258 | val_loss: 0.1117\n",
      "[555,    51] train_loss: 0.5222 | val_loss: 0.1151\n",
      "[556,    51] train_loss: 0.5313 | val_loss: 0.1117\n",
      "[557,    51] train_loss: 0.5209 | val_loss: 0.1125\n",
      "[558,    51] train_loss: 0.5350 | val_loss: 0.1109\n",
      "[559,    51] train_loss: 0.5243 | val_loss: 0.1122\n",
      "[560,    51] train_loss: 0.5334 | val_loss: 0.1131\n",
      "[561,    51] train_loss: 0.5306 | val_loss: 0.1126\n",
      "[562,    51] train_loss: 0.5292 | val_loss: 0.1141\n",
      "[563,    51] train_loss: 0.5298 | val_loss: 0.1122\n",
      "[564,    51] train_loss: 0.5292 | val_loss: 0.1133\n",
      "[565,    51] train_loss: 0.5345 | val_loss: 0.1107\n",
      "[566,    51] train_loss: 0.5201 | val_loss: 0.1133\n",
      "[567,    51] train_loss: 0.5195 | val_loss: 0.1126\n",
      "[568,    51] train_loss: 0.5310 | val_loss: 0.1119\n",
      "[569,    51] train_loss: 0.5267 | val_loss: 0.1146\n",
      "[570,    51] train_loss: 0.5312 | val_loss: 0.1126\n",
      "[571,    51] train_loss: 0.5330 | val_loss: 0.1113\n",
      "[572,    51] train_loss: 0.5245 | val_loss: 0.1143\n",
      "[573,    51] train_loss: 0.5285 | val_loss: 0.1131\n",
      "[574,    51] train_loss: 0.5177 | val_loss: 0.1120\n",
      "[575,    51] train_loss: 0.5274 | val_loss: 0.1123\n",
      "[576,    51] train_loss: 0.5283 | val_loss: 0.1142\n",
      "[577,    51] train_loss: 0.5270 | val_loss: 0.1102\n",
      "[578,    51] train_loss: 0.5293 | val_loss: 0.1119\n",
      "[579,    51] train_loss: 0.5304 | val_loss: 0.1124\n",
      "[580,    51] train_loss: 0.5305 | val_loss: 0.1118\n",
      "[581,    51] train_loss: 0.5318 | val_loss: 0.1115\n",
      "[582,    51] train_loss: 0.5256 | val_loss: 0.1141\n",
      "[583,    51] train_loss: 0.5335 | val_loss: 0.1134\n",
      "[584,    51] train_loss: 0.5193 | val_loss: 0.1107\n",
      "[585,    51] train_loss: 0.5289 | val_loss: 0.1105\n",
      "[586,    51] train_loss: 0.5355 | val_loss: 0.1112\n",
      "[587,    51] train_loss: 0.5270 | val_loss: 0.1132\n",
      "[588,    51] train_loss: 0.5268 | val_loss: 0.1127\n",
      "[589,    51] train_loss: 0.5328 | val_loss: 0.1137\n",
      "[590,    51] train_loss: 0.5278 | val_loss: 0.1129\n",
      "[591,    51] train_loss: 0.5262 | val_loss: 0.1147\n",
      "[592,    51] train_loss: 0.5370 | val_loss: 0.1130\n",
      "[593,    51] train_loss: 0.5314 | val_loss: 0.1114\n",
      "[594,    51] train_loss: 0.5304 | val_loss: 0.1142\n",
      "[595,    51] train_loss: 0.5259 | val_loss: 0.1141\n",
      "[596,    51] train_loss: 0.5351 | val_loss: 0.1127\n",
      "[597,    51] train_loss: 0.5288 | val_loss: 0.1141\n",
      "[598,    51] train_loss: 0.5185 | val_loss: 0.1131\n",
      "[599,    51] train_loss: 0.5208 | val_loss: 0.1123\n",
      "[600,    51] train_loss: 0.5303 | val_loss: 0.1125\n",
      "Saving checkpoint 600\n",
      "[601,    51] train_loss: 0.5294 | val_loss: 0.1128\n",
      "[602,    51] train_loss: 0.5307 | val_loss: 0.1125\n",
      "[603,    51] train_loss: 0.5272 | val_loss: 0.1114\n",
      "[604,    51] train_loss: 0.5311 | val_loss: 0.1133\n",
      "[605,    51] train_loss: 0.5284 | val_loss: 0.1138\n",
      "[606,    51] train_loss: 0.5279 | val_loss: 0.1138\n",
      "[607,    51] train_loss: 0.5279 | val_loss: 0.1130\n",
      "[608,    51] train_loss: 0.5253 | val_loss: 0.1124\n",
      "[609,    51] train_loss: 0.5301 | val_loss: 0.1122\n",
      "[610,    51] train_loss: 0.5292 | val_loss: 0.1135\n",
      "[611,    51] train_loss: 0.5288 | val_loss: 0.1135\n",
      "[612,    51] train_loss: 0.5266 | val_loss: 0.1105\n",
      "[613,    51] train_loss: 0.5346 | val_loss: 0.1131\n",
      "[614,    51] train_loss: 0.5331 | val_loss: 0.1118\n",
      "[615,    51] train_loss: 0.5231 | val_loss: 0.1148\n",
      "[616,    51] train_loss: 0.5189 | val_loss: 0.1112\n",
      "[617,    51] train_loss: 0.5284 | val_loss: 0.1108\n",
      "[618,    51] train_loss: 0.5285 | val_loss: 0.1129\n",
      "[619,    51] train_loss: 0.5251 | val_loss: 0.1102\n",
      "[620,    51] train_loss: 0.5279 | val_loss: 0.1123\n",
      "[621,    51] train_loss: 0.5299 | val_loss: 0.1113\n",
      "[622,    51] train_loss: 0.5316 | val_loss: 0.1133\n",
      "[623,    51] train_loss: 0.5281 | val_loss: 0.1115\n",
      "[624,    51] train_loss: 0.5309 | val_loss: 0.1123\n",
      "[625,    51] train_loss: 0.5310 | val_loss: 0.1126\n",
      "[626,    51] train_loss: 0.5335 | val_loss: 0.1131\n",
      "[627,    51] train_loss: 0.5278 | val_loss: 0.1126\n",
      "[628,    51] train_loss: 0.5254 | val_loss: 0.1140\n",
      "[629,    51] train_loss: 0.5235 | val_loss: 0.1126\n",
      "[630,    51] train_loss: 0.5285 | val_loss: 0.1122\n",
      "[631,    51] train_loss: 0.5355 | val_loss: 0.1123\n",
      "[632,    51] train_loss: 0.5298 | val_loss: 0.1127\n",
      "[633,    51] train_loss: 0.5316 | val_loss: 0.1136\n",
      "[634,    51] train_loss: 0.5214 | val_loss: 0.1116\n",
      "[635,    51] train_loss: 0.5300 | val_loss: 0.1127\n",
      "[636,    51] train_loss: 0.5306 | val_loss: 0.1134\n",
      "[637,    51] train_loss: 0.5266 | val_loss: 0.1120\n",
      "[638,    51] train_loss: 0.5285 | val_loss: 0.1123\n",
      "[639,    51] train_loss: 0.5239 | val_loss: 0.1133\n",
      "[640,    51] train_loss: 0.5178 | val_loss: 0.1128\n",
      "[641,    51] train_loss: 0.5174 | val_loss: 0.1122\n",
      "[642,    51] train_loss: 0.5169 | val_loss: 0.1124\n",
      "[643,    51] train_loss: 0.5240 | val_loss: 0.1129\n",
      "[644,    51] train_loss: 0.5195 | val_loss: 0.1132\n",
      "[645,    51] train_loss: 0.5333 | val_loss: 0.1132\n",
      "[646,    51] train_loss: 0.5230 | val_loss: 0.1111\n",
      "[647,    51] train_loss: 0.5253 | val_loss: 0.1127\n",
      "[648,    51] train_loss: 0.5300 | val_loss: 0.1119\n",
      "[649,    51] train_loss: 0.5317 | val_loss: 0.1120\n",
      "[650,    51] train_loss: 0.5296 | val_loss: 0.1106\n",
      "Saving checkpoint 650\n",
      "[651,    51] train_loss: 0.5315 | val_loss: 0.1112\n",
      "[652,    51] train_loss: 0.5371 | val_loss: 0.1133\n",
      "[653,    51] train_loss: 0.5329 | val_loss: 0.1109\n",
      "[654,    51] train_loss: 0.5300 | val_loss: 0.1136\n",
      "[655,    51] train_loss: 0.5244 | val_loss: 0.1111\n",
      "[656,    51] train_loss: 0.5390 | val_loss: 0.1134\n",
      "[657,    51] train_loss: 0.5205 | val_loss: 0.1142\n",
      "[658,    51] train_loss: 0.5302 | val_loss: 0.1140\n",
      "[659,    51] train_loss: 0.5312 | val_loss: 0.1107\n",
      "[660,    51] train_loss: 0.5209 | val_loss: 0.1127\n",
      "[661,    51] train_loss: 0.5295 | val_loss: 0.1130\n",
      "[662,    51] train_loss: 0.5340 | val_loss: 0.1127\n",
      "[663,    51] train_loss: 0.5343 | val_loss: 0.1130\n",
      "[664,    51] train_loss: 0.5296 | val_loss: 0.1127\n",
      "[665,    51] train_loss: 0.5355 | val_loss: 0.1129\n",
      "[666,    51] train_loss: 0.5326 | val_loss: 0.1122\n",
      "[667,    51] train_loss: 0.5173 | val_loss: 0.1110\n",
      "[668,    51] train_loss: 0.5302 | val_loss: 0.1130\n",
      "[669,    51] train_loss: 0.5244 | val_loss: 0.1127\n",
      "[670,    51] train_loss: 0.5371 | val_loss: 0.1135\n",
      "[671,    51] train_loss: 0.5210 | val_loss: 0.1141\n",
      "[672,    51] train_loss: 0.5284 | val_loss: 0.1125\n",
      "[673,    51] train_loss: 0.5286 | val_loss: 0.1113\n",
      "[674,    51] train_loss: 0.5216 | val_loss: 0.1132\n",
      "[675,    51] train_loss: 0.5298 | val_loss: 0.1112\n",
      "[676,    51] train_loss: 0.5275 | val_loss: 0.1114\n",
      "[677,    51] train_loss: 0.5259 | val_loss: 0.1128\n",
      "[678,    51] train_loss: 0.5284 | val_loss: 0.1128\n",
      "[679,    51] train_loss: 0.5179 | val_loss: 0.1130\n",
      "[680,    51] train_loss: 0.5371 | val_loss: 0.1117\n",
      "[681,    51] train_loss: 0.5325 | val_loss: 0.1121\n",
      "[682,    51] train_loss: 0.5307 | val_loss: 0.1121\n",
      "[683,    51] train_loss: 0.5187 | val_loss: 0.1122\n",
      "[684,    51] train_loss: 0.5295 | val_loss: 0.1145\n",
      "[685,    51] train_loss: 0.5291 | val_loss: 0.1125\n",
      "[686,    51] train_loss: 0.5290 | val_loss: 0.1136\n",
      "[687,    51] train_loss: 0.5191 | val_loss: 0.1117\n",
      "[688,    51] train_loss: 0.5322 | val_loss: 0.1102\n",
      "[689,    51] train_loss: 0.5311 | val_loss: 0.1104\n",
      "[690,    51] train_loss: 0.5314 | val_loss: 0.1134\n",
      "[691,    51] train_loss: 0.5350 | val_loss: 0.1117\n",
      "[692,    51] train_loss: 0.5215 | val_loss: 0.1118\n",
      "[693,    51] train_loss: 0.5298 | val_loss: 0.1128\n",
      "[694,    51] train_loss: 0.5287 | val_loss: 0.1129\n",
      "[695,    51] train_loss: 0.5244 | val_loss: 0.1128\n",
      "[696,    51] train_loss: 0.5220 | val_loss: 0.1113\n",
      "[697,    51] train_loss: 0.5312 | val_loss: 0.1122\n",
      "[698,    51] train_loss: 0.5301 | val_loss: 0.1110\n",
      "[699,    51] train_loss: 0.5141 | val_loss: 0.1117\n",
      "[700,    51] train_loss: 0.5211 | val_loss: 0.1121\n",
      "Saving checkpoint 700\n",
      "[701,    51] train_loss: 0.5260 | val_loss: 0.1112\n",
      "[702,    51] train_loss: 0.5316 | val_loss: 0.1126\n",
      "[703,    51] train_loss: 0.5251 | val_loss: 0.1130\n",
      "[704,    51] train_loss: 0.5348 | val_loss: 0.1111\n",
      "[705,    51] train_loss: 0.5299 | val_loss: 0.1139\n",
      "[706,    51] train_loss: 0.5316 | val_loss: 0.1119\n",
      "[707,    51] train_loss: 0.5256 | val_loss: 0.1124\n",
      "[708,    51] train_loss: 0.5270 | val_loss: 0.1123\n",
      "[709,    51] train_loss: 0.5325 | val_loss: 0.1117\n",
      "[710,    51] train_loss: 0.5187 | val_loss: 0.1103\n",
      "[711,    51] train_loss: 0.5182 | val_loss: 0.1131\n",
      "[712,    51] train_loss: 0.5283 | val_loss: 0.1129\n",
      "[713,    51] train_loss: 0.5354 | val_loss: 0.1114\n",
      "[714,    51] train_loss: 0.5221 | val_loss: 0.1131\n",
      "[715,    51] train_loss: 0.5240 | val_loss: 0.1129\n",
      "[716,    51] train_loss: 0.5283 | val_loss: 0.1126\n",
      "[717,    51] train_loss: 0.5329 | val_loss: 0.1126\n",
      "[718,    51] train_loss: 0.5274 | val_loss: 0.1113\n",
      "[719,    51] train_loss: 0.5293 | val_loss: 0.1119\n",
      "[720,    51] train_loss: 0.5259 | val_loss: 0.1124\n",
      "[721,    51] train_loss: 0.5286 | val_loss: 0.1124\n",
      "[722,    51] train_loss: 0.5168 | val_loss: 0.1112\n",
      "[723,    51] train_loss: 0.5302 | val_loss: 0.1130\n",
      "[724,    51] train_loss: 0.5364 | val_loss: 0.1111\n",
      "[725,    51] train_loss: 0.5274 | val_loss: 0.1124\n",
      "[726,    51] train_loss: 0.5296 | val_loss: 0.1120\n",
      "[727,    51] train_loss: 0.5210 | val_loss: 0.1128\n",
      "[728,    51] train_loss: 0.5296 | val_loss: 0.1139\n",
      "[729,    51] train_loss: 0.5312 | val_loss: 0.1138\n",
      "[730,    51] train_loss: 0.5310 | val_loss: 0.1119\n",
      "[731,    51] train_loss: 0.5245 | val_loss: 0.1137\n",
      "[732,    51] train_loss: 0.5269 | val_loss: 0.1115\n",
      "[733,    51] train_loss: 0.5336 | val_loss: 0.1113\n",
      "[734,    51] train_loss: 0.5291 | val_loss: 0.1104\n",
      "[735,    51] train_loss: 0.5249 | val_loss: 0.1136\n",
      "[736,    51] train_loss: 0.5168 | val_loss: 0.1116\n",
      "[737,    51] train_loss: 0.5268 | val_loss: 0.1121\n",
      "[738,    51] train_loss: 0.5336 | val_loss: 0.1140\n",
      "[739,    51] train_loss: 0.5194 | val_loss: 0.1126\n",
      "[740,    51] train_loss: 0.5300 | val_loss: 0.1105\n",
      "[741,    51] train_loss: 0.5163 | val_loss: 0.1122\n",
      "[742,    51] train_loss: 0.5223 | val_loss: 0.1119\n",
      "[743,    51] train_loss: 0.5253 | val_loss: 0.1134\n",
      "[744,    51] train_loss: 0.5166 | val_loss: 0.1115\n",
      "[745,    51] train_loss: 0.5261 | val_loss: 0.1124\n",
      "[746,    51] train_loss: 0.5263 | val_loss: 0.1130\n",
      "[747,    51] train_loss: 0.5284 | val_loss: 0.1127\n",
      "[748,    51] train_loss: 0.5288 | val_loss: 0.1134\n",
      "[749,    51] train_loss: 0.5342 | val_loss: 0.1134\n",
      "[750,    51] train_loss: 0.5294 | val_loss: 0.1103\n",
      "Saving checkpoint 750\n",
      "[751,    51] train_loss: 0.5327 | val_loss: 0.1109\n",
      "[752,    51] train_loss: 0.5302 | val_loss: 0.1132\n",
      "[753,    51] train_loss: 0.5291 | val_loss: 0.1125\n",
      "[754,    51] train_loss: 0.5326 | val_loss: 0.1123\n",
      "[755,    51] train_loss: 0.5383 | val_loss: 0.1120\n",
      "[756,    51] train_loss: 0.5220 | val_loss: 0.1140\n",
      "[757,    51] train_loss: 0.5248 | val_loss: 0.1141\n",
      "[758,    51] train_loss: 0.5247 | val_loss: 0.1136\n",
      "[759,    51] train_loss: 0.5201 | val_loss: 0.1121\n",
      "[760,    51] train_loss: 0.5248 | val_loss: 0.1124\n",
      "[761,    51] train_loss: 0.5309 | val_loss: 0.1122\n",
      "[762,    51] train_loss: 0.5349 | val_loss: 0.1099\n",
      "[763,    51] train_loss: 0.5198 | val_loss: 0.1128\n",
      "[764,    51] train_loss: 0.5317 | val_loss: 0.1118\n",
      "[765,    51] train_loss: 0.5284 | val_loss: 0.1121\n",
      "[766,    51] train_loss: 0.5262 | val_loss: 0.1118\n",
      "[767,    51] train_loss: 0.5322 | val_loss: 0.1126\n",
      "[768,    51] train_loss: 0.5322 | val_loss: 0.1105\n",
      "[769,    51] train_loss: 0.5304 | val_loss: 0.1105\n",
      "[770,    51] train_loss: 0.5243 | val_loss: 0.1116\n",
      "[771,    51] train_loss: 0.5206 | val_loss: 0.1110\n",
      "[772,    51] train_loss: 0.5277 | val_loss: 0.1117\n",
      "[773,    51] train_loss: 0.5215 | val_loss: 0.1103\n",
      "[774,    51] train_loss: 0.5176 | val_loss: 0.1117\n",
      "[775,    51] train_loss: 0.5162 | val_loss: 0.1120\n",
      "[776,    51] train_loss: 0.5226 | val_loss: 0.1146\n",
      "[777,    51] train_loss: 0.5320 | val_loss: 0.1122\n",
      "[778,    51] train_loss: 0.5321 | val_loss: 0.1122\n",
      "[779,    51] train_loss: 0.5282 | val_loss: 0.1136\n",
      "[780,    51] train_loss: 0.5187 | val_loss: 0.1140\n",
      "[781,    51] train_loss: 0.5304 | val_loss: 0.1101\n",
      "[782,    51] train_loss: 0.5305 | val_loss: 0.1130\n",
      "[783,    51] train_loss: 0.5304 | val_loss: 0.1115\n",
      "[784,    51] train_loss: 0.5272 | val_loss: 0.1099\n",
      "[785,    51] train_loss: 0.5185 | val_loss: 0.1115\n",
      "[786,    51] train_loss: 0.5248 | val_loss: 0.1132\n",
      "[787,    51] train_loss: 0.5167 | val_loss: 0.1117\n",
      "[788,    51] train_loss: 0.5166 | val_loss: 0.1111\n",
      "[789,    51] train_loss: 0.5316 | val_loss: 0.1114\n",
      "[790,    51] train_loss: 0.5256 | val_loss: 0.1131\n",
      "[791,    51] train_loss: 0.5203 | val_loss: 0.1116\n",
      "[792,    51] train_loss: 0.5318 | val_loss: 0.1098\n",
      "[793,    51] train_loss: 0.5279 | val_loss: 0.1120\n",
      "[794,    51] train_loss: 0.5298 | val_loss: 0.1128\n",
      "[795,    51] train_loss: 0.5336 | val_loss: 0.1108\n",
      "[796,    51] train_loss: 0.5275 | val_loss: 0.1132\n",
      "[797,    51] train_loss: 0.5280 | val_loss: 0.1132\n",
      "[798,    51] train_loss: 0.5360 | val_loss: 0.1129\n",
      "[799,    51] train_loss: 0.5282 | val_loss: 0.1136\n",
      "[800,    51] train_loss: 0.5222 | val_loss: 0.1126\n",
      "Saving checkpoint 800\n",
      "[801,    51] train_loss: 0.5277 | val_loss: 0.1133\n",
      "[802,    51] train_loss: 0.5266 | val_loss: 0.1140\n",
      "[803,    51] train_loss: 0.5272 | val_loss: 0.1123\n",
      "[804,    51] train_loss: 0.5143 | val_loss: 0.1121\n",
      "[805,    51] train_loss: 0.5318 | val_loss: 0.1111\n",
      "[806,    51] train_loss: 0.5194 | val_loss: 0.1099\n",
      "[807,    51] train_loss: 0.5185 | val_loss: 0.1112\n",
      "[808,    51] train_loss: 0.5268 | val_loss: 0.1117\n",
      "[809,    51] train_loss: 0.5263 | val_loss: 0.1122\n",
      "[810,    51] train_loss: 0.5270 | val_loss: 0.1141\n",
      "[811,    51] train_loss: 0.5256 | val_loss: 0.1122\n",
      "[812,    51] train_loss: 0.5325 | val_loss: 0.1144\n",
      "[813,    51] train_loss: 0.5241 | val_loss: 0.1115\n",
      "[814,    51] train_loss: 0.5266 | val_loss: 0.1112\n",
      "[815,    51] train_loss: 0.5185 | val_loss: 0.1123\n",
      "[816,    51] train_loss: 0.5197 | val_loss: 0.1124\n",
      "[817,    51] train_loss: 0.5209 | val_loss: 0.1106\n",
      "[818,    51] train_loss: 0.5267 | val_loss: 0.1114\n",
      "[819,    51] train_loss: 0.5269 | val_loss: 0.1105\n",
      "[820,    51] train_loss: 0.5297 | val_loss: 0.1110\n",
      "[821,    51] train_loss: 0.5255 | val_loss: 0.1130\n",
      "[822,    51] train_loss: 0.5336 | val_loss: 0.1116\n",
      "[823,    51] train_loss: 0.5166 | val_loss: 0.1128\n",
      "[824,    51] train_loss: 0.5339 | val_loss: 0.1109\n",
      "[825,    51] train_loss: 0.5325 | val_loss: 0.1107\n",
      "[826,    51] train_loss: 0.5342 | val_loss: 0.1126\n",
      "[827,    51] train_loss: 0.5310 | val_loss: 0.1111\n",
      "[828,    51] train_loss: 0.5258 | val_loss: 0.1124\n",
      "[829,    51] train_loss: 0.5234 | val_loss: 0.1135\n",
      "[830,    51] train_loss: 0.5275 | val_loss: 0.1108\n",
      "[831,    51] train_loss: 0.5328 | val_loss: 0.1135\n",
      "[832,    51] train_loss: 0.5318 | val_loss: 0.1140\n",
      "[833,    51] train_loss: 0.5195 | val_loss: 0.1127\n",
      "[834,    51] train_loss: 0.5295 | val_loss: 0.1134\n",
      "[835,    51] train_loss: 0.5322 | val_loss: 0.1128\n",
      "[836,    51] train_loss: 0.5159 | val_loss: 0.1105\n",
      "[837,    51] train_loss: 0.5215 | val_loss: 0.1143\n",
      "[838,    51] train_loss: 0.5282 | val_loss: 0.1111\n",
      "[839,    51] train_loss: 0.5301 | val_loss: 0.1103\n",
      "[840,    51] train_loss: 0.5173 | val_loss: 0.1137\n",
      "[841,    51] train_loss: 0.5264 | val_loss: 0.1125\n",
      "[842,    51] train_loss: 0.5282 | val_loss: 0.1117\n",
      "[843,    51] train_loss: 0.5235 | val_loss: 0.1143\n",
      "[844,    51] train_loss: 0.5185 | val_loss: 0.1130\n",
      "[845,    51] train_loss: 0.5206 | val_loss: 0.1116\n",
      "[846,    51] train_loss: 0.5287 | val_loss: 0.1122\n",
      "[847,    51] train_loss: 0.5277 | val_loss: 0.1116\n",
      "[848,    51] train_loss: 0.5314 | val_loss: 0.1120\n",
      "[849,    51] train_loss: 0.5258 | val_loss: 0.1125\n",
      "[850,    51] train_loss: 0.5357 | val_loss: 0.1112\n",
      "Saving checkpoint 850\n",
      "[851,    51] train_loss: 0.5281 | val_loss: 0.1120\n",
      "[852,    51] train_loss: 0.5179 | val_loss: 0.1123\n",
      "[853,    51] train_loss: 0.5309 | val_loss: 0.1097\n",
      "[854,    51] train_loss: 0.5303 | val_loss: 0.1124\n",
      "[855,    51] train_loss: 0.5310 | val_loss: 0.1122\n",
      "[856,    51] train_loss: 0.5298 | val_loss: 0.1111\n",
      "[857,    51] train_loss: 0.5168 | val_loss: 0.1109\n",
      "[858,    51] train_loss: 0.5138 | val_loss: 0.1122\n",
      "[859,    51] train_loss: 0.5251 | val_loss: 0.1121\n",
      "[860,    51] train_loss: 0.5275 | val_loss: 0.1125\n",
      "[861,    51] train_loss: 0.5215 | val_loss: 0.1127\n",
      "[862,    51] train_loss: 0.5229 | val_loss: 0.1101\n",
      "[863,    51] train_loss: 0.5252 | val_loss: 0.1136\n",
      "[864,    51] train_loss: 0.5162 | val_loss: 0.1108\n",
      "[865,    51] train_loss: 0.5299 | val_loss: 0.1130\n",
      "[866,    51] train_loss: 0.5198 | val_loss: 0.1135\n",
      "[867,    51] train_loss: 0.5218 | val_loss: 0.1125\n",
      "[868,    51] train_loss: 0.5168 | val_loss: 0.1111\n",
      "[869,    51] train_loss: 0.5278 | val_loss: 0.1138\n",
      "[870,    51] train_loss: 0.5320 | val_loss: 0.1134\n",
      "[871,    51] train_loss: 0.5266 | val_loss: 0.1122\n",
      "[872,    51] train_loss: 0.5239 | val_loss: 0.1118\n",
      "[873,    51] train_loss: 0.5294 | val_loss: 0.1108\n",
      "[874,    51] train_loss: 0.5307 | val_loss: 0.1122\n",
      "[875,    51] train_loss: 0.5286 | val_loss: 0.1114\n",
      "[876,    51] train_loss: 0.5287 | val_loss: 0.1131\n",
      "[877,    51] train_loss: 0.5336 | val_loss: 0.1115\n",
      "[878,    51] train_loss: 0.5231 | val_loss: 0.1120\n",
      "[879,    51] train_loss: 0.5216 | val_loss: 0.1122\n",
      "[880,    51] train_loss: 0.5272 | val_loss: 0.1096\n",
      "[881,    51] train_loss: 0.5271 | val_loss: 0.1124\n",
      "[882,    51] train_loss: 0.5313 | val_loss: 0.1097\n",
      "[883,    51] train_loss: 0.5276 | val_loss: 0.1151\n",
      "[884,    51] train_loss: 0.5277 | val_loss: 0.1139\n",
      "[885,    51] train_loss: 0.5175 | val_loss: 0.1150\n",
      "[886,    51] train_loss: 0.5167 | val_loss: 0.1124\n",
      "[887,    51] train_loss: 0.5340 | val_loss: 0.1117\n",
      "[888,    51] train_loss: 0.5254 | val_loss: 0.1125\n",
      "[889,    51] train_loss: 0.5171 | val_loss: 0.1133\n",
      "[890,    51] train_loss: 0.5272 | val_loss: 0.1111\n",
      "[891,    51] train_loss: 0.5221 | val_loss: 0.1111\n",
      "[892,    51] train_loss: 0.5294 | val_loss: 0.1116\n",
      "[893,    51] train_loss: 0.5191 | val_loss: 0.1126\n",
      "[894,    51] train_loss: 0.5243 | val_loss: 0.1121\n",
      "[895,    51] train_loss: 0.5253 | val_loss: 0.1120\n",
      "[896,    51] train_loss: 0.5235 | val_loss: 0.1117\n",
      "[897,    51] train_loss: 0.5319 | val_loss: 0.1131\n",
      "[898,    51] train_loss: 0.5315 | val_loss: 0.1120\n",
      "[899,    51] train_loss: 0.5326 | val_loss: 0.1119\n",
      "[900,    51] train_loss: 0.5267 | val_loss: 0.1109\n",
      "Saving checkpoint 900\n",
      "[901,    51] train_loss: 0.5291 | val_loss: 0.1132\n",
      "[902,    51] train_loss: 0.5133 | val_loss: 0.1127\n",
      "[903,    51] train_loss: 0.5241 | val_loss: 0.1112\n",
      "[904,    51] train_loss: 0.5111 | val_loss: 0.1110\n",
      "[905,    51] train_loss: 0.5184 | val_loss: 0.1128\n",
      "[906,    51] train_loss: 0.5267 | val_loss: 0.1134\n",
      "[907,    51] train_loss: 0.5238 | val_loss: 0.1104\n",
      "[908,    51] train_loss: 0.5284 | val_loss: 0.1121\n",
      "[909,    51] train_loss: 0.5208 | val_loss: 0.1121\n",
      "[910,    51] train_loss: 0.5241 | val_loss: 0.1125\n",
      "[911,    51] train_loss: 0.5334 | val_loss: 0.1131\n",
      "[912,    51] train_loss: 0.5163 | val_loss: 0.1121\n",
      "[913,    51] train_loss: 0.5173 | val_loss: 0.1123\n",
      "[914,    51] train_loss: 0.5266 | val_loss: 0.1124\n",
      "[915,    51] train_loss: 0.5263 | val_loss: 0.1113\n",
      "[916,    51] train_loss: 0.5212 | val_loss: 0.1110\n",
      "[917,    51] train_loss: 0.5350 | val_loss: 0.1131\n",
      "[918,    51] train_loss: 0.5149 | val_loss: 0.1129\n",
      "[919,    51] train_loss: 0.5248 | val_loss: 0.1123\n",
      "[920,    51] train_loss: 0.5337 | val_loss: 0.1118\n",
      "[921,    51] train_loss: 0.5240 | val_loss: 0.1126\n",
      "[922,    51] train_loss: 0.5234 | val_loss: 0.1123\n",
      "[923,    51] train_loss: 0.5332 | val_loss: 0.1112\n",
      "[924,    51] train_loss: 0.5282 | val_loss: 0.1117\n",
      "[925,    51] train_loss: 0.5266 | val_loss: 0.1117\n",
      "[926,    51] train_loss: 0.5265 | val_loss: 0.1114\n",
      "[927,    51] train_loss: 0.5244 | val_loss: 0.1116\n",
      "[928,    51] train_loss: 0.5279 | val_loss: 0.1129\n",
      "[929,    51] train_loss: 0.5312 | val_loss: 0.1112\n",
      "[930,    51] train_loss: 0.5279 | val_loss: 0.1120\n",
      "[931,    51] train_loss: 0.5252 | val_loss: 0.1112\n",
      "[932,    51] train_loss: 0.5136 | val_loss: 0.1103\n",
      "[933,    51] train_loss: 0.5203 | val_loss: 0.1118\n",
      "[934,    51] train_loss: 0.5250 | val_loss: 0.1114\n",
      "[935,    51] train_loss: 0.5324 | val_loss: 0.1141\n",
      "[936,    51] train_loss: 0.5249 | val_loss: 0.1116\n",
      "[937,    51] train_loss: 0.5272 | val_loss: 0.1134\n",
      "[938,    51] train_loss: 0.5263 | val_loss: 0.1126\n",
      "[939,    51] train_loss: 0.5154 | val_loss: 0.1124\n",
      "[940,    51] train_loss: 0.5250 | val_loss: 0.1116\n",
      "[941,    51] train_loss: 0.5241 | val_loss: 0.1122\n",
      "[942,    51] train_loss: 0.5336 | val_loss: 0.1116\n",
      "[943,    51] train_loss: 0.5218 | val_loss: 0.1114\n",
      "[944,    51] train_loss: 0.5346 | val_loss: 0.1112\n",
      "[945,    51] train_loss: 0.5280 | val_loss: 0.1112\n",
      "[946,    51] train_loss: 0.5244 | val_loss: 0.1126\n",
      "[947,    51] train_loss: 0.5228 | val_loss: 0.1131\n",
      "[948,    51] train_loss: 0.5257 | val_loss: 0.1119\n",
      "[949,    51] train_loss: 0.5265 | val_loss: 0.1116\n",
      "[950,    51] train_loss: 0.5295 | val_loss: 0.1118\n",
      "Saving checkpoint 950\n",
      "[951,    51] train_loss: 0.5209 | val_loss: 0.1149\n",
      "[952,    51] train_loss: 0.5260 | val_loss: 0.1111\n",
      "[953,    51] train_loss: 0.5178 | val_loss: 0.1122\n",
      "[954,    51] train_loss: 0.5312 | val_loss: 0.1124\n",
      "[955,    51] train_loss: 0.5143 | val_loss: 0.1112\n",
      "[956,    51] train_loss: 0.5261 | val_loss: 0.1132\n",
      "[957,    51] train_loss: 0.5322 | val_loss: 0.1121\n",
      "[958,    51] train_loss: 0.5214 | val_loss: 0.1129\n",
      "[959,    51] train_loss: 0.5344 | val_loss: 0.1111\n",
      "[960,    51] train_loss: 0.5183 | val_loss: 0.1102\n",
      "[961,    51] train_loss: 0.5293 | val_loss: 0.1123\n",
      "[962,    51] train_loss: 0.5352 | val_loss: 0.1119\n",
      "[963,    51] train_loss: 0.5258 | val_loss: 0.1122\n",
      "[964,    51] train_loss: 0.5251 | val_loss: 0.1137\n",
      "[965,    51] train_loss: 0.5240 | val_loss: 0.1122\n",
      "[966,    51] train_loss: 0.5150 | val_loss: 0.1101\n",
      "[967,    51] train_loss: 0.5179 | val_loss: 0.1120\n",
      "[968,    51] train_loss: 0.5261 | val_loss: 0.1120\n",
      "[969,    51] train_loss: 0.5265 | val_loss: 0.1103\n",
      "[970,    51] train_loss: 0.5153 | val_loss: 0.1124\n",
      "[971,    51] train_loss: 0.5188 | val_loss: 0.1130\n",
      "[972,    51] train_loss: 0.5264 | val_loss: 0.1119\n",
      "[973,    51] train_loss: 0.5321 | val_loss: 0.1111\n",
      "[974,    51] train_loss: 0.5289 | val_loss: 0.1131\n",
      "[975,    51] train_loss: 0.5137 | val_loss: 0.1125\n",
      "[976,    51] train_loss: 0.5172 | val_loss: 0.1119\n",
      "[977,    51] train_loss: 0.5170 | val_loss: 0.1116\n",
      "[978,    51] train_loss: 0.5144 | val_loss: 0.1097\n",
      "[979,    51] train_loss: 0.5262 | val_loss: 0.1115\n",
      "[980,    51] train_loss: 0.5276 | val_loss: 0.1130\n",
      "[981,    51] train_loss: 0.5240 | val_loss: 0.1125\n",
      "[982,    51] train_loss: 0.5162 | val_loss: 0.1132\n",
      "[983,    51] train_loss: 0.5191 | val_loss: 0.1124\n",
      "[984,    51] train_loss: 0.5264 | val_loss: 0.1126\n",
      "[985,    51] train_loss: 0.5327 | val_loss: 0.1118\n",
      "[986,    51] train_loss: 0.5270 | val_loss: 0.1122\n",
      "[987,    51] train_loss: 0.5307 | val_loss: 0.1117\n",
      "[988,    51] train_loss: 0.5246 | val_loss: 0.1130\n",
      "[989,    51] train_loss: 0.5229 | val_loss: 0.1110\n",
      "[990,    51] train_loss: 0.5335 | val_loss: 0.1112\n",
      "[991,    51] train_loss: 0.5312 | val_loss: 0.1118\n",
      "[992,    51] train_loss: 0.5184 | val_loss: 0.1132\n",
      "[993,    51] train_loss: 0.5228 | val_loss: 0.1124\n",
      "[994,    51] train_loss: 0.5221 | val_loss: 0.1111\n",
      "[995,    51] train_loss: 0.5267 | val_loss: 0.1113\n",
      "[996,    51] train_loss: 0.5278 | val_loss: 0.1122\n",
      "[997,    51] train_loss: 0.5295 | val_loss: 0.1113\n",
      "[998,    51] train_loss: 0.5268 | val_loss: 0.1134\n",
      "[999,    51] train_loss: 0.5224 | val_loss: 0.1124\n",
      "[1000,    51] train_loss: 0.5190 | val_loss: 0.1098\n",
      "Saving checkpoint 1000\n",
      "[1001,    51] train_loss: 0.5278 | val_loss: 0.1117\n",
      "[1002,    51] train_loss: 0.5188 | val_loss: 0.1104\n",
      "[1003,    51] train_loss: 0.5284 | val_loss: 0.1130\n",
      "[1004,    51] train_loss: 0.5332 | val_loss: 0.1123\n",
      "[1005,    51] train_loss: 0.5281 | val_loss: 0.1126\n",
      "[1006,    51] train_loss: 0.5257 | val_loss: 0.1115\n",
      "[1007,    51] train_loss: 0.5298 | val_loss: 0.1124\n",
      "[1008,    51] train_loss: 0.5281 | val_loss: 0.1128\n",
      "[1009,    51] train_loss: 0.5150 | val_loss: 0.1103\n",
      "[1010,    51] train_loss: 0.5331 | val_loss: 0.1133\n",
      "[1011,    51] train_loss: 0.5166 | val_loss: 0.1130\n",
      "[1012,    51] train_loss: 0.5268 | val_loss: 0.1126\n",
      "[1013,    51] train_loss: 0.5265 | val_loss: 0.1122\n",
      "[1014,    51] train_loss: 0.5151 | val_loss: 0.1117\n",
      "[1015,    51] train_loss: 0.5239 | val_loss: 0.1118\n",
      "[1016,    51] train_loss: 0.5242 | val_loss: 0.1135\n",
      "[1017,    51] train_loss: 0.5265 | val_loss: 0.1134\n",
      "[1018,    51] train_loss: 0.5236 | val_loss: 0.1116\n",
      "[1019,    51] train_loss: 0.5308 | val_loss: 0.1131\n",
      "[1020,    51] train_loss: 0.5181 | val_loss: 0.1117\n",
      "[1021,    51] train_loss: 0.5271 | val_loss: 0.1125\n",
      "[1022,    51] train_loss: 0.5132 | val_loss: 0.1122\n",
      "[1023,    51] train_loss: 0.5251 | val_loss: 0.1110\n",
      "[1024,    51] train_loss: 0.5328 | val_loss: 0.1101\n",
      "[1025,    51] train_loss: 0.5257 | val_loss: 0.1111\n",
      "[1026,    51] train_loss: 0.5298 | val_loss: 0.1113\n",
      "[1027,    51] train_loss: 0.5190 | val_loss: 0.1105\n",
      "[1028,    51] train_loss: 0.5251 | val_loss: 0.1117\n",
      "[1029,    51] train_loss: 0.5231 | val_loss: 0.1133\n",
      "[1030,    51] train_loss: 0.5280 | val_loss: 0.1123\n",
      "[1031,    51] train_loss: 0.5219 | val_loss: 0.1104\n",
      "[1032,    51] train_loss: 0.5253 | val_loss: 0.1136\n",
      "[1033,    51] train_loss: 0.5287 | val_loss: 0.1118\n",
      "[1034,    51] train_loss: 0.5130 | val_loss: 0.1123\n",
      "[1035,    51] train_loss: 0.5281 | val_loss: 0.1126\n",
      "[1036,    51] train_loss: 0.5252 | val_loss: 0.1115\n",
      "[1037,    51] train_loss: 0.5193 | val_loss: 0.1108\n",
      "[1038,    51] train_loss: 0.5323 | val_loss: 0.1121\n",
      "[1039,    51] train_loss: 0.5208 | val_loss: 0.1127\n",
      "[1040,    51] train_loss: 0.5267 | val_loss: 0.1130\n",
      "[1041,    51] train_loss: 0.5289 | val_loss: 0.1117\n",
      "[1042,    51] train_loss: 0.5274 | val_loss: 0.1128\n",
      "[1043,    51] train_loss: 0.5294 | val_loss: 0.1125\n",
      "[1044,    51] train_loss: 0.5235 | val_loss: 0.1137\n",
      "[1045,    51] train_loss: 0.5172 | val_loss: 0.1121\n",
      "[1046,    51] train_loss: 0.5115 | val_loss: 0.1116\n",
      "[1047,    51] train_loss: 0.5288 | val_loss: 0.1116\n",
      "[1048,    51] train_loss: 0.5253 | val_loss: 0.1121\n",
      "[1049,    51] train_loss: 0.5304 | val_loss: 0.1097\n",
      "[1050,    51] train_loss: 0.5187 | val_loss: 0.1113\n",
      "Saving checkpoint 1050\n",
      "[1051,    51] train_loss: 0.5233 | val_loss: 0.1105\n",
      "[1052,    51] train_loss: 0.5254 | val_loss: 0.1137\n",
      "[1053,    51] train_loss: 0.5222 | val_loss: 0.1124\n",
      "[1054,    51] train_loss: 0.5206 | val_loss: 0.1110\n",
      "[1055,    51] train_loss: 0.5226 | val_loss: 0.1119\n",
      "[1056,    51] train_loss: 0.5285 | val_loss: 0.1112\n",
      "[1057,    51] train_loss: 0.5303 | val_loss: 0.1135\n",
      "[1058,    51] train_loss: 0.5235 | val_loss: 0.1103\n",
      "[1059,    51] train_loss: 0.5232 | val_loss: 0.1114\n",
      "[1060,    51] train_loss: 0.5290 | val_loss: 0.1149\n",
      "[1061,    51] train_loss: 0.5262 | val_loss: 0.1125\n",
      "[1062,    51] train_loss: 0.5189 | val_loss: 0.1117\n",
      "[1063,    51] train_loss: 0.5275 | val_loss: 0.1137\n",
      "[1064,    51] train_loss: 0.5286 | val_loss: 0.1115\n",
      "[1065,    51] train_loss: 0.5252 | val_loss: 0.1132\n",
      "[1066,    51] train_loss: 0.5196 | val_loss: 0.1112\n",
      "[1067,    51] train_loss: 0.5257 | val_loss: 0.1100\n",
      "[1068,    51] train_loss: 0.5156 | val_loss: 0.1117\n",
      "[1069,    51] train_loss: 0.5291 | val_loss: 0.1127\n",
      "[1070,    51] train_loss: 0.5253 | val_loss: 0.1105\n",
      "[1071,    51] train_loss: 0.5251 | val_loss: 0.1122\n",
      "[1072,    51] train_loss: 0.5292 | val_loss: 0.1118\n",
      "[1073,    51] train_loss: 0.5194 | val_loss: 0.1127\n",
      "[1074,    51] train_loss: 0.5248 | val_loss: 0.1128\n",
      "[1075,    51] train_loss: 0.5315 | val_loss: 0.1123\n",
      "[1076,    51] train_loss: 0.5267 | val_loss: 0.1109\n",
      "[1077,    51] train_loss: 0.5270 | val_loss: 0.1129\n",
      "[1078,    51] train_loss: 0.5258 | val_loss: 0.1115\n",
      "[1079,    51] train_loss: 0.5215 | val_loss: 0.1131\n",
      "[1080,    51] train_loss: 0.5243 | val_loss: 0.1112\n",
      "[1081,    51] train_loss: 0.5237 | val_loss: 0.1128\n",
      "[1082,    51] train_loss: 0.5219 | val_loss: 0.1112\n",
      "[1083,    51] train_loss: 0.5255 | val_loss: 0.1100\n",
      "[1084,    51] train_loss: 0.5256 | val_loss: 0.1122\n",
      "[1085,    51] train_loss: 0.5284 | val_loss: 0.1106\n",
      "[1086,    51] train_loss: 0.5251 | val_loss: 0.1119\n",
      "[1087,    51] train_loss: 0.5301 | val_loss: 0.1113\n",
      "[1088,    51] train_loss: 0.5297 | val_loss: 0.1110\n",
      "[1089,    51] train_loss: 0.5283 | val_loss: 0.1115\n",
      "[1090,    51] train_loss: 0.5160 | val_loss: 0.1118\n",
      "[1091,    51] train_loss: 0.5285 | val_loss: 0.1120\n",
      "[1092,    51] train_loss: 0.5260 | val_loss: 0.1103\n",
      "[1093,    51] train_loss: 0.5252 | val_loss: 0.1117\n",
      "[1094,    51] train_loss: 0.5294 | val_loss: 0.1126\n",
      "[1095,    51] train_loss: 0.5269 | val_loss: 0.1107\n",
      "[1096,    51] train_loss: 0.5176 | val_loss: 0.1114\n",
      "[1097,    51] train_loss: 0.5260 | val_loss: 0.1122\n",
      "[1098,    51] train_loss: 0.5278 | val_loss: 0.1114\n",
      "[1099,    51] train_loss: 0.5325 | val_loss: 0.1106\n",
      "[1100,    51] train_loss: 0.5310 | val_loss: 0.1109\n",
      "Saving checkpoint 1100\n",
      "[1101,    51] train_loss: 0.5308 | val_loss: 0.1146\n",
      "[1102,    51] train_loss: 0.5185 | val_loss: 0.1110\n",
      "[1103,    51] train_loss: 0.5281 | val_loss: 0.1109\n",
      "[1104,    51] train_loss: 0.5364 | val_loss: 0.1107\n",
      "[1105,    51] train_loss: 0.5251 | val_loss: 0.1126\n",
      "[1106,    51] train_loss: 0.5243 | val_loss: 0.1119\n",
      "[1107,    51] train_loss: 0.5156 | val_loss: 0.1127\n",
      "[1108,    51] train_loss: 0.5144 | val_loss: 0.1112\n",
      "[1109,    51] train_loss: 0.5196 | val_loss: 0.1113\n",
      "[1110,    51] train_loss: 0.5271 | val_loss: 0.1118\n",
      "[1111,    51] train_loss: 0.5143 | val_loss: 0.1121\n",
      "[1112,    51] train_loss: 0.5249 | val_loss: 0.1101\n",
      "[1113,    51] train_loss: 0.5238 | val_loss: 0.1103\n",
      "[1114,    51] train_loss: 0.5212 | val_loss: 0.1130\n",
      "[1115,    51] train_loss: 0.5164 | val_loss: 0.1096\n",
      "[1116,    51] train_loss: 0.5226 | val_loss: 0.1116\n",
      "[1117,    51] train_loss: 0.5250 | val_loss: 0.1131\n",
      "[1118,    51] train_loss: 0.5139 | val_loss: 0.1123\n",
      "[1119,    51] train_loss: 0.5233 | val_loss: 0.1116\n",
      "[1120,    51] train_loss: 0.5312 | val_loss: 0.1113\n",
      "[1121,    51] train_loss: 0.5138 | val_loss: 0.1128\n",
      "[1122,    51] train_loss: 0.5303 | val_loss: 0.1109\n",
      "[1123,    51] train_loss: 0.5269 | val_loss: 0.1132\n",
      "[1124,    51] train_loss: 0.5229 | val_loss: 0.1110\n",
      "[1125,    51] train_loss: 0.5233 | val_loss: 0.1101\n",
      "[1126,    51] train_loss: 0.5240 | val_loss: 0.1125\n",
      "[1127,    51] train_loss: 0.5235 | val_loss: 0.1108\n",
      "[1128,    51] train_loss: 0.5142 | val_loss: 0.1110\n",
      "[1129,    51] train_loss: 0.5202 | val_loss: 0.1134\n",
      "[1130,    51] train_loss: 0.5235 | val_loss: 0.1122\n",
      "[1131,    51] train_loss: 0.5135 | val_loss: 0.1108\n",
      "[1132,    51] train_loss: 0.5222 | val_loss: 0.1117\n",
      "[1133,    51] train_loss: 0.5228 | val_loss: 0.1111\n",
      "[1134,    51] train_loss: 0.5302 | val_loss: 0.1111\n",
      "[1135,    51] train_loss: 0.5175 | val_loss: 0.1115\n",
      "[1136,    51] train_loss: 0.5274 | val_loss: 0.1117\n",
      "[1137,    51] train_loss: 0.5136 | val_loss: 0.1128\n",
      "[1138,    51] train_loss: 0.5206 | val_loss: 0.1098\n",
      "[1139,    51] train_loss: 0.5293 | val_loss: 0.1127\n",
      "[1140,    51] train_loss: 0.5197 | val_loss: 0.1119\n",
      "[1141,    51] train_loss: 0.5155 | val_loss: 0.1131\n",
      "[1142,    51] train_loss: 0.5309 | val_loss: 0.1120\n",
      "[1143,    51] train_loss: 0.5125 | val_loss: 0.1115\n",
      "[1144,    51] train_loss: 0.5290 | val_loss: 0.1109\n",
      "[1145,    51] train_loss: 0.5247 | val_loss: 0.1110\n",
      "[1146,    51] train_loss: 0.5225 | val_loss: 0.1108\n",
      "[1147,    51] train_loss: 0.5260 | val_loss: 0.1130\n",
      "[1148,    51] train_loss: 0.5330 | val_loss: 0.1124\n",
      "[1149,    51] train_loss: 0.5244 | val_loss: 0.1124\n",
      "[1150,    51] train_loss: 0.5272 | val_loss: 0.1110\n",
      "Saving checkpoint 1150\n",
      "[1151,    51] train_loss: 0.5212 | val_loss: 0.1107\n",
      "[1152,    51] train_loss: 0.5276 | val_loss: 0.1112\n",
      "[1153,    51] train_loss: 0.5179 | val_loss: 0.1122\n",
      "[1154,    51] train_loss: 0.5255 | val_loss: 0.1118\n",
      "[1155,    51] train_loss: 0.5269 | val_loss: 0.1108\n",
      "[1156,    51] train_loss: 0.5297 | val_loss: 0.1128\n",
      "[1157,    51] train_loss: 0.5223 | val_loss: 0.1109\n",
      "[1158,    51] train_loss: 0.5237 | val_loss: 0.1114\n",
      "[1159,    51] train_loss: 0.5295 | val_loss: 0.1127\n",
      "[1160,    51] train_loss: 0.5142 | val_loss: 0.1124\n",
      "[1161,    51] train_loss: 0.5140 | val_loss: 0.1106\n",
      "[1162,    51] train_loss: 0.5262 | val_loss: 0.1118\n",
      "[1163,    51] train_loss: 0.5276 | val_loss: 0.1106\n",
      "[1164,    51] train_loss: 0.5289 | val_loss: 0.1107\n",
      "[1165,    51] train_loss: 0.5278 | val_loss: 0.1102\n",
      "[1166,    51] train_loss: 0.5251 | val_loss: 0.1123\n",
      "[1167,    51] train_loss: 0.5241 | val_loss: 0.1126\n",
      "[1168,    51] train_loss: 0.5262 | val_loss: 0.1108\n",
      "[1169,    51] train_loss: 0.5242 | val_loss: 0.1115\n",
      "[1170,    51] train_loss: 0.5281 | val_loss: 0.1119\n",
      "[1171,    51] train_loss: 0.5296 | val_loss: 0.1113\n",
      "[1172,    51] train_loss: 0.5274 | val_loss: 0.1121\n",
      "[1173,    51] train_loss: 0.5244 | val_loss: 0.1133\n",
      "[1174,    51] train_loss: 0.5123 | val_loss: 0.1107\n",
      "[1175,    51] train_loss: 0.5274 | val_loss: 0.1111\n",
      "[1176,    51] train_loss: 0.5191 | val_loss: 0.1120\n",
      "[1177,    51] train_loss: 0.5232 | val_loss: 0.1116\n",
      "[1178,    51] train_loss: 0.5239 | val_loss: 0.1117\n",
      "[1179,    51] train_loss: 0.5232 | val_loss: 0.1126\n",
      "[1180,    51] train_loss: 0.5277 | val_loss: 0.1128\n",
      "[1181,    51] train_loss: 0.5276 | val_loss: 0.1116\n",
      "[1182,    51] train_loss: 0.5287 | val_loss: 0.1115\n",
      "[1183,    51] train_loss: 0.5260 | val_loss: 0.1106\n",
      "[1184,    51] train_loss: 0.5296 | val_loss: 0.1115\n",
      "[1185,    51] train_loss: 0.5233 | val_loss: 0.1120\n",
      "[1186,    51] train_loss: 0.5237 | val_loss: 0.1114\n",
      "[1187,    51] train_loss: 0.5191 | val_loss: 0.1104\n",
      "[1188,    51] train_loss: 0.5319 | val_loss: 0.1081\n",
      "[1189,    51] train_loss: 0.5229 | val_loss: 0.1124\n",
      "[1190,    51] train_loss: 0.5243 | val_loss: 0.1104\n",
      "[1191,    51] train_loss: 0.5276 | val_loss: 0.1108\n",
      "[1192,    51] train_loss: 0.5208 | val_loss: 0.1116\n",
      "[1193,    51] train_loss: 0.5276 | val_loss: 0.1108\n",
      "[1194,    51] train_loss: 0.5267 | val_loss: 0.1113\n",
      "[1195,    51] train_loss: 0.5269 | val_loss: 0.1123\n",
      "[1196,    51] train_loss: 0.5195 | val_loss: 0.1111\n",
      "[1197,    51] train_loss: 0.5230 | val_loss: 0.1114\n",
      "[1198,    51] train_loss: 0.5263 | val_loss: 0.1105\n",
      "[1199,    51] train_loss: 0.5156 | val_loss: 0.1108\n",
      "[1200,    51] train_loss: 0.5265 | val_loss: 0.1105\n",
      "Saving checkpoint 1200\n",
      "[1201,    51] train_loss: 0.5241 | val_loss: 0.1102\n",
      "[1202,    51] train_loss: 0.5329 | val_loss: 0.1114\n",
      "[1203,    51] train_loss: 0.5243 | val_loss: 0.1112\n",
      "[1204,    51] train_loss: 0.5228 | val_loss: 0.1099\n",
      "[1205,    51] train_loss: 0.5152 | val_loss: 0.1121\n",
      "[1206,    51] train_loss: 0.5125 | val_loss: 0.1119\n",
      "[1207,    51] train_loss: 0.5230 | val_loss: 0.1100\n",
      "[1208,    51] train_loss: 0.5223 | val_loss: 0.1101\n",
      "[1209,    51] train_loss: 0.5176 | val_loss: 0.1119\n",
      "[1210,    51] train_loss: 0.5242 | val_loss: 0.1124\n",
      "[1211,    51] train_loss: 0.5164 | val_loss: 0.1111\n",
      "[1212,    51] train_loss: 0.5248 | val_loss: 0.1131\n",
      "[1213,    51] train_loss: 0.5266 | val_loss: 0.1113\n",
      "[1214,    51] train_loss: 0.5319 | val_loss: 0.1124\n",
      "[1215,    51] train_loss: 0.5260 | val_loss: 0.1114\n",
      "[1216,    51] train_loss: 0.5371 | val_loss: 0.1117\n",
      "[1217,    51] train_loss: 0.5140 | val_loss: 0.1100\n",
      "[1218,    51] train_loss: 0.5287 | val_loss: 0.1116\n",
      "[1219,    51] train_loss: 0.5265 | val_loss: 0.1126\n",
      "[1220,    51] train_loss: 0.5249 | val_loss: 0.1107\n",
      "[1221,    51] train_loss: 0.5263 | val_loss: 0.1121\n",
      "[1222,    51] train_loss: 0.5162 | val_loss: 0.1108\n",
      "[1223,    51] train_loss: 0.5159 | val_loss: 0.1108\n",
      "[1224,    51] train_loss: 0.5172 | val_loss: 0.1106\n",
      "[1225,    51] train_loss: 0.5219 | val_loss: 0.1103\n",
      "[1226,    51] train_loss: 0.5245 | val_loss: 0.1126\n",
      "[1227,    51] train_loss: 0.5244 | val_loss: 0.1112\n",
      "[1228,    51] train_loss: 0.5294 | val_loss: 0.1112\n",
      "[1229,    51] train_loss: 0.5173 | val_loss: 0.1114\n",
      "[1230,    51] train_loss: 0.5256 | val_loss: 0.1097\n",
      "[1231,    51] train_loss: 0.5281 | val_loss: 0.1112\n",
      "[1232,    51] train_loss: 0.5280 | val_loss: 0.1118\n",
      "[1233,    51] train_loss: 0.5266 | val_loss: 0.1117\n",
      "[1234,    51] train_loss: 0.5269 | val_loss: 0.1118\n",
      "[1235,    51] train_loss: 0.5240 | val_loss: 0.1118\n",
      "[1236,    51] train_loss: 0.5271 | val_loss: 0.1129\n",
      "[1237,    51] train_loss: 0.5205 | val_loss: 0.1115\n",
      "[1238,    51] train_loss: 0.5236 | val_loss: 0.1123\n",
      "[1239,    51] train_loss: 0.5263 | val_loss: 0.1103\n",
      "[1240,    51] train_loss: 0.5143 | val_loss: 0.1104\n",
      "[1241,    51] train_loss: 0.5277 | val_loss: 0.1100\n",
      "[1242,    51] train_loss: 0.5240 | val_loss: 0.1127\n",
      "[1243,    51] train_loss: 0.5240 | val_loss: 0.1116\n",
      "[1244,    51] train_loss: 0.5107 | val_loss: 0.1102\n",
      "[1245,    51] train_loss: 0.5277 | val_loss: 0.1109\n",
      "[1246,    51] train_loss: 0.5146 | val_loss: 0.1133\n",
      "[1247,    51] train_loss: 0.5339 | val_loss: 0.1114\n",
      "[1248,    51] train_loss: 0.5262 | val_loss: 0.1119\n",
      "[1249,    51] train_loss: 0.5275 | val_loss: 0.1105\n",
      "[1250,    51] train_loss: 0.5290 | val_loss: 0.1105\n",
      "Saving checkpoint 1250\n",
      "[1251,    51] train_loss: 0.5245 | val_loss: 0.1105\n",
      "[1252,    51] train_loss: 0.5207 | val_loss: 0.1128\n",
      "[1253,    51] train_loss: 0.5279 | val_loss: 0.1112\n",
      "[1254,    51] train_loss: 0.5214 | val_loss: 0.1107\n",
      "[1255,    51] train_loss: 0.5260 | val_loss: 0.1114\n",
      "[1256,    51] train_loss: 0.5248 | val_loss: 0.1117\n",
      "[1257,    51] train_loss: 0.5106 | val_loss: 0.1102\n",
      "[1258,    51] train_loss: 0.5262 | val_loss: 0.1117\n",
      "[1259,    51] train_loss: 0.5249 | val_loss: 0.1121\n",
      "[1260,    51] train_loss: 0.5240 | val_loss: 0.1122\n",
      "[1261,    51] train_loss: 0.5249 | val_loss: 0.1135\n",
      "[1262,    51] train_loss: 0.5203 | val_loss: 0.1111\n",
      "[1263,    51] train_loss: 0.5203 | val_loss: 0.1106\n",
      "[1264,    51] train_loss: 0.5237 | val_loss: 0.1109\n",
      "[1265,    51] train_loss: 0.5147 | val_loss: 0.1110\n",
      "[1266,    51] train_loss: 0.5310 | val_loss: 0.1112\n",
      "[1267,    51] train_loss: 0.5149 | val_loss: 0.1109\n",
      "[1268,    51] train_loss: 0.5305 | val_loss: 0.1105\n",
      "[1269,    51] train_loss: 0.5334 | val_loss: 0.1109\n",
      "[1270,    51] train_loss: 0.5240 | val_loss: 0.1116\n",
      "[1271,    51] train_loss: 0.5239 | val_loss: 0.1116\n",
      "[1272,    51] train_loss: 0.5156 | val_loss: 0.1138\n",
      "[1273,    51] train_loss: 0.5197 | val_loss: 0.1120\n",
      "[1274,    51] train_loss: 0.5298 | val_loss: 0.1100\n",
      "[1275,    51] train_loss: 0.5245 | val_loss: 0.1108\n",
      "[1276,    51] train_loss: 0.5258 | val_loss: 0.1109\n",
      "[1277,    51] train_loss: 0.5208 | val_loss: 0.1105\n",
      "[1278,    51] train_loss: 0.5279 | val_loss: 0.1128\n",
      "[1279,    51] train_loss: 0.5154 | val_loss: 0.1120\n",
      "[1280,    51] train_loss: 0.5276 | val_loss: 0.1116\n",
      "[1281,    51] train_loss: 0.5259 | val_loss: 0.1122\n",
      "[1282,    51] train_loss: 0.5304 | val_loss: 0.1124\n",
      "[1283,    51] train_loss: 0.5238 | val_loss: 0.1106\n",
      "[1284,    51] train_loss: 0.5227 | val_loss: 0.1110\n",
      "[1285,    51] train_loss: 0.5280 | val_loss: 0.1103\n",
      "[1286,    51] train_loss: 0.5265 | val_loss: 0.1110\n",
      "[1287,    51] train_loss: 0.5323 | val_loss: 0.1108\n",
      "[1288,    51] train_loss: 0.5142 | val_loss: 0.1111\n",
      "[1289,    51] train_loss: 0.5269 | val_loss: 0.1105\n",
      "[1290,    51] train_loss: 0.5292 | val_loss: 0.1131\n",
      "[1291,    51] train_loss: 0.5288 | val_loss: 0.1124\n",
      "[1292,    51] train_loss: 0.5212 | val_loss: 0.1101\n",
      "[1293,    51] train_loss: 0.5238 | val_loss: 0.1111\n",
      "[1294,    51] train_loss: 0.5293 | val_loss: 0.1119\n",
      "[1295,    51] train_loss: 0.5190 | val_loss: 0.1130\n",
      "[1296,    51] train_loss: 0.5268 | val_loss: 0.1132\n",
      "[1297,    51] train_loss: 0.5315 | val_loss: 0.1126\n",
      "[1298,    51] train_loss: 0.5290 | val_loss: 0.1111\n",
      "[1299,    51] train_loss: 0.5156 | val_loss: 0.1118\n",
      "[1300,    51] train_loss: 0.5278 | val_loss: 0.1113\n",
      "Saving checkpoint 1300\n",
      "[1301,    51] train_loss: 0.5298 | val_loss: 0.1099\n",
      "[1302,    51] train_loss: 0.5277 | val_loss: 0.1106\n",
      "[1303,    51] train_loss: 0.5210 | val_loss: 0.1132\n",
      "[1304,    51] train_loss: 0.5231 | val_loss: 0.1106\n",
      "[1305,    51] train_loss: 0.5180 | val_loss: 0.1118\n",
      "[1306,    51] train_loss: 0.5246 | val_loss: 0.1127\n",
      "[1307,    51] train_loss: 0.5242 | val_loss: 0.1112\n",
      "[1308,    51] train_loss: 0.5261 | val_loss: 0.1125\n",
      "[1309,    51] train_loss: 0.5133 | val_loss: 0.1084\n",
      "[1310,    51] train_loss: 0.5262 | val_loss: 0.1101\n",
      "[1311,    51] train_loss: 0.5232 | val_loss: 0.1104\n",
      "[1312,    51] train_loss: 0.5268 | val_loss: 0.1110\n",
      "[1313,    51] train_loss: 0.5253 | val_loss: 0.1108\n",
      "[1314,    51] train_loss: 0.5280 | val_loss: 0.1105\n",
      "[1315,    51] train_loss: 0.5212 | val_loss: 0.1110\n",
      "[1316,    51] train_loss: 0.5226 | val_loss: 0.1109\n",
      "[1317,    51] train_loss: 0.5230 | val_loss: 0.1122\n",
      "[1318,    51] train_loss: 0.5254 | val_loss: 0.1125\n",
      "[1319,    51] train_loss: 0.5253 | val_loss: 0.1115\n",
      "[1320,    51] train_loss: 0.5283 | val_loss: 0.1116\n",
      "[1321,    51] train_loss: 0.5210 | val_loss: 0.1119\n",
      "[1322,    51] train_loss: 0.5295 | val_loss: 0.1115\n",
      "[1323,    51] train_loss: 0.5242 | val_loss: 0.1117\n",
      "[1324,    51] train_loss: 0.5288 | val_loss: 0.1104\n",
      "[1325,    51] train_loss: 0.5174 | val_loss: 0.1115\n",
      "[1326,    51] train_loss: 0.5219 | val_loss: 0.1091\n",
      "[1327,    51] train_loss: 0.5200 | val_loss: 0.1118\n",
      "[1328,    51] train_loss: 0.5276 | val_loss: 0.1112\n",
      "[1329,    51] train_loss: 0.5222 | val_loss: 0.1119\n",
      "[1330,    51] train_loss: 0.5295 | val_loss: 0.1096\n",
      "[1331,    51] train_loss: 0.5148 | val_loss: 0.1129\n",
      "[1332,    51] train_loss: 0.5136 | val_loss: 0.1119\n",
      "[1333,    51] train_loss: 0.5218 | val_loss: 0.1109\n",
      "[1334,    51] train_loss: 0.5246 | val_loss: 0.1129\n",
      "[1335,    51] train_loss: 0.5143 | val_loss: 0.1102\n",
      "[1336,    51] train_loss: 0.5202 | val_loss: 0.1103\n",
      "[1337,    51] train_loss: 0.5236 | val_loss: 0.1122\n",
      "[1338,    51] train_loss: 0.5266 | val_loss: 0.1124\n",
      "[1339,    51] train_loss: 0.5312 | val_loss: 0.1112\n",
      "[1340,    51] train_loss: 0.5254 | val_loss: 0.1109\n",
      "[1341,    51] train_loss: 0.5205 | val_loss: 0.1106\n",
      "[1342,    51] train_loss: 0.5236 | val_loss: 0.1122\n",
      "[1343,    51] train_loss: 0.5116 | val_loss: 0.1106\n",
      "[1344,    51] train_loss: 0.5248 | val_loss: 0.1120\n",
      "[1345,    51] train_loss: 0.5250 | val_loss: 0.1106\n",
      "[1346,    51] train_loss: 0.5181 | val_loss: 0.1114\n",
      "[1347,    51] train_loss: 0.5232 | val_loss: 0.1091\n",
      "[1348,    51] train_loss: 0.5237 | val_loss: 0.1107\n",
      "[1349,    51] train_loss: 0.5255 | val_loss: 0.1119\n",
      "[1350,    51] train_loss: 0.5205 | val_loss: 0.1103\n",
      "Saving checkpoint 1350\n",
      "[1351,    51] train_loss: 0.5256 | val_loss: 0.1115\n",
      "[1352,    51] train_loss: 0.5130 | val_loss: 0.1128\n",
      "[1353,    51] train_loss: 0.5230 | val_loss: 0.1099\n",
      "[1354,    51] train_loss: 0.5214 | val_loss: 0.1113\n",
      "[1355,    51] train_loss: 0.5288 | val_loss: 0.1111\n",
      "[1356,    51] train_loss: 0.5263 | val_loss: 0.1109\n",
      "[1357,    51] train_loss: 0.5228 | val_loss: 0.1123\n",
      "[1358,    51] train_loss: 0.5247 | val_loss: 0.1109\n",
      "[1359,    51] train_loss: 0.5183 | val_loss: 0.1120\n",
      "[1360,    51] train_loss: 0.5224 | val_loss: 0.1100\n",
      "[1361,    51] train_loss: 0.5222 | val_loss: 0.1119\n",
      "[1362,    51] train_loss: 0.5241 | val_loss: 0.1116\n",
      "[1363,    51] train_loss: 0.5284 | val_loss: 0.1115\n",
      "[1364,    51] train_loss: 0.5174 | val_loss: 0.1104\n",
      "[1365,    51] train_loss: 0.5253 | val_loss: 0.1125\n",
      "[1366,    51] train_loss: 0.5244 | val_loss: 0.1104\n",
      "[1367,    51] train_loss: 0.5246 | val_loss: 0.1113\n",
      "[1368,    51] train_loss: 0.5231 | val_loss: 0.1100\n",
      "[1369,    51] train_loss: 0.5237 | val_loss: 0.1115\n",
      "[1370,    51] train_loss: 0.5157 | val_loss: 0.1106\n",
      "[1371,    51] train_loss: 0.5175 | val_loss: 0.1112\n",
      "[1372,    51] train_loss: 0.5242 | val_loss: 0.1133\n",
      "[1373,    51] train_loss: 0.5209 | val_loss: 0.1102\n",
      "[1374,    51] train_loss: 0.5261 | val_loss: 0.1117\n",
      "[1375,    51] train_loss: 0.5263 | val_loss: 0.1125\n",
      "[1376,    51] train_loss: 0.5286 | val_loss: 0.1103\n",
      "[1377,    51] train_loss: 0.5172 | val_loss: 0.1117\n",
      "[1378,    51] train_loss: 0.5260 | val_loss: 0.1125\n",
      "[1379,    51] train_loss: 0.5267 | val_loss: 0.1103\n",
      "[1380,    51] train_loss: 0.5135 | val_loss: 0.1100\n",
      "[1381,    51] train_loss: 0.5276 | val_loss: 0.1121\n",
      "[1382,    51] train_loss: 0.5216 | val_loss: 0.1129\n",
      "[1383,    51] train_loss: 0.5190 | val_loss: 0.1097\n",
      "[1384,    51] train_loss: 0.5304 | val_loss: 0.1112\n",
      "[1385,    51] train_loss: 0.5206 | val_loss: 0.1111\n",
      "[1386,    51] train_loss: 0.5171 | val_loss: 0.1125\n",
      "[1387,    51] train_loss: 0.5220 | val_loss: 0.1137\n",
      "[1388,    51] train_loss: 0.5235 | val_loss: 0.1095\n",
      "[1389,    51] train_loss: 0.5238 | val_loss: 0.1127\n",
      "[1390,    51] train_loss: 0.5287 | val_loss: 0.1116\n",
      "[1391,    51] train_loss: 0.5189 | val_loss: 0.1089\n",
      "[1392,    51] train_loss: 0.5193 | val_loss: 0.1113\n",
      "[1393,    51] train_loss: 0.5136 | val_loss: 0.1088\n",
      "[1394,    51] train_loss: 0.5199 | val_loss: 0.1104\n",
      "[1395,    51] train_loss: 0.5211 | val_loss: 0.1102\n",
      "[1396,    51] train_loss: 0.5259 | val_loss: 0.1106\n",
      "[1397,    51] train_loss: 0.5164 | val_loss: 0.1084\n",
      "[1398,    51] train_loss: 0.5160 | val_loss: 0.1103\n",
      "[1399,    51] train_loss: 0.5282 | val_loss: 0.1124\n",
      "[1400,    51] train_loss: 0.5214 | val_loss: 0.1106\n",
      "Saving checkpoint 1400\n",
      "[1401,    51] train_loss: 0.5248 | val_loss: 0.1121\n",
      "[1402,    51] train_loss: 0.5262 | val_loss: 0.1125\n",
      "[1403,    51] train_loss: 0.5219 | val_loss: 0.1108\n",
      "[1404,    51] train_loss: 0.5252 | val_loss: 0.1115\n",
      "[1405,    51] train_loss: 0.5280 | val_loss: 0.1118\n",
      "[1406,    51] train_loss: 0.5237 | val_loss: 0.1099\n",
      "[1407,    51] train_loss: 0.5229 | val_loss: 0.1120\n",
      "[1408,    51] train_loss: 0.5144 | val_loss: 0.1101\n",
      "[1409,    51] train_loss: 0.5118 | val_loss: 0.1113\n",
      "[1410,    51] train_loss: 0.5266 | val_loss: 0.1105\n",
      "[1411,    51] train_loss: 0.5128 | val_loss: 0.1110\n",
      "[1412,    51] train_loss: 0.5255 | val_loss: 0.1102\n",
      "[1413,    51] train_loss: 0.5195 | val_loss: 0.1102\n",
      "[1414,    51] train_loss: 0.5280 | val_loss: 0.1130\n",
      "[1415,    51] train_loss: 0.5239 | val_loss: 0.1117\n",
      "[1416,    51] train_loss: 0.5178 | val_loss: 0.1102\n",
      "[1417,    51] train_loss: 0.5186 | val_loss: 0.1116\n",
      "[1418,    51] train_loss: 0.5221 | val_loss: 0.1119\n",
      "[1419,    51] train_loss: 0.5184 | val_loss: 0.1125\n",
      "[1420,    51] train_loss: 0.5220 | val_loss: 0.1120\n",
      "[1421,    51] train_loss: 0.5270 | val_loss: 0.1128\n",
      "[1422,    51] train_loss: 0.5273 | val_loss: 0.1104\n",
      "[1423,    51] train_loss: 0.5263 | val_loss: 0.1098\n",
      "[1424,    51] train_loss: 0.5304 | val_loss: 0.1131\n",
      "[1425,    51] train_loss: 0.5243 | val_loss: 0.1102\n",
      "[1426,    51] train_loss: 0.5248 | val_loss: 0.1114\n",
      "[1427,    51] train_loss: 0.5148 | val_loss: 0.1099\n",
      "[1428,    51] train_loss: 0.5181 | val_loss: 0.1102\n",
      "[1429,    51] train_loss: 0.5265 | val_loss: 0.1099\n",
      "[1430,    51] train_loss: 0.5255 | val_loss: 0.1115\n",
      "[1431,    51] train_loss: 0.5165 | val_loss: 0.1106\n",
      "[1432,    51] train_loss: 0.5235 | val_loss: 0.1128\n",
      "[1433,    51] train_loss: 0.5198 | val_loss: 0.1116\n",
      "[1434,    51] train_loss: 0.5247 | val_loss: 0.1122\n",
      "[1435,    51] train_loss: 0.5184 | val_loss: 0.1117\n",
      "[1436,    51] train_loss: 0.5152 | val_loss: 0.1102\n",
      "[1437,    51] train_loss: 0.5275 | val_loss: 0.1109\n",
      "[1438,    51] train_loss: 0.5288 | val_loss: 0.1113\n",
      "[1439,    51] train_loss: 0.5202 | val_loss: 0.1111\n",
      "[1440,    51] train_loss: 0.5259 | val_loss: 0.1112\n",
      "[1441,    51] train_loss: 0.5266 | val_loss: 0.1107\n",
      "[1442,    51] train_loss: 0.5253 | val_loss: 0.1123\n",
      "[1443,    51] train_loss: 0.5285 | val_loss: 0.1109\n",
      "[1444,    51] train_loss: 0.5307 | val_loss: 0.1108\n",
      "[1445,    51] train_loss: 0.5242 | val_loss: 0.1129\n",
      "[1446,    51] train_loss: 0.5282 | val_loss: 0.1105\n",
      "[1447,    51] train_loss: 0.5225 | val_loss: 0.1118\n",
      "[1448,    51] train_loss: 0.5283 | val_loss: 0.1112\n",
      "[1449,    51] train_loss: 0.5229 | val_loss: 0.1109\n",
      "[1450,    51] train_loss: 0.5215 | val_loss: 0.1107\n",
      "Saving checkpoint 1450\n",
      "[1451,    51] train_loss: 0.5193 | val_loss: 0.1119\n",
      "[1452,    51] train_loss: 0.5313 | val_loss: 0.1107\n",
      "[1453,    51] train_loss: 0.5219 | val_loss: 0.1125\n",
      "[1454,    51] train_loss: 0.5133 | val_loss: 0.1120\n",
      "[1455,    51] train_loss: 0.5271 | val_loss: 0.1111\n",
      "[1456,    51] train_loss: 0.5143 | val_loss: 0.1111\n",
      "[1457,    51] train_loss: 0.5159 | val_loss: 0.1108\n",
      "[1458,    51] train_loss: 0.5203 | val_loss: 0.1097\n",
      "[1459,    51] train_loss: 0.5270 | val_loss: 0.1102\n",
      "[1460,    51] train_loss: 0.5182 | val_loss: 0.1108\n",
      "[1461,    51] train_loss: 0.5238 | val_loss: 0.1115\n",
      "[1462,    51] train_loss: 0.5225 | val_loss: 0.1144\n",
      "[1463,    51] train_loss: 0.5272 | val_loss: 0.1114\n",
      "[1464,    51] train_loss: 0.5253 | val_loss: 0.1127\n",
      "[1465,    51] train_loss: 0.5164 | val_loss: 0.1091\n",
      "[1466,    51] train_loss: 0.5285 | val_loss: 0.1133\n",
      "[1467,    51] train_loss: 0.5247 | val_loss: 0.1116\n",
      "[1468,    51] train_loss: 0.5245 | val_loss: 0.1111\n",
      "[1469,    51] train_loss: 0.5230 | val_loss: 0.1114\n",
      "[1470,    51] train_loss: 0.5240 | val_loss: 0.1115\n",
      "[1471,    51] train_loss: 0.5226 | val_loss: 0.1119\n",
      "[1472,    51] train_loss: 0.5278 | val_loss: 0.1123\n",
      "[1473,    51] train_loss: 0.5265 | val_loss: 0.1126\n",
      "[1474,    51] train_loss: 0.5240 | val_loss: 0.1118\n",
      "[1475,    51] train_loss: 0.5154 | val_loss: 0.1103\n",
      "[1476,    51] train_loss: 0.5137 | val_loss: 0.1113\n",
      "[1477,    51] train_loss: 0.5260 | val_loss: 0.1105\n",
      "[1478,    51] train_loss: 0.5254 | val_loss: 0.1118\n",
      "[1479,    51] train_loss: 0.5218 | val_loss: 0.1109\n",
      "[1480,    51] train_loss: 0.5231 | val_loss: 0.1119\n",
      "[1481,    51] train_loss: 0.5217 | val_loss: 0.1114\n",
      "[1482,    51] train_loss: 0.5167 | val_loss: 0.1111\n",
      "[1483,    51] train_loss: 0.5254 | val_loss: 0.1120\n",
      "[1484,    51] train_loss: 0.5288 | val_loss: 0.1113\n",
      "[1485,    51] train_loss: 0.5352 | val_loss: 0.1109\n",
      "[1486,    51] train_loss: 0.5248 | val_loss: 0.1113\n",
      "[1487,    51] train_loss: 0.5149 | val_loss: 0.1110\n",
      "[1488,    51] train_loss: 0.5285 | val_loss: 0.1120\n",
      "[1489,    51] train_loss: 0.5207 | val_loss: 0.1124\n",
      "[1490,    51] train_loss: 0.5318 | val_loss: 0.1094\n",
      "[1491,    51] train_loss: 0.5269 | val_loss: 0.1107\n",
      "[1492,    51] train_loss: 0.5181 | val_loss: 0.1130\n",
      "[1493,    51] train_loss: 0.5179 | val_loss: 0.1110\n",
      "[1494,    51] train_loss: 0.5248 | val_loss: 0.1110\n",
      "[1495,    51] train_loss: 0.5222 | val_loss: 0.1088\n",
      "[1496,    51] train_loss: 0.5271 | val_loss: 0.1113\n",
      "[1497,    51] train_loss: 0.5239 | val_loss: 0.1126\n",
      "[1498,    51] train_loss: 0.5161 | val_loss: 0.1109\n",
      "[1499,    51] train_loss: 0.5218 | val_loss: 0.1102\n",
      "Saving checkpoint 1499\n",
      "[1500,    51] train_loss: 0.5278 | val_loss: 0.1112\n",
      "Total train time: 2494.932124332587min\n",
      "Evaluating model...\n",
      "Using 2053 samples for validation set\n",
      "8211 total training samples\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lmeyers/ReID_complete/SCL_reID/train/pytorch_train_and_eval_reid_2.py\", line 396, in <module>\n",
      "    train_and_eval(args.config_file)\n",
      "  File \"/home/lmeyers/ReID_complete/SCL_reID/train/pytorch_train_and_eval_reid_2.py\", line 336, in train_and_eval\n",
      "    reference_embeddings, reference_labels, reference_loss = get_embeddings(model, reference_dataloader, loss_fn, miner, device, feature_extractor)\n",
      "UnboundLocalError: local variable 'reference_dataloader' referenced before assignment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train loss ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: triplet_num ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid loss ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train loss 0.14333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: triplet_num 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid loss 0.11123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mwise-valley-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/vit_baselines_test64_ids_batch2_sample_num_64/runs/8mp1hgly\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/home/lmeyers/contrastive_learning_new_training/64_ids_batch2_sample_num_64/wandb/run-20240914_045459-8mp1hgly/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If testing multiple lengths of training, add multiple #'s to epochs_to_test\n",
    "epochs_to_test = [1500]\n",
    "\n",
    "#Loops through number of epochs\n",
    "for n in epochs_to_test: \n",
    "    \n",
    "    #Loops through files\n",
    "    for i in range(len(file_paths)):\n",
    "        train_file = file_paths[i] #train file path\n",
    "       \n",
    "        if i == 0: #for training on different batches at the same time\\\n",
    "            reference_file = '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_02.csv'\n",
    "            test_file = '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch2/summer_bee_dataset_open_train_bee_64_ids_batch2_sample_num_max.csv'\n",
    "        else:\n",
    "            reference_file = '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_02.csv'\n",
    "            test_file = '/home/lmeyers/summer_bee_data_reextract/new_open_max_ids_batch1/summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_max.csv'\n",
    "\n",
    "\n",
    "        ##----------------Filter particular runs (if needed)----------\n",
    "        #if num_images == 'max':\n",
    "\n",
    "        ##---------- Initilize new config .yml for new training file---------------\n",
    "        \n",
    "        #open config yaml to update experiment params\n",
    "        with open('../yml_and_csv_files/reid_template.yml', 'r') as fo:\n",
    "            config = yaml.safe_load(fo)\n",
    "        \n",
    "        #------------ Initilize and make new dir for each training set-----\n",
    "\n",
    "        # Saves wandb folder, checkpoints, and outputs to folder named based on run string, which should contain attrs that differntiate run\n",
    "        run_str = os.path.basename(train_file)[34:-4] #MAY NEED TO MODIFY BASED ON CSV NAME\n",
    "        run_dir_name = os.path.join(config['train_settings']['wandb_dir_path'],run_str+'/')\n",
    "        if not os.path.exists(run_dir_name):\n",
    "            os.mkdir(run_dir_name)\n",
    "        split_parts = run_str.rsplit('_', 1) #String parse csv name\n",
    "        if len(split_parts) > 1: # Check if there is at least one underscore in the string\n",
    "            # Get the substring after the last underscore\n",
    "            num_images = split_parts[1]\n",
    "            num_ids = split_parts[0][:2]\n",
    "        else:\n",
    "            # Handle the case where there are no underscores in the string\n",
    "            num_images = run_str \n",
    "        \n",
    "        # Saves wandb folder, checkpoints, and outputs to folder named based on run string, which should contain attrs that differntiate run\n",
    "        wandb_name =  config['train_settings']['wandb_project_name']+run_str #set wandb_dir_name\n",
    "        \n",
    "        #Update params\n",
    "        config['model_settings']['num_labels']= num_ids\n",
    "        print('Num labels ',num_ids)\n",
    "\n",
    "        #Check if batch size needs to be updated\n",
    "        df = pd.read_csv(train_file)\n",
    "        if config['data_settings']['batch_size'] > len(df):\n",
    "            config['data_settings']['batch_size'] = len(df)\n",
    "            print('Updated batch to contain all Data. Size = ',len(df))\n",
    "        \n",
    "        #Check if print_k needs to be updated for small dataset\n",
    "        print_k = config['train_settings']['print_k']\n",
    "        if print_k > len(df)/config['data_settings']['batch_size']:\n",
    "            print_k = len(df)/config['data_settings']['batch_size']\n",
    "            config['train_settings']['print_k'] = print_k\n",
    "            print('Updating print_k to contain whole epoch. Num_batches =',print_k)\n",
    "        \n",
    "        #Testing a differnt num of epochs based on loop\n",
    "        config['train_settings']['num_epochs'] = n\n",
    "\n",
    "        #updating datafiles\n",
    "        config['data_settings']['datafiles']['train']=train_file\n",
    "        config['data_settings']['datafiles']['reference']= reference_file\n",
    "\n",
    "        #config['data_settings']['datafiles']['train']=train_csv\n",
    "        config['data_settings']['datafiles']['test'] = test_file\n",
    "        config['data_settings']['datafiles']['valid']= ''\n",
    "        config['data_settings']['datafiles']['query']= test_file\n",
    "\n",
    "        #update Model path\n",
    "        config['model_settings']['model_path'] = os.path.join(run_dir_name,run_str+'.pth')\n",
    "\n",
    "        #update pickle_file to prevent being overwritten\n",
    "        pickle_file = os.path.join(run_dir_name,'results.pkl')\n",
    "        config['eval_settings']['pickle_file'] = pickle_file\n",
    "        csv_file = os.path.join(run_dir_name,\"results.csv\")\n",
    "        config['eval_settings']['results_file'] = csv_file\n",
    "\n",
    "        #update wandb_project_name\n",
    "        config['train_settings']['wandb_project_name'] = wandb_name\n",
    "        config['train_settings']['wandb_dir_path'] = run_dir_name #this should make a seperate wandb folder for runs\n",
    "\n",
    "        #save yml\n",
    "        new_yml_file = run_dir_name+run_str+'.yml'\n",
    "        with open(new_yml_file, 'w') as fo:\n",
    "                yaml.dump(config,fo)   \n",
    "\n",
    "        #---------- actually run training too--------------\n",
    "        !python pytorch_train_and_eval_reid_2.py --config_file {new_yml_file}\n",
    "\n",
    "        # Save model to wandb file location to prevent overwriting\n",
    "        # new dir in wandb/ will be generated each training run\n",
    "        !cp {config['model_settings']['model_path']} {config['train_settings']['wandb_dir_path']+'/wandb/latest-run/files/'+os.path.basename(config['model_settings']['model_path'])}\n",
    "\n",
    "        # read python results from pickle file, \n",
    "        with open(config['eval_settings']['pickle_file'],'rb') as fi:\n",
    "            results = pickle.load(fi)  \n",
    "            \n",
    "        # Write out run summary to results tracking document\n",
    "       \n",
    "        results_dict =  {'run_str': run_str,\n",
    "                                            'wandb_id':results['wandb_id'],\n",
    "                                            'num_ids':num_ids,\n",
    "                                            'num_images_per_id':num_images,\n",
    "                                            'total_training_images':len(pd.read_csv(train_file))-(len(pd.read_csv(train_file))*config['data_settings']['percent_valid']),\n",
    "                                            'batch_size':config['data_settings']['batch_size'],\n",
    "                                            'num_epochs':config['train_settings']['num_epochs'],\n",
    "                                            'train_loss':results['train_loss'],\n",
    "                                            'valid_loss':results['valid_loss'],\n",
    "                                            '1NN':results['1NN_acc'],\n",
    "                                            '3NN':results['3NN_acc'],\n",
    "                                            'training_file':train_file,\n",
    "                                            'reference_file':reference_file,\n",
    "                                            'query_file':test_file,\n",
    "                                            'start_time':results['start_time'],\n",
    "                                            'train_time':results['train_time'],\n",
    "                                            'stop_epoch':results['stop_epoch']}\n",
    "        \n",
    "        if not os.path.exists(config['eval_settings']['results_file']):\n",
    "            !touch {config['eval_settings']['results_file']}\n",
    "            results_df = pd.DataFrame(results_dict,index=[0])\n",
    "            results_df.to_csv(config['eval_settings']['results_file'])\n",
    "        else:\n",
    "            #read df and append row\n",
    "            results_df = pd.read_csv(config['eval_settings']['results_file'])\n",
    "            results_df.loc[len(results_df)] = results_dict\n",
    "            results_df.to_csv(config['eval_settings']['results_file'],index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc0b48",
   "metadata": {},
   "source": [
    "## If folder contains csvs from both batches: run below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06a4c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsantiago/summer_bee_data/open_sets/new_open_04_ids_all_colors_batch1/summer_bee_dataset_open_train_bee_4_ids_batch1_sample_num_max.csv\n",
      "/home/gsantiago/summer_bee_data/open_sets/new_open_04_ids_all_colors_batch1/summer_bee_dataset_open_train_bee_4_ids_batch1_sample_num_16.csv\n",
      "/home/gsantiago/summer_bee_data/open_sets/new_open_04_ids_all_colors_batch1/summer_bee_dataset_open_train_bee_4_ids_batch1_sample_num_04.csv\n",
      "32 4\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './reid_template.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_images, num_ids)\n\u001b[1;32m    102\u001b[0m  \u001b[38;5;66;03m#open config yaml to update experiment params\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./reid_template.yml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fo:\n\u001b[1;32m    104\u001b[0m     config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(fo)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m#Update params\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#num labels should be taken from pandas because batch1!=batch2\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './reid_template.yml'"
     ]
    }
   ],
   "source": [
    "# if you want only train on batch1, add the string after the asterisk\n",
    "#here im training on 32 ids batch1\n",
    "directory_of_csvs ='/home/gsantiago/summer_bee_data/open_sets/new*04*batch1'\n",
    "\n",
    "sample_num_of_interest = \"sample_num_\"\n",
    "\n",
    "#this variable is for creating a folder that will contain the files we want\n",
    "type_of_train_wanted = '/home/gsantiago/ReID_model_training/new_auto_train_eval/models_trained/'\n",
    "#type_of_train_wanted = '/home/lmeyers/ReID_complete/few_shot_experiments/new_training_models/'\n",
    "\n",
    "#wandb_dir_name is the directory where eveything wandb saves or whatevah\n",
    "wandb_dir_name = \"/home/gsantiago/ReID_model_training/new_auto_train_eval/models_trained/\"\n",
    "\n",
    "results_pickle=\"/home/gsantiago/ReID_model_training/new_auto_train_eval/\"\n",
    "\n",
    "csv_for_results = \"/home/gsantiago/ReID_model_training/new_auto_train_eval/Few_shot_expirament_results_tracking.csv\"\n",
    "epochs_to_test = [1500]\n",
    "label_col = 'reID'\n",
    "gpu_id = '1'\n",
    "\n",
    "\n",
    "\n",
    "## optional!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "## REMOVE LATER\n",
    "\n",
    "\n",
    "non_trained_models=[\n",
    "\n",
    "# '/home/gsantiago/summer_bee_data/open_sets/new_open_04_ids_all_colors_batch1/summer_bee_dataset_open_train_bee_4_ids_batch1_sample_num_16.csv',\n",
    "\n",
    "'/home/gsantiago/summer_bee_data/open_sets/new_open_04_ids_all_colors_batch1/summer_bee_dataset_open_train_bee_4_ids_batch1_sample_num_32.csv',\n",
    "\n",
    "'/home/gsantiago/summer_bee_data/open_sets/new_open_04_ids_all_colors_batch1/summer_bee_dataset_open_train_bee_4_ids_batch1_sample_num_64.csv'\n",
    "\n",
    "]\n",
    "if not os.path.exists(type_of_train_wanted):\n",
    "    os.mkdir(type_of_train_wanted)\n",
    "\n",
    "\n",
    "\n",
    "for n in epochs_to_test:\n",
    "    #loops through every file that starts with that string\n",
    "    for split in glob(directory_of_csvs):\n",
    "        #print(split)\n",
    "        \n",
    "        #get number of batch to reference and test on the other\n",
    "        \n",
    "        batch = split.split('_')[-1]\n",
    "        #print(batch)\n",
    "        #print(os.path.dirname(split))\n",
    "        parent_dir = os.path.dirname(split)\n",
    "        \n",
    "        if batch == \"batch1\":\n",
    "            query_file = parent_dir +'/open_reference_query_testing_batch2/summer_bee_dataset_closed_test_bee_query_64_ids_batch2.csv'\n",
    "            reference_file = parent_dir +'/open_reference_query_testing_batch2/summer_bee_dataset_closed_test_bee_reference_64_ids_batch2.csv'\n",
    "            valid_file = parent_dir +'/open_reference_query_testing_batch2/summer_bee_dataset_closed_test_bee_valid_64_ids_batch2.csv'\n",
    "        else:\n",
    "            query_file = parent_dir +'/open_reference_query_testing_batch1/summer_bee_dataset_closed_test_bee_query_64_ids_batch1.csv'\n",
    "            reference_file = parent_dir +'/open_reference_query_testing_batch1/summer_bee_dataset_closed_test_bee_reference_64_ids_batch1.csv'\n",
    "            valid_file = parent_dir +'/open_reference_query_testing_batch1/summer_bee_dataset_closed_test_bee_valid_64_ids_batch1.csv'\n",
    "        split +='/*'+sample_num_of_interest+'*'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #this loops through each directory and takes the csv with the sample num of interest\n",
    "        # if you want to loop through every sample num, sample_num should be \"sample_num\"\n",
    "        for csv in glob(split):\n",
    "            if csv not in non_trained_models:\n",
    "                print(csv)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            train_file = csv\n",
    "            wandb_name = os.path.basename(os.path.dirname(train_file))\n",
    "            run_str = os.path.basename(train_file)[:-4]\n",
    "            run_dir_name = type_of_train_wanted+run_str+'/'\n",
    "            #print(wandb_name)\n",
    "            if not os.path.exists(run_dir_name):\n",
    "                os.mkdir(run_dir_name)\n",
    "            #print(run_dir_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            split_parts = train_file.split('/')[-1].split('_')\n",
    "            #print(split_parts)\n",
    "            # Check if there is at least one underscore in the string\n",
    "            if len(split_parts) > 1:\n",
    "                # Get the substring after the last underscore\n",
    "                num_images = split_parts[-1].replace('.csv', '')\n",
    "                num_ids = split_parts[6]\n",
    "            else:\n",
    "                # Handle the case where there are no underscores in the string\n",
    "                num_images = run_str\n",
    "\n",
    "            print(num_images, num_ids)\n",
    "\n",
    "             #open config yaml to update experiment params\n",
    "            with open('./reid_template.yml', 'r') as fo:\n",
    "                config = yaml.safe_load(fo)\n",
    "\n",
    "            #Update params\n",
    "\n",
    "            #num labels should be taken from pandas because batch1!=batch2\n",
    "\n",
    "            df = pd.read_csv(train_file)\n",
    "            num_labels = df['ID'].nunique()\n",
    "\n",
    "            config['model_settings']['num_labels']= num_labels\n",
    "            \n",
    "            \n",
    "            #ubdating label_col\n",
    "            config['data_settings']['label_col']=  label_col\n",
    "            \n",
    "            #gpu\n",
    "            config['train_settings']['gpu'] = gpu_id\n",
    "            print('Num labels ',num_labels)\n",
    "\n",
    "            #Check if batch size needs to be updated\n",
    "\n",
    "            config['data_settings']['batch_size'] = 64\n",
    "            if config['data_settings']['batch_size'] > len(df):\n",
    "                config['data_settings']['batch_size'] = len(df)\n",
    "                print('Updated batch to contain all Data. Size = ',len(df))\n",
    "\n",
    "            #Check if print_k needs to be updated for small dataset\n",
    "            print_k = config['train_settings']['print_k']\n",
    "            if print_k > len(df)/config['data_settings']['batch_size']:\n",
    "                print_k = len(df)/config['data_settings']['batch_size']\n",
    "                config['train_settings']['print_k'] = print_k\n",
    "                print('Updating print_k to contain whole epoch. Num_batches =',print_k)\n",
    "\n",
    "            #Testing a differnt num epochs (EXPIRAMENT HERE)\n",
    "            config['train_settings']['num_epochs'] = n\n",
    "\n",
    "            #updating datafiles\n",
    "            config['data_settings']['datafiles']['train']=train_file\n",
    "            config['data_settings']['datafiles']['reference']= reference_file\n",
    "\n",
    "\n",
    "            #config['data_settings']['datafiles']['train']=train_csv\n",
    "            config['data_settings']['datafiles']['test'] = query_file\n",
    "            config['data_settings']['datafiles']['valid']= valid_file \n",
    "            config['data_settings']['datafiles']['query']= query_file\n",
    "\n",
    "            #update Model path\n",
    "            config['model_settings']['model_path'] = run_dir_name+run_str+'.pth'\n",
    "\n",
    "            #update wandb_project_name\n",
    "            config['train_settings']['wandb_project_name'] = wandb_name\n",
    "            config['train_settings']['wandb_dir_path'] = wandb_dir_name + run_str #this should make a seperate wandb folder for runs\n",
    "            \n",
    "            #pickle_config_file\n",
    "            config['eval_settings']['pickle_file'] = results_pickle+ 'results.pkl'\n",
    "            config['eval_settings']['results_file']= csv_for_results\n",
    "            \n",
    "#             #\"\"\"\n",
    "#             #skipping max because I already ran it\n",
    "#             if num_images not in [64, '64'] and 'monocolor' not in run_str:\n",
    "#                 print('Skipping')\n",
    "#                 continue\n",
    "#             #\"\"\"\n",
    "\n",
    "            #save yml\n",
    "            new_yml_file = run_dir_name+run_str+'.yml'\n",
    "            with open(new_yml_file, 'w') as fo:\n",
    "                    yaml.dump(config,fo)   \n",
    "\n",
    "            #---------- actually run training too--------------\n",
    "            !python3 pytorch_train_and_eval_reid_2.py --config_file {new_yml_file}\n",
    "\n",
    "            # Save model to wandb file location to prevent overwriting\n",
    "            !cp {config['model_settings']['model_path']} {config['train_settings']['wandb_dir_path']+'/wandb/latest-run/files/'+os.path.basename(config['model_settings']['model_path'])}\n",
    "\n",
    "            with open(config['eval_settings']['pickle_file'],'rb') as fi:\n",
    "                results = pickle.load(fi)  \n",
    "\n",
    "            # Write out run summary to results tracking document\n",
    "            results_df = pd.read_csv(config['eval_settings']['results_file'])\n",
    "            results_df.loc[len(results_df)] = {'run_str': run_str,\n",
    "                                                'wandb_id':results['wandb_id'],\n",
    "                                                'num_ids':num_ids,\n",
    "                                                'num_images_per_id':num_images,\n",
    "                                                'total_training_images':len(pd.read_csv(train_file)),\n",
    "                                                'batch_size':config['data_settings']['batch_size'],\n",
    "                                                'num_epochs':config['train_settings']['num_epochs'],\n",
    "                                                'train_loss':results['train_loss'],\n",
    "                                                'valid_loss':results['valid_loss'],\n",
    "                                                '1NN':results['1NN_acc'],\n",
    "                                                '3NN':results['3NN_acc'],\n",
    "                                                'training_file':train_file,\n",
    "                                                'reference_file':reference_file,\n",
    "                                                'query_file':query_file,\n",
    "                                                'start_time':results['start_time'],\n",
    "                                                'train_time':results['train_time'],\n",
    "                                                'stop_epoch':results['stop_epoch']}\n",
    "            results_df.to_csv(config['eval_settings']['results_file'],index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c200c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61825432",
   "metadata": {},
   "source": [
    "#### In event of run failure to record automatically\n",
    "Use below code to save run details from results.pickle even if there was an issue in your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad9149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(config['eval_settings']['pickle_file'],'rb') as fi:\n",
    "    results = pickle.load(fi)   \n",
    "\n",
    "# Write out run summary to results tracking document\n",
    "results_df = pd.read_csv(config['eval_settings']['results_file'])\n",
    "results_df.loc[len(results_df)] = {'run_str': run_str,\n",
    "                                    'wandb_id':results['wandb_id'],\n",
    "                                    'num_ids':num_ids,\n",
    "                                    'num_images_per_id':num_images,\n",
    "                                    'total_training_images':len(pd.read_csv(train_file)),\n",
    "                                    'batch_size':config['data_settings']['batch_size'],\n",
    "                                    'num_epochs':config['train_settings']['num_epochs'],\n",
    "                                    'train_loss':results['train_loss'],\n",
    "                                    'valid_loss':results['valid_loss'],\n",
    "                                    '1NN':results['1NN_acc'],\n",
    "                                    '3NN':results['3NN_acc'],\n",
    "                                    'training_file':train_file,\n",
    "                                    'reference_file':reference_file,\n",
    "                                    'query_file':query_file,\n",
    "                                    'start_time':results['start_time'],\n",
    "                                    'train_time':results['train_time'],\n",
    "                                    'stop_epoch':results['stop_epoch']}\n",
    "results_df.to_csv(config['eval_settings']['results_file'],index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
