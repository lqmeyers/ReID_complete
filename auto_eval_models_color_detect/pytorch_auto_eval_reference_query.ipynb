{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04098bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "import os\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5d774",
   "metadata": {},
   "source": [
    "## Reference train set, query test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a61ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_32', '/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_max', '/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_08', '/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_64']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_32',\n",
       " '/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_08',\n",
       " '/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_64']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##FILTer OUT THE MODELS TO TRAIN\n",
    "\n",
    "directory_of_models_trained_64 =  '/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_**'\n",
    "globbed_dir = glob(directory_of_models_trained_64)\n",
    "print(globbed_dir)\n",
    "\n",
    "replaced_models = ['non_permutated',\"16_ids_monocolor_and\",'16_ids_four_times_colors_batch','_4_ids_','double_colors','max']\n",
    "wanted = []\n",
    "for i in globbed_dir:\n",
    "    found = False\n",
    "    for j in replaced_models:\n",
    "        \n",
    "        if j in i:\n",
    "            found =True\n",
    "    if(not found):\n",
    "        wanted.append(i)\n",
    "        \n",
    "directory_of_models_trained_all_ids = '/data/new_reid_models/summer_bee_dataset_open_train_bee_64_ids_batch1_*'\n",
    "\n",
    "for i in glob(directory_of_models_trained_all_ids):\n",
    "    wanted.append(i)\n",
    "wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69b8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_64']\n"
     ]
    }
   ],
   "source": [
    "wanted = []\n",
    "\"\"\"\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/8_ids_double_colors_batch1_sample_num_64')\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/16_ids_four_times_permutated_colors_batch1_sample_num_64')\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/4_ids_batch1_sample_num_64')\n",
    "wanted.append('/home/jrodriguez/color_detect_experiments/_ids_permutated_ids_batch1_sample_num_64')\n",
    "wanted.append('/home/jrodriguez/color_detect_experiments/_ids_monocolor_and_permutated_ids_batch1_sample_num_64')\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/_ids_batch1_sample_num_16')\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/_ids_batch1_sample_num_08')\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/_ids_batch1_sample_num_04')\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/_ids_batch1_sample_num_02')\n",
    "\"\"\"\n",
    "wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/64_ids_batch1_sample_num_64')\n",
    "#wanted.append('/home/lmeyers/ReID_complete/color_detect_experiments/4_ids_batch1_sample_num_64')\n",
    "print(wanted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/64_ids/summer_bee_dataset_closed_test_bee_query_64_ids_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/32_ids_non_permuated/summer_bee_dataset_closed_test_bee_query_32_ids_non_permutated_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/8_ids_monocolor/summer_bee_dataset_closed_test_bee_query_8_ids_monocolor_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/16_ids_permutated/summer_bee_dataset_closed_test_bee_query_16_ids_permutated_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/16_ids_non_permutated/summer_bee_dataset_closed_test_bee_query_16_ids_non_permutated_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/32_ids_permutated/summer_bee_dataset_closed_test_bee_query_32_ids_permutated_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/24_non_permutated/summer_bee_dataset_closed_test_bee_query_24_ids_non_permutated_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/24_ids_permutated/summer_bee_dataset_closed_test_bee_query_24_ids_permutated_batch2_sample_num_64.csv', '/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/8_ids_bicolor/summer_bee_dataset_closed_test_bee_query_8_ids_bicolor_batch2_sample_num_64.csv']\n"
     ]
    }
   ],
   "source": [
    "query_files = os.walk('/home/gsantiago/summer_bee_data/open_sets/visapp_open_reference_query_testing_batch2/')\n",
    "tckr = 0 \n",
    "\n",
    "files_all = []\n",
    "for root, dir, files in query_files:\n",
    "    for f in files:\n",
    "        if 'query' in f:\n",
    "            files_all.append(root+r'/'+f)\n",
    "\n",
    "print(files_all)\n",
    "#test_csvs ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473537ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:09:53.262479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:09:54.434690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3129.0 out of 3880 = 0.8064432989690722\n",
      "Total Correct_ID Samples 3232.0 out of 3880 = 0.8329896907216495\n",
      "Total Acc: tensor(0.9778)\n",
      "Total Precision: tensor(0.9097)\n",
      "Total Recall: tensor(0.9225)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:10:40.441614: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:10:41.921390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3235.0 out of 3880 = 0.8337628865979382\n",
      "Total Correct_ID Samples 3349.0 out of 3880 = 0.8631443298969073\n",
      "Total Acc: tensor(0.9821)\n",
      "Total Precision: tensor(0.9265)\n",
      "Total Recall: tensor(0.9357)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:11:23.003808: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:11:24.390620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3210.0 out of 3880 = 0.8273195876288659\n",
      "Total Correct_ID Samples 3294.0 out of 3880 = 0.8489690721649484\n",
      "Total Acc: tensor(0.9809)\n",
      "Total Precision: tensor(0.9223)\n",
      "Total Recall: tensor(0.9310)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:12:07.968742: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:12:09.435841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3196.0 out of 3880 = 0.8237113402061855\n",
      "Total Correct_ID Samples 3295.0 out of 3880 = 0.8492268041237113\n",
      "Total Acc: tensor(0.9802)\n",
      "Total Precision: tensor(0.9218)\n",
      "Total Recall: tensor(0.9273)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:12:53.688104: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:12:55.039972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 1890.0 out of 3880 = 0.48711340206185566\n",
      "Total Correct_ID Samples 2648.0 out of 3880 = 0.6824742268041237\n",
      "Total Acc: tensor(0.9583)\n",
      "Total Precision: tensor(0.8132)\n",
      "Total Recall: tensor(0.9338)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:13:36.831520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:13:37.969626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3088.0 out of 3880 = 0.7958762886597938\n",
      "Total Correct_ID Samples 3245.0 out of 3880 = 0.836340206185567\n",
      "Total Acc: tensor(0.9781)\n",
      "Total Precision: tensor(0.9112)\n",
      "Total Recall: tensor(0.9236)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:14:18.225086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:14:19.457747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3236.0 out of 3880 = 0.8340206185567011\n",
      "Total Correct_ID Samples 3305.0 out of 3880 = 0.8518041237113402\n",
      "Total Acc: tensor(0.9822)\n",
      "Total Precision: tensor(0.9279)\n",
      "Total Recall: tensor(0.9355)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:15:01.399361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:15:02.842137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3241.0 out of 3880 = 0.8353092783505155\n",
      "Total Correct_ID Samples 3332.0 out of 3880 = 0.8587628865979381\n",
      "Total Acc: tensor(0.9810)\n",
      "Total Precision: tensor(0.9226)\n",
      "Total Recall: tensor(0.9305)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:15:43.809640: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:15:45.194597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3193.0 out of 3880 = 0.8229381443298969\n",
      "Total Correct_ID Samples 3287.0 out of 3880 = 0.8471649484536082\n",
      "Total Acc: tensor(0.9812)\n",
      "Total Precision: tensor(0.9244)\n",
      "Total Recall: tensor(0.9316)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:16:27.186512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:16:28.388914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3239.0 out of 3880 = 0.8347938144329897\n",
      "Total Correct_ID Samples 3317.0 out of 3880 = 0.8548969072164948\n",
      "Total Acc: tensor(0.9823)\n",
      "Total Precision: tensor(0.9277)\n",
      "Total Recall: tensor(0.9332)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:17:09.059133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:17:10.244428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 163.0 out of 3880 = 0.04201030927835052\n",
      "Total Correct_ID Samples 1040.0 out of 3880 = 0.26804123711340205\n",
      "Total Acc: tensor(0.8930)\n",
      "Total Precision: tensor(0.5813)\n",
      "Total Recall: tensor(0.8350)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:17:51.701669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:17:52.886001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 2411.0 out of 3880 = 0.6213917525773196\n",
      "Total Correct_ID Samples 2887.0 out of 3880 = 0.7440721649484536\n",
      "Total Acc: tensor(0.9681)\n",
      "Total Precision: tensor(0.8584)\n",
      "Total Recall: tensor(0.9332)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:18:34.143200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:18:35.318503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3253.0 out of 3880 = 0.8384020618556701\n",
      "Total Correct_ID Samples 3318.0 out of 3880 = 0.8551546391752577\n",
      "Total Acc: tensor(0.9829)\n",
      "Total Precision: tensor(0.9318)\n",
      "Total Recall: tensor(0.9373)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:19:16.064989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:19:17.372592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Total Correct Samples 3208.0 out of 3880 = 0.8268041237113402\n",
      "Total Correct_ID Samples 3281.0 out of 3880 = 0.8456185567010309\n",
      "Total Acc: tensor(0.9800)\n",
      "Total Precision: tensor(0.9183)\n",
      "Total Recall: tensor(0.9220)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:19:58.791044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:20:00.116417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1532.0 out of 1976 = 0.7753036437246964\n",
      "Total Correct_ID Samples 1570.0 out of 1976 = 0.7945344129554656\n",
      "Total Acc: tensor(0.9744)\n",
      "Total Precision: tensor(0.8962)\n",
      "Total Recall: tensor(0.9053)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:20:27.996009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:20:29.204395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1596.0 out of 1976 = 0.8076923076923077\n",
      "Total Correct_ID Samples 1650.0 out of 1976 = 0.8350202429149798\n",
      "Total Acc: tensor(0.9783)\n",
      "Total Precision: tensor(0.9131)\n",
      "Total Recall: tensor(0.9201)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:20:58.015559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:20:59.258730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1611.0 out of 1976 = 0.8152834008097166\n",
      "Total Correct_ID Samples 1634.0 out of 1976 = 0.8269230769230769\n",
      "Total Acc: tensor(0.9784)\n",
      "Total Precision: tensor(0.9134)\n",
      "Total Recall: tensor(0.9167)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:21:27.561079: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:21:28.711174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1521.0 out of 1976 = 0.7697368421052632\n",
      "Total Correct_ID Samples 1574.0 out of 1976 = 0.7965587044534413\n",
      "Total Acc: tensor(0.9737)\n",
      "Total Precision: tensor(0.8973)\n",
      "Total Recall: tensor(0.8998)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:21:58.214385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:21:59.647301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 935.0 out of 1976 = 0.4731781376518219\n",
      "Total Correct_ID Samples 1310.0 out of 1976 = 0.6629554655870445\n",
      "Total Acc: tensor(0.9555)\n",
      "Total Precision: tensor(0.8019)\n",
      "Total Recall: tensor(0.9306)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:22:29.204122: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:22:30.552927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1454.0 out of 1976 = 0.7358299595141701\n",
      "Total Correct_ID Samples 1531.0 out of 1976 = 0.7747975708502024\n",
      "Total Acc: tensor(0.9721)\n",
      "Total Precision: tensor(0.8882)\n",
      "Total Recall: tensor(0.9062)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:23:01.942234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:23:03.308485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1571.0 out of 1976 = 0.7950404858299596\n",
      "Total Correct_ID Samples 1603.0 out of 1976 = 0.8112348178137652\n",
      "Total Acc: tensor(0.9779)\n",
      "Total Precision: tensor(0.9135)\n",
      "Total Recall: tensor(0.9164)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:23:31.905326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:23:33.060761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1586.0 out of 1976 = 0.8026315789473685\n",
      "Total Correct_ID Samples 1627.0 out of 1976 = 0.8233805668016194\n",
      "Total Acc: tensor(0.9774)\n",
      "Total Precision: tensor(0.9091)\n",
      "Total Recall: tensor(0.9153)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:24:02.026474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:24:03.505137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1565.0 out of 1976 = 0.792004048582996\n",
      "Total Correct_ID Samples 1591.0 out of 1976 = 0.805161943319838\n",
      "Total Acc: tensor(0.9761)\n",
      "Total Precision: tensor(0.9041)\n",
      "Total Recall: tensor(0.9091)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:24:32.246511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:24:33.446532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1613.0 out of 1976 = 0.8162955465587044\n",
      "Total Correct_ID Samples 1642.0 out of 1976 = 0.8309716599190283\n",
      "Total Acc: tensor(0.9799)\n",
      "Total Precision: tensor(0.9219)\n",
      "Total Recall: tensor(0.9220)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:25:04.193863: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:25:05.637787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 24.0 out of 1976 = 0.012145748987854251\n",
      "Total Correct_ID Samples 442.0 out of 1976 = 0.2236842105263158\n",
      "Total Acc: tensor(0.8877)\n",
      "Total Precision: tensor(0.5583)\n",
      "Total Recall: tensor(0.8198)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:25:34.092837: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:25:35.423849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1243.0 out of 1976 = 0.6290485829959515\n",
      "Total Correct_ID Samples 1478.0 out of 1976 = 0.7479757085020243\n",
      "Total Acc: tensor(0.9677)\n",
      "Total Precision: tensor(0.8599)\n",
      "Total Recall: tensor(0.9309)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:26:03.759246: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:26:04.956402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1658.0 out of 1976 = 0.8390688259109311\n",
      "Total Correct_ID Samples 1690.0 out of 1976 = 0.8552631578947368\n",
      "Total Acc: tensor(0.9822)\n",
      "Total Precision: tensor(0.9297)\n",
      "Total Recall: tensor(0.9345)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:26:34.021443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:26:35.276993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Total Correct Samples 1614.0 out of 1976 = 0.8168016194331984\n",
      "Total Correct_ID Samples 1647.0 out of 1976 = 0.833502024291498\n",
      "Total Acc: tensor(0.9792)\n",
      "Total Precision: tensor(0.9155)\n",
      "Total Recall: tensor(0.9224)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:27:02.875044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:27:04.110165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 422.0 out of 482 = 0.8755186721991701\n",
      "Total Correct_ID Samples 433.0 out of 482 = 0.8983402489626556\n",
      "Total Acc: tensor(0.9844)\n",
      "Total Precision: tensor(0.9373)\n",
      "Total Recall: tensor(0.9426)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:27:22.108704: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:27:23.233785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 421.0 out of 482 = 0.8734439834024896\n",
      "Total Correct_ID Samples 436.0 out of 482 = 0.9045643153526971\n",
      "Total Acc: tensor(0.9863)\n",
      "Total Precision: tensor(0.9426)\n",
      "Total Recall: tensor(0.9534)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:27:40.466191: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:27:41.786637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 404.0 out of 482 = 0.8381742738589212\n",
      "Total Correct_ID Samples 416.0 out of 482 = 0.8630705394190872\n",
      "Total Acc: tensor(0.9800)\n",
      "Total Precision: tensor(0.9180)\n",
      "Total Recall: tensor(0.9292)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:27:59.091127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:28:00.312048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 440.0 out of 482 = 0.9128630705394191\n",
      "Total Correct_ID Samples 447.0 out of 482 = 0.9273858921161826\n",
      "Total Acc: tensor(0.9921)\n",
      "Total Precision: tensor(0.9679)\n",
      "Total Recall: tensor(0.9697)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:28:17.835625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:28:19.216115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 204.0 out of 482 = 0.42323651452282157\n",
      "Total Correct_ID Samples 338.0 out of 482 = 0.7012448132780082\n",
      "Total Acc: tensor(0.9590)\n",
      "Total Precision: tensor(0.7982)\n",
      "Total Recall: tensor(0.9370)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:28:37.339423: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:28:38.656146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 415.0 out of 482 = 0.8609958506224067\n",
      "Total Correct_ID Samples 443.0 out of 482 = 0.9190871369294605\n",
      "Total Acc: tensor(0.9849)\n",
      "Total Precision: tensor(0.9356)\n",
      "Total Recall: tensor(0.9446)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:28:57.492424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:28:58.802576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 408.0 out of 482 = 0.8464730290456431\n",
      "Total Correct_ID Samples 430.0 out of 482 = 0.8921161825726142\n",
      "Total Acc: tensor(0.9811)\n",
      "Total Precision: tensor(0.9194)\n",
      "Total Recall: tensor(0.9370)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:29:17.255786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:29:18.656937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 430.0 out of 482 = 0.8921161825726142\n",
      "Total Correct_ID Samples 445.0 out of 482 = 0.9232365145228216\n",
      "Total Acc: tensor(0.9884)\n",
      "Total Precision: tensor(0.9547)\n",
      "Total Recall: tensor(0.9535)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:29:37.642936: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:29:38.837313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 408.0 out of 482 = 0.8464730290456431\n",
      "Total Correct_ID Samples 426.0 out of 482 = 0.8838174273858921\n",
      "Total Acc: tensor(0.9857)\n",
      "Total Precision: tensor(0.9425)\n",
      "Total Recall: tensor(0.9515)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:29:56.884009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:29:58.018810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 418.0 out of 482 = 0.8672199170124482\n",
      "Total Correct_ID Samples 435.0 out of 482 = 0.9024896265560166\n",
      "Total Acc: tensor(0.9862)\n",
      "Total Precision: tensor(0.9458)\n",
      "Total Recall: tensor(0.9455)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:30:15.126338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:30:16.341779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 78.0 out of 482 = 0.16182572614107885\n",
      "Total Correct_ID Samples 226.0 out of 482 = 0.46887966804979253\n",
      "Total Acc: tensor(0.9070)\n",
      "Total Precision: tensor(0.6241)\n",
      "Total Recall: tensor(0.9331)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:30:34.209273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:30:35.742000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 274.0 out of 482 = 0.5684647302904564\n",
      "Total Correct_ID Samples 352.0 out of 482 = 0.7302904564315352\n",
      "Total Acc: tensor(0.9637)\n",
      "Total Precision: tensor(0.8365)\n",
      "Total Recall: tensor(0.9196)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:30:54.522259: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:30:55.731150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 415.0 out of 482 = 0.8609958506224067\n",
      "Total Correct_ID Samples 424.0 out of 482 = 0.8796680497925311\n",
      "Total Acc: tensor(0.9846)\n",
      "Total Precision: tensor(0.9389)\n",
      "Total Recall: tensor(0.9447)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:31:12.658469: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:31:13.896375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 401.0 out of 482 = 0.8319502074688797\n",
      "Total Correct_ID Samples 421.0 out of 482 = 0.8734439834024896\n",
      "Total Acc: tensor(0.9802)\n",
      "Total Precision: tensor(0.9101)\n",
      "Total Recall: tensor(0.9123)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:31:32.380994: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:31:33.613586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 795.0 out of 958 = 0.8298538622129437\n",
      "Total Correct_ID Samples 809.0 out of 958 = 0.8444676409185804\n",
      "Total Acc: tensor(0.9804)\n",
      "Total Precision: tensor(0.9198)\n",
      "Total Recall: tensor(0.9363)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:31:56.053082: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:31:57.493382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 833.0 out of 958 = 0.8695198329853863\n",
      "Total Correct_ID Samples 849.0 out of 958 = 0.8862212943632568\n",
      "Total Acc: tensor(0.9868)\n",
      "Total Precision: tensor(0.9461)\n",
      "Total Recall: tensor(0.9541)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:32:19.010263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:32:20.403578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 833.0 out of 958 = 0.8695198329853863\n",
      "Total Correct_ID Samples 846.0 out of 958 = 0.8830897703549061\n",
      "Total Acc: tensor(0.9858)\n",
      "Total Precision: tensor(0.9441)\n",
      "Total Recall: tensor(0.9494)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:32:41.468950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:32:42.734018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 842.0 out of 958 = 0.8789144050104384\n",
      "Total Correct_ID Samples 850.0 out of 958 = 0.8872651356993737\n",
      "Total Acc: tensor(0.9865)\n",
      "Total Precision: tensor(0.9473)\n",
      "Total Recall: tensor(0.9530)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:33:03.056694: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:33:04.371545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 505.0 out of 958 = 0.5271398747390397\n",
      "Total Correct_ID Samples 656.0 out of 958 = 0.6847599164926931\n",
      "Total Acc: tensor(0.9602)\n",
      "Total Precision: tensor(0.8249)\n",
      "Total Recall: tensor(0.9483)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:33:25.794196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:33:27.177298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 785.0 out of 958 = 0.8194154488517745\n",
      "Total Correct_ID Samples 822.0 out of 958 = 0.8580375782881002\n",
      "Total Acc: tensor(0.9828)\n",
      "Total Precision: tensor(0.9302)\n",
      "Total Recall: tensor(0.9446)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:33:49.723022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:33:51.103639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 815.0 out of 958 = 0.8507306889352818\n",
      "Total Correct_ID Samples 825.0 out of 958 = 0.8611691022964509\n",
      "Total Acc: tensor(0.9842)\n",
      "Total Precision: tensor(0.9350)\n",
      "Total Recall: tensor(0.9483)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:34:12.846989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:34:14.179000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 840.0 out of 958 = 0.8768267223382046\n",
      "Total Correct_ID Samples 855.0 out of 958 = 0.8924843423799582\n",
      "Total Acc: tensor(0.9855)\n",
      "Total Precision: tensor(0.9431)\n",
      "Total Recall: tensor(0.9483)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:34:35.711115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:34:36.976693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 853.0 out of 958 = 0.8903966597077244\n",
      "Total Correct_ID Samples 865.0 out of 958 = 0.9029227557411273\n",
      "Total Acc: tensor(0.9891)\n",
      "Total Precision: tensor(0.9557)\n",
      "Total Recall: tensor(0.9630)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:34:58.708936: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:34:59.973485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 846.0 out of 958 = 0.8830897703549061\n",
      "Total Correct_ID Samples 856.0 out of 958 = 0.8935281837160751\n",
      "Total Acc: tensor(0.9866)\n",
      "Total Precision: tensor(0.9488)\n",
      "Total Recall: tensor(0.9515)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:35:22.316118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:35:23.532191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 47.0 out of 958 = 0.049060542797494784\n",
      "Total Correct_ID Samples 239.0 out of 958 = 0.24947807933194155\n",
      "Total Acc: tensor(0.8975)\n",
      "Total Precision: tensor(0.6137)\n",
      "Total Recall: tensor(0.8638)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:35:45.531789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:35:46.828374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 596.0 out of 958 = 0.6221294363256785\n",
      "Total Correct_ID Samples 724.0 out of 958 = 0.755741127348643\n",
      "Total Acc: tensor(0.9704)\n",
      "Total Precision: tensor(0.8667)\n",
      "Total Recall: tensor(0.9483)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:36:08.405273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:36:09.904291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 828.0 out of 958 = 0.8643006263048016\n",
      "Total Correct_ID Samples 836.0 out of 958 = 0.872651356993737\n",
      "Total Acc: tensor(0.9866)\n",
      "Total Precision: tensor(0.9461)\n",
      "Total Recall: tensor(0.9536)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:36:31.930055: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:36:33.322594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Total Correct Samples 829.0 out of 958 = 0.8653444676409185\n",
      "Total Correct_ID Samples 834.0 out of 958 = 0.8705636743215032\n",
      "Total Acc: tensor(0.9834)\n",
      "Total Precision: tensor(0.9323)\n",
      "Total Recall: tensor(0.9400)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:36:55.775944: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:36:57.026454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 784.0 out of 980 = 0.8\n",
      "Total Correct_ID Samples 793.0 out of 980 = 0.8091836734693878\n",
      "Total Acc: tensor(0.9756)\n",
      "Total Precision: tensor(0.9037)\n",
      "Total Recall: tensor(0.9148)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:37:19.515844: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:37:20.739004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 839.0 out of 980 = 0.8561224489795919\n",
      "Total Correct_ID Samples 859.0 out of 980 = 0.8765306122448979\n",
      "Total Acc: tensor(0.9848)\n",
      "Total Precision: tensor(0.9395)\n",
      "Total Recall: tensor(0.9448)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:37:43.374005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:37:44.715215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 778.0 out of 980 = 0.7938775510204081\n",
      "Total Correct_ID Samples 796.0 out of 980 = 0.8122448979591836\n",
      "Total Acc: tensor(0.9776)\n",
      "Total Precision: tensor(0.9080)\n",
      "Total Recall: tensor(0.9170)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:38:07.645915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:38:08.861140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 746.0 out of 980 = 0.7612244897959184\n",
      "Total Correct_ID Samples 763.0 out of 980 = 0.7785714285714286\n",
      "Total Acc: tensor(0.9718)\n",
      "Total Precision: tensor(0.8899)\n",
      "Total Recall: tensor(0.8913)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:38:30.061717: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:38:31.400227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 544.0 out of 980 = 0.5551020408163265\n",
      "Total Correct_ID Samples 683.0 out of 980 = 0.6969387755102041\n",
      "Total Acc: tensor(0.9550)\n",
      "Total Precision: tensor(0.8113)\n",
      "Total Recall: tensor(0.9184)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:38:53.581998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:38:54.800207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 740.0 out of 980 = 0.7551020408163265\n",
      "Total Correct_ID Samples 789.0 out of 980 = 0.8051020408163265\n",
      "Total Acc: tensor(0.9760)\n",
      "Total Precision: tensor(0.8970)\n",
      "Total Recall: tensor(0.9194)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:39:16.697882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:39:17.949715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 823.0 out of 980 = 0.8397959183673469\n",
      "Total Correct_ID Samples 834.0 out of 980 = 0.8510204081632653\n",
      "Total Acc: tensor(0.9833)\n",
      "Total Precision: tensor(0.9359)\n",
      "Total Recall: tensor(0.9354)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:39:39.752917: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:39:41.064042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 799.0 out of 980 = 0.8153061224489796\n",
      "Total Correct_ID Samples 818.0 out of 980 = 0.8346938775510204\n",
      "Total Acc: tensor(0.9789)\n",
      "Total Precision: tensor(0.9143)\n",
      "Total Recall: tensor(0.9217)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:40:02.962809: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:40:04.118344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 750.0 out of 980 = 0.7653061224489796\n",
      "Total Correct_ID Samples 769.0 out of 980 = 0.7846938775510204\n",
      "Total Acc: tensor(0.9736)\n",
      "Total Precision: tensor(0.8939)\n",
      "Total Recall: tensor(0.9025)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:40:25.566702: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:40:26.872771: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 846.0 out of 980 = 0.863265306122449\n",
      "Total Correct_ID Samples 853.0 out of 980 = 0.8704081632653061\n",
      "Total Acc: tensor(0.9827)\n",
      "Total Precision: tensor(0.9362)\n",
      "Total Recall: tensor(0.9334)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:40:48.966580: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:40:50.263721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 36.0 out of 980 = 0.036734693877551024\n",
      "Total Correct_ID Samples 250.0 out of 980 = 0.25510204081632654\n",
      "Total Acc: tensor(0.8914)\n",
      "Total Precision: tensor(0.5883)\n",
      "Total Recall: tensor(0.8353)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:41:12.717541: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:41:13.894386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 581.0 out of 980 = 0.5928571428571429\n",
      "Total Correct_ID Samples 713.0 out of 980 = 0.7275510204081632\n",
      "Total Acc: tensor(0.9659)\n",
      "Total Precision: tensor(0.8506)\n",
      "Total Recall: tensor(0.9253)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:41:35.216868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:41:36.510740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 830.0 out of 980 = 0.8469387755102041\n",
      "Total Correct_ID Samples 840.0 out of 980 = 0.8571428571428571\n",
      "Total Acc: tensor(0.9830)\n",
      "Total Precision: tensor(0.9341)\n",
      "Total Recall: tensor(0.9337)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:41:58.032510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:41:59.460098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Total Correct Samples 834.0 out of 980 = 0.8510204081632653\n",
      "Total Correct_ID Samples 847.0 out of 980 = 0.8642857142857143\n",
      "Total Acc: tensor(0.9821)\n",
      "Total Precision: tensor(0.9282)\n",
      "Total Recall: tensor(0.9349)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:42:20.682813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:42:22.080119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1497.0 out of 1916 = 0.7813152400835073\n",
      "Total Correct_ID Samples 1529.0 out of 1916 = 0.7980167014613778\n",
      "Total Acc: tensor(0.9736)\n",
      "Total Precision: tensor(0.8936)\n",
      "Total Recall: tensor(0.9047)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:42:49.612293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:42:50.857983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1581.0 out of 1916 = 0.8251565762004175\n",
      "Total Correct_ID Samples 1625.0 out of 1916 = 0.8481210855949896\n",
      "Total Acc: tensor(0.9814)\n",
      "Total Precision: tensor(0.9245)\n",
      "Total Recall: tensor(0.9338)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:43:17.473852: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:43:18.655067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1556.0 out of 1916 = 0.8121085594989561\n",
      "Total Correct_ID Samples 1581.0 out of 1916 = 0.8251565762004175\n",
      "Total Acc: tensor(0.9796)\n",
      "Total Precision: tensor(0.9171)\n",
      "Total Recall: tensor(0.9249)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:43:46.197357: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:43:47.497107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1547.0 out of 1916 = 0.80741127348643\n",
      "Total Correct_ID Samples 1571.0 out of 1916 = 0.819937369519833\n",
      "Total Acc: tensor(0.9772)\n",
      "Total Precision: tensor(0.9106)\n",
      "Total Recall: tensor(0.9144)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:44:16.101097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:44:17.494153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 969.0 out of 1916 = 0.505741127348643\n",
      "Total Correct_ID Samples 1261.0 out of 1916 = 0.6581419624217119\n",
      "Total Acc: tensor(0.9545)\n",
      "Total Precision: tensor(0.8047)\n",
      "Total Recall: tensor(0.9192)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:44:46.371694: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:44:47.699810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1514.0 out of 1916 = 0.7901878914405011\n",
      "Total Correct_ID Samples 1576.0 out of 1916 = 0.8225469728601252\n",
      "Total Acc: tensor(0.9789)\n",
      "Total Precision: tensor(0.9118)\n",
      "Total Recall: tensor(0.9278)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:45:16.348635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:45:17.696984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1571.0 out of 1916 = 0.819937369519833\n",
      "Total Correct_ID Samples 1598.0 out of 1916 = 0.8340292275574113\n",
      "Total Acc: tensor(0.9811)\n",
      "Total Precision: tensor(0.9239)\n",
      "Total Recall: tensor(0.9336)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:45:47.971174: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:45:49.245249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1580.0 out of 1916 = 0.824634655532359\n",
      "Total Correct_ID Samples 1612.0 out of 1916 = 0.8413361169102297\n",
      "Total Acc: tensor(0.9798)\n",
      "Total Precision: tensor(0.9170)\n",
      "Total Recall: tensor(0.9260)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:46:18.090181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:46:19.413375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1571.0 out of 1916 = 0.819937369519833\n",
      "Total Correct_ID Samples 1614.0 out of 1916 = 0.8423799582463466\n",
      "Total Acc: tensor(0.9799)\n",
      "Total Precision: tensor(0.9180)\n",
      "Total Recall: tensor(0.9257)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:46:47.088561: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:46:48.258946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1621.0 out of 1916 = 0.8460334029227558\n",
      "Total Correct_ID Samples 1632.0 out of 1916 = 0.8517745302713987\n",
      "Total Acc: tensor(0.9827)\n",
      "Total Precision: tensor(0.9347)\n",
      "Total Recall: tensor(0.9332)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:47:14.536863: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:47:15.688940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 90.0 out of 1916 = 0.04697286012526096\n",
      "Total Correct_ID Samples 493.0 out of 1916 = 0.25730688935281837\n",
      "Total Acc: tensor(0.8972)\n",
      "Total Precision: tensor(0.6115)\n",
      "Total Recall: tensor(0.8288)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:47:42.700242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:47:43.881982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1176.0 out of 1916 = 0.6137787056367432\n",
      "Total Correct_ID Samples 1385.0 out of 1916 = 0.7228601252609603\n",
      "Total Acc: tensor(0.9649)\n",
      "Total Precision: tensor(0.8480)\n",
      "Total Recall: tensor(0.9205)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:48:10.796685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:48:12.088421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1567.0 out of 1916 = 0.8178496868475992\n",
      "Total Correct_ID Samples 1588.0 out of 1916 = 0.8288100208768268\n",
      "Total Acc: tensor(0.9804)\n",
      "Total Precision: tensor(0.9228)\n",
      "Total Recall: tensor(0.9270)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:48:40.835327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:48:42.299906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Total Correct Samples 1595.0 out of 1916 = 0.8324634655532359\n",
      "Total Correct_ID Samples 1613.0 out of 1916 = 0.8418580375782881\n",
      "Total Acc: tensor(0.9802)\n",
      "Total Precision: tensor(0.9203)\n",
      "Total Recall: tensor(0.9270)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:49:11.053873: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:49:12.479946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1093.0 out of 1480 = 0.7385135135135135\n",
      "Total Correct_ID Samples 1121.0 out of 1480 = 0.7574324324324324\n",
      "Total Acc: tensor(0.9678)\n",
      "Total Precision: tensor(0.8653)\n",
      "Total Recall: tensor(0.8877)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:49:37.187273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:49:38.637830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1151.0 out of 1480 = 0.7777027027027027\n",
      "Total Correct_ID Samples 1189.0 out of 1480 = 0.8033783783783783\n",
      "Total Acc: tensor(0.9694)\n",
      "Total Precision: tensor(0.8811)\n",
      "Total Recall: tensor(0.8968)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:50:02.847070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:50:04.145254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1146.0 out of 1480 = 0.7743243243243243\n",
      "Total Correct_ID Samples 1170.0 out of 1480 = 0.7905405405405406\n",
      "Total Acc: tensor(0.9716)\n",
      "Total Precision: tensor(0.8844)\n",
      "Total Recall: tensor(0.9017)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:50:28.728124: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:50:29.934758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1119.0 out of 1480 = 0.7560810810810811\n",
      "Total Correct_ID Samples 1156.0 out of 1480 = 0.7810810810810811\n",
      "Total Acc: tensor(0.9688)\n",
      "Total Precision: tensor(0.8796)\n",
      "Total Recall: tensor(0.8848)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:50:54.181454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:50:55.567334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 681.0 out of 1480 = 0.46013513513513515\n",
      "Total Correct_ID Samples 943.0 out of 1480 = 0.6371621621621621\n",
      "Total Acc: tensor(0.9494)\n",
      "Total Precision: tensor(0.7799)\n",
      "Total Recall: tensor(0.9134)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:51:20.517595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:51:21.776449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1089.0 out of 1480 = 0.7358108108108108\n",
      "Total Correct_ID Samples 1132.0 out of 1480 = 0.7648648648648648\n",
      "Total Acc: tensor(0.9679)\n",
      "Total Precision: tensor(0.8748)\n",
      "Total Recall: tensor(0.8831)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:51:47.275299: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:51:48.427566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1134.0 out of 1480 = 0.7662162162162162\n",
      "Total Correct_ID Samples 1154.0 out of 1480 = 0.7797297297297298\n",
      "Total Acc: tensor(0.9601)\n",
      "Total Precision: tensor(0.8603)\n",
      "Total Recall: tensor(0.8711)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:52:13.623622: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:52:15.056142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1140.0 out of 1480 = 0.7702702702702703\n",
      "Total Correct_ID Samples 1168.0 out of 1480 = 0.7891891891891892\n",
      "Total Acc: tensor(0.9737)\n",
      "Total Precision: tensor(0.8947)\n",
      "Total Recall: tensor(0.8965)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:52:40.720273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:52:42.028584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1128.0 out of 1480 = 0.7621621621621621\n",
      "Total Correct_ID Samples 1143.0 out of 1480 = 0.7722972972972973\n",
      "Total Acc: tensor(0.9713)\n",
      "Total Precision: tensor(0.8851)\n",
      "Total Recall: tensor(0.8890)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:53:07.517348: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:53:08.979026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1232.0 out of 1480 = 0.8324324324324325\n",
      "Total Correct_ID Samples 1245.0 out of 1480 = 0.8412162162162162\n",
      "Total Acc: tensor(0.9790)\n",
      "Total Precision: tensor(0.9191)\n",
      "Total Recall: tensor(0.9199)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:53:33.131033: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:53:34.405607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 27.0 out of 1480 = 0.018243243243243244\n",
      "Total Correct_ID Samples 302.0 out of 1480 = 0.20405405405405405\n",
      "Total Acc: tensor(0.8835)\n",
      "Total Precision: tensor(0.5596)\n",
      "Total Recall: tensor(0.8219)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:54:01.262176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:54:02.607026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 886.0 out of 1480 = 0.5986486486486486\n",
      "Total Correct_ID Samples 1069.0 out of 1480 = 0.7222972972972973\n",
      "Total Acc: tensor(0.9635)\n",
      "Total Precision: tensor(0.8436)\n",
      "Total Recall: tensor(0.9141)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:54:28.875766: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:54:30.311995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1188.0 out of 1480 = 0.8027027027027027\n",
      "Total Correct_ID Samples 1210.0 out of 1480 = 0.8175675675675675\n",
      "Total Acc: tensor(0.9779)\n",
      "Total Precision: tensor(0.9118)\n",
      "Total Recall: tensor(0.9189)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:54:53.528015: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:54:54.752312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Total Correct Samples 1196.0 out of 1480 = 0.8081081081081081\n",
      "Total Correct_ID Samples 1221.0 out of 1480 = 0.825\n",
      "Total Acc: tensor(0.9762)\n",
      "Total Precision: tensor(0.9046)\n",
      "Total Recall: tensor(0.9128)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:55:19.071118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:55:20.448774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1225.0 out of 1440 = 0.8506944444444444\n",
      "Total Correct_ID Samples 1247.0 out of 1440 = 0.8659722222222223\n",
      "Total Acc: tensor(0.9822)\n",
      "Total Precision: tensor(0.9275)\n",
      "Total Recall: tensor(0.9378)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:55:45.079059: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:55:46.345475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1272.0 out of 1440 = 0.8833333333333333\n",
      "Total Correct_ID Samples 1308.0 out of 1440 = 0.9083333333333333\n",
      "Total Acc: tensor(0.9884)\n",
      "Total Precision: tensor(0.9510)\n",
      "Total Recall: tensor(0.9603)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:56:10.830881: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:56:12.239632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1237.0 out of 1440 = 0.8590277777777777\n",
      "Total Correct_ID Samples 1265.0 out of 1440 = 0.8784722222222222\n",
      "Total Acc: tensor(0.9846)\n",
      "Total Precision: tensor(0.9378)\n",
      "Total Recall: tensor(0.9443)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:56:36.687681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:56:37.861886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1265.0 out of 1440 = 0.8784722222222222\n",
      "Total Correct_ID Samples 1296.0 out of 1440 = 0.9\n",
      "Total Acc: tensor(0.9866)\n",
      "Total Precision: tensor(0.9460)\n",
      "Total Recall: tensor(0.9531)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:57:01.366765: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:57:02.660432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 699.0 out of 1440 = 0.48541666666666666\n",
      "Total Correct_ID Samples 989.0 out of 1440 = 0.6868055555555556\n",
      "Total Acc: tensor(0.9575)\n",
      "Total Precision: tensor(0.8062)\n",
      "Total Recall: tensor(0.9378)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:57:28.491628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:57:29.835855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1187.0 out of 1440 = 0.8243055555555555\n",
      "Total Correct_ID Samples 1262.0 out of 1440 = 0.8763888888888889\n",
      "Total Acc: tensor(0.9824)\n",
      "Total Precision: tensor(0.9263)\n",
      "Total Recall: tensor(0.9426)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:57:53.727842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:57:55.129787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1239.0 out of 1440 = 0.8604166666666667\n",
      "Total Correct_ID Samples 1270.0 out of 1440 = 0.8819444444444444\n",
      "Total Acc: tensor(0.9845)\n",
      "Total Precision: tensor(0.9353)\n",
      "Total Recall: tensor(0.9453)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:58:20.692600: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:58:22.023341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1274.0 out of 1440 = 0.8847222222222222\n",
      "Total Correct_ID Samples 1298.0 out of 1440 = 0.9013888888888889\n",
      "Total Acc: tensor(0.9869)\n",
      "Total Precision: tensor(0.9475)\n",
      "Total Recall: tensor(0.9545)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:58:47.232294: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:58:48.600294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1270.0 out of 1440 = 0.8819444444444444\n",
      "Total Correct_ID Samples 1295.0 out of 1440 = 0.8993055555555556\n",
      "Total Acc: tensor(0.9877)\n",
      "Total Precision: tensor(0.9509)\n",
      "Total Recall: tensor(0.9575)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:59:13.275819: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:59:14.634525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1253.0 out of 1440 = 0.8701388888888889\n",
      "Total Correct_ID Samples 1291.0 out of 1440 = 0.8965277777777778\n",
      "Total Acc: tensor(0.9854)\n",
      "Total Precision: tensor(0.9386)\n",
      "Total Recall: tensor(0.9423)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 16:59:38.511938: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 16:59:39.899334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 137.0 out of 1440 = 0.09513888888888888\n",
      "Total Correct_ID Samples 468.0 out of 1440 = 0.325\n",
      "Total Acc: tensor(0.9026)\n",
      "Total Precision: tensor(0.6264)\n",
      "Total Recall: tensor(0.9001)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:00:04.847945: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:00:06.248374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 864.0 out of 1440 = 0.6\n",
      "Total Correct_ID Samples 1074.0 out of 1440 = 0.7458333333333333\n",
      "Total Acc: tensor(0.9679)\n",
      "Total Precision: tensor(0.8528)\n",
      "Total Recall: tensor(0.9351)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:00:30.452868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:00:31.719214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1253.0 out of 1440 = 0.8701388888888889\n",
      "Total Correct_ID Samples 1276.0 out of 1440 = 0.8861111111111111\n",
      "Total Acc: tensor(0.9859)\n",
      "Total Precision: tensor(0.9434)\n",
      "Total Recall: tensor(0.9467)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:00:57.457776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:00:58.717537: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Total Correct Samples 1253.0 out of 1440 = 0.8701388888888889\n",
      "Total Correct_ID Samples 1284.0 out of 1440 = 0.8916666666666667\n",
      "Total Acc: tensor(0.9832)\n",
      "Total Precision: tensor(0.9289)\n",
      "Total Recall: tensor(0.9344)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:01:24.349760: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:01:25.716088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 372.0 out of 482 = 0.7717842323651453\n",
      "Total Correct_ID Samples 387.0 out of 482 = 0.8029045643153527\n",
      "Total Acc: tensor(0.9745)\n",
      "Total Precision: tensor(0.8932)\n",
      "Total Recall: tensor(0.9206)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:01:44.108859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:01:45.450392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 414.0 out of 482 = 0.8589211618257261\n",
      "Total Correct_ID Samples 424.0 out of 482 = 0.8796680497925311\n",
      "Total Acc: tensor(0.9861)\n",
      "Total Precision: tensor(0.9423)\n",
      "Total Recall: tensor(0.9546)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:02:02.420755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:02:03.654863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 417.0 out of 482 = 0.8651452282157677\n",
      "Total Correct_ID Samples 421.0 out of 482 = 0.8734439834024896\n",
      "Total Acc: tensor(0.9847)\n",
      "Total Precision: tensor(0.9396)\n",
      "Total Recall: tensor(0.9481)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:02:22.271474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:02:23.568976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 439.0 out of 482 = 0.9107883817427386\n",
      "Total Correct_ID Samples 443.0 out of 482 = 0.9190871369294605\n",
      "Total Acc: tensor(0.9903)\n",
      "Total Precision: tensor(0.9611)\n",
      "Total Recall: tensor(0.9662)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:02:42.034613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:02:43.341638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 203.0 out of 482 = 0.4211618257261411\n",
      "Total Correct_ID Samples 298.0 out of 482 = 0.6182572614107884\n",
      "Total Acc: tensor(0.9558)\n",
      "Total Precision: tensor(0.7960)\n",
      "Total Recall: tensor(0.9485)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:03:00.570437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:03:01.823641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 392.0 out of 482 = 0.8132780082987552\n",
      "Total Correct_ID Samples 407.0 out of 482 = 0.8443983402489627\n",
      "Total Acc: tensor(0.9827)\n",
      "Total Precision: tensor(0.9279)\n",
      "Total Recall: tensor(0.9458)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:03:19.254247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:03:20.702296: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 377.0 out of 482 = 0.7821576763485477\n",
      "Total Correct_ID Samples 392.0 out of 482 = 0.8132780082987552\n",
      "Total Acc: tensor(0.9767)\n",
      "Total Precision: tensor(0.9035)\n",
      "Total Recall: tensor(0.9245)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:03:38.323191: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:03:39.564572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 406.0 out of 482 = 0.8423236514522822\n",
      "Total Correct_ID Samples 410.0 out of 482 = 0.8506224066390041\n",
      "Total Acc: tensor(0.9833)\n",
      "Total Precision: tensor(0.9328)\n",
      "Total Recall: tensor(0.9437)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:03:57.758561: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:03:59.093732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 424.0 out of 482 = 0.8796680497925311\n",
      "Total Correct_ID Samples 430.0 out of 482 = 0.8921161825726142\n",
      "Total Acc: tensor(0.9874)\n",
      "Total Precision: tensor(0.9485)\n",
      "Total Recall: tensor(0.9601)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:04:17.950627: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:04:19.290475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 425.0 out of 482 = 0.8817427385892116\n",
      "Total Correct_ID Samples 432.0 out of 482 = 0.8962655601659751\n",
      "Total Acc: tensor(0.9884)\n",
      "Total Precision: tensor(0.9535)\n",
      "Total Recall: tensor(0.9582)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:04:36.703889: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:04:37.949022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 38.0 out of 482 = 0.07883817427385892\n",
      "Total Correct_ID Samples 132.0 out of 482 = 0.27385892116182575\n",
      "Total Acc: tensor(0.8935)\n",
      "Total Precision: tensor(0.6133)\n",
      "Total Recall: tensor(0.8890)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:04:55.427385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:04:56.763175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 300.0 out of 482 = 0.6224066390041494\n",
      "Total Correct_ID Samples 365.0 out of 482 = 0.7572614107883817\n",
      "Total Acc: tensor(0.9716)\n",
      "Total Precision: tensor(0.8668)\n",
      "Total Recall: tensor(0.9571)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:05:15.080898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:05:16.404329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 412.0 out of 482 = 0.8547717842323651\n",
      "Total Correct_ID Samples 416.0 out of 482 = 0.8630705394190872\n",
      "Total Acc: tensor(0.9846)\n",
      "Total Precision: tensor(0.9369)\n",
      "Total Recall: tensor(0.9474)\n",
      "Saving model...\n",
      "Finished\n",
      "batch1\n",
      "summer_bee_dataset_open_train_bee_64_ids_batch1_sample_num_64\n",
      "63\n",
      "64\n",
      "2023-11-20 17:05:33.977099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 17:05:35.471590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Device: cuda\n",
      "Evaluating model...\n",
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Total Correct Samples 411.0 out of 482 = 0.8526970954356846\n",
      "Total Correct_ID Samples 416.0 out of 482 = 0.8630705394190872\n",
      "Total Acc: tensor(0.9865)\n",
      "Total Precision: tensor(0.9431)\n",
      "Total Recall: tensor(0.9590)\n",
      "Saving model...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_for_ymls = './new_configs_reference_train_query_test/'\n",
    "directory_for_jsons = './jsons_for_results/'\n",
    "\n",
    "gpu_id = '0'\n",
    "if(not os.path.exists(directory_for_ymls)):\n",
    "    os.mkdir(directory_for_ymls)\n",
    "    \n",
    "if(not os.path.exists(directory_for_jsons)):\n",
    "    os.mkdir(directory_for_jsons)\n",
    "#/home/lmeyers/ReID_complete/color_detect_experiments/_ids_batch1_sample_num_02/wandb/latest-run/run-11qqubh3.wandb\n",
    "\n",
    "for query_file in files_all:\n",
    "    for model_dir in wanted:\n",
    "        \n",
    "        #print(model_dir+'/wandb/latest-run/*.wandb')\n",
    "        #wandb_id = glob(model_dir+'/wandb/latest-run/run*')\n",
    "        #print(wandb_id[4:-6])\n",
    "        #\"\"\"\n",
    "        model_files = glob(model_dir+'/checkpoints/*00.pth')\n",
    "        #model_files.append(glob(model_dir+'/checkpoints/*99.pth')[0])\n",
    "        \n",
    "        \n",
    "        #should not happen if all models were trained\n",
    "        if len(model_files) <=0:\n",
    "            print('this path needs training')\n",
    "            print(model_dir)\n",
    "            continue\n",
    "        \n",
    "        yml_config_path = glob(model_dir+'/*.yml')[0]\n",
    "        with open(yml_config_path, 'r') as f:\n",
    "            yml_config = yaml.safe_load(f)\n",
    "        \n",
    "        for model in model_files:\n",
    "            \n",
    "            model_checkpoint = model.split('/')[-1][:-4]\n",
    "            \n",
    "\n",
    "            yml_config['model_settings']['model_path'] = model\n",
    "\n",
    "            training_csv = yml_config['data_settings']['datafiles']['train']\n",
    "\n",
    "            #training_csv = training_csv.replace('/home/gsantiago/summer_bee_data/','/home/gsantiago/all_data_csvs/')\n",
    "            training_csv = training_csv.replace('/home/lizardi_lab/josue/summer_bee_data/', '/home/gsantiago/summer_bee_data/')\n",
    "\n",
    "            ## this prints \n",
    "\n",
    "            #/home/gsantiago/summer_bee_data/open_sets/new_open_08_ids_monocolor_batch1\n",
    "\n",
    "            # print(os.path.dirname(training_csv))\n",
    "            parent_train_directory=os.path.dirname(training_csv)\n",
    "            batch = parent_train_directory.split('_')[-1]\n",
    "\n",
    "            # things needed for csv\n",
    "            run_str  = os.path.basename(training_csv)[:-4]\n",
    "            training_df = pd.read_csv(training_csv)\n",
    "            num_ids = training_df['reID'].nunique()\n",
    "            num_images_per_id = run_str.split('_')[-1]\n",
    "\n",
    "            print(batch)\n",
    "            print(run_str)\n",
    "            print(num_ids)\n",
    "            print(num_images_per_id)\n",
    "\n",
    "\n",
    "            #reference  train, query test\n",
    "            #if(batch == 'batch1'):\n",
    "            open_sets_dir = (os.path.dirname(parent_train_directory))\n",
    "\n",
    "\n",
    "            #reference_csv = yml_config['data_settings']['datafiles']['reference']\n",
    "\n",
    "            #training_csv = training_csv.replace('/home/gsantiago/summer_bee_data/','/home/gsantiago/all_data_csvs/')\n",
    "            #reference_csv = reference_csv.replace('/home/lizardi_lab/josue/summer_bee_data/', '/home/gsantiago/summer_bee_data/')\n",
    "            \n",
    "            #test_csv = yml_config['data_settings']['datafiles']['test']\n",
    "            #test_csv = test_csv.replace('/home/lizardi_lab/josue/summer_bee_data/', '/home/gsantiago/summer_bee_data/')\n",
    "\n",
    "            color_map_file = yml_config['data_settings']['datafiles']['color_map']\n",
    "            color_map_file = color_map_file.replace('/home/lizardi_lab/josue/color_detect_experiments/', '/home/lmeyers/ReID_complete/')\n",
    "\n",
    "            #reference_file_train_both = glob(open_sets_dir+'/open_reference_query_testing_batch1/*reference*')[0]\n",
    "            #reference_file_test_both = glob(open_sets_dir+'/open_reference_query_testing_batch2/*reference*')[0]\n",
    "            \n",
    "            #query_file=glob(open_sets_dir+'/open_reference_query_testing_batch2/*query*')[0]\n",
    "\n",
    "            #\"\"\"\n",
    "            \"\"\"\n",
    "            else:\n",
    "                open_sets_dir = (os.path.dirname(parent_train_directory))\n",
    "                reference_file_train_both = glob(open_sets_dir+'/open_reference_query_testing_batch2/*reference*')[0]\n",
    "                reference_file_test_both = glob(open_sets_dir+'/open_reference_query_testing_batch1/*reference*')[0]\n",
    "                \n",
    "                query_file=glob(open_sets_dir+'/open_reference_query_testing_batch1/*query*')[0]\n",
    "                #training_csv = training_csv.replace('/home/gsantiago/all_data_csvs/', '/home/gsantiago/summer_bee_data/')\n",
    "            #\"\"\"\n",
    "            #\"\"\"\n",
    "\n",
    "            #yml_config['data_settings']['datafiles']['reference']=reference_\n",
    "\n",
    "            #yml_config['data_settings']['datafiles']['test']=test_csv\n",
    "\n",
    "            yml_config['eval_settings']['results_file']='/home/lmeyers/ReID_complete/auto_eval_models_color_detect/evaluation_all_checkpoints_v2.csv'\n",
    "            yml_config['eval_settings']['pickle_file'] = '/home/lmeyers/ReID_complete/auto_eval_models_color_detect/results_pickle.pkl'\n",
    "            yml_config['train_settings']['gpu']=gpu_id\n",
    "            yml_config['data_settings']['datafiles']['test'] = query_file\n",
    "\n",
    "            yml_config['data_settings']['datafiles']['color_map'] = color_map_file\n",
    "\n",
    "        \n",
    "            yml_file = directory_for_ymls+ os.path.basename(yml_config_path)\n",
    "            with open(yml_file, 'w') as f:\n",
    "                yaml.dump(yml_config, f)\n",
    "\n",
    "\n",
    "            ## python runs\n",
    "\n",
    "\n",
    "            !python3 ../color_detect_experiments/color_detect_eval_v2.py --config_file {yml_file}\n",
    "            with open(yml_config['eval_settings']['pickle_file'],'rb') as fi:\n",
    "                results = pickle.load(fi)  \n",
    "\n",
    "\n",
    "            # Convert ndarray to list\n",
    "\n",
    "            #for key in results.keys():\n",
    "                #results[key] = results[key].tolist()\n",
    "\n",
    "            with open(directory_for_jsons+run_str+'_training_'+model_checkpoint+'.json', 'w') as f:\n",
    "                json.dump(results, f)\n",
    "\n",
    "            # Write out run summary to results tracking document\n",
    "            results_df = pd.read_csv(yml_config['eval_settings']['results_file'])\n",
    "            results_df.loc[len(results_df)] = {'run_str': run_str,\n",
    "                                                'wandb_id':'Null',\n",
    "                                                'num_ids':num_ids,\n",
    "                                                'num_images_per_id':num_images_per_id,\n",
    "                                                'total_training_images':len(training_df),\n",
    "                                                'batch_size':yml_config['data_settings']['batch_size'],\n",
    "                                                'num_epochs':model_checkpoint,\n",
    "                                                'percent_correct_samples':results['percent_correct_samples'],\n",
    "                                                'percent_correct_id':results['percent_correct_id_samples'],\n",
    "                                                'total_acc':results['Total Acc:'],\n",
    "                                                'total_precision':results['Total Precision:'],\n",
    "                                                'total_recall':results['Total Recall:'],\n",
    "                                                'training_file':training_csv,\n",
    "                                                'test_file':yml_config['data_settings']['datafiles']['test'],\n",
    "                                                'stop_epoch':results['stop_epoch'],\n",
    "                                                }\n",
    "                                                \n",
    "            results_df.to_csv(yml_config['eval_settings']['results_file'],index=False)\n",
    "        #\"\"\"\n",
    "\n",
    "        \"\"\"  ##-----------Duplicate???\n",
    "            \n",
    "            yml_config['data_settings']['datafiles']['reference']=reference_file_test_both\n",
    "\n",
    "            yml_config['data_settings']['datafiles']['query']=query_file\n",
    "            yml_config['train_settings']['gpu']=gpu_id\n",
    "\n",
    "            yml_file = directory_for_ymls+ os.path.basename(yml_config_path)\n",
    "            with open(yml_file, 'w') as f:\n",
    "                yaml.dump(yml_config, f)\n",
    "\n",
    "\n",
    "            ## python runs\n",
    "\n",
    "\n",
    "            !python3 ../pytorch_eval_reid.py --config_file {yml_file}\n",
    "            with open(yml_config['eval_settings']['pickle_file'],'rb') as fi:\n",
    "                results = pickle.load(fi)  \n",
    "\n",
    "\n",
    "            # Convert ndarray to list\n",
    "\n",
    "            for key in results.keys():\n",
    "                results[key] = results[key].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            with open(directory_for_jsons+run_str+'testing'+model_checkpoint+'.json', 'w') as f:\n",
    "                json.dump(results, f)\n",
    "\n",
    "            # Write out run summary to results tracking document\n",
    "            results_df = pd.read_csv(yml_config['eval_settings']['results_file'])\n",
    "            results_df.loc[len(results_df)] = {'run_str': run_str,\n",
    "                                                'type_of_reference': 'testing',\n",
    "                                                'num_ids':num_ids,\n",
    "                                                'num_images_per_id':num_images_per_id,\n",
    "                                                'total_training_images':len(training_df),\n",
    "                                                'batch_size':yml_config['data_settings']['batch_size'],\n",
    "                                                'num_epochs':model_checkpoint,\n",
    "\n",
    "                                                '1NN':results['1NN_acc'],\n",
    "                                                '3NN':results['3NN_acc'],\n",
    "\n",
    "\n",
    "                                                'training_file':training_csv,\n",
    "                                                'reference_file':reference_file_test_both,\n",
    "                                                'query_file':query_file\n",
    "                                                }\n",
    "            results_df.to_csv(yml_config['eval_settings']['results_file'],index=False)\n",
    "        \n",
    "        \n",
    "        \"\"\"    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ae91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fad390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1NN_acc\n",
      "3NN_acc\n",
      "label_list\n",
      "knn_class\n",
      "knn_conf\n"
     ]
    }
   ],
   "source": [
    " with open(yml_config['eval_settings']['pickle_file'],'rb') as fi:\n",
    "        results = pickle.load(fi)  \n",
    "        \n",
    "    \n",
    "# Convert ndarray to list\n",
    "\n",
    "for key in results.keys():\n",
    "    print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40940da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
