{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import sys \n",
    "\n",
    "sys.path.insert(1,'/home/lmeyers/ReID_complete/')\n",
    "\n",
    "from pytorch_data import *\n",
    "from pytorch_models import *\n",
    "from pytorch_train_and_eval_color_detect import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/lmeyers/ReID_complete/color_detect_experiments/8_ids_double_colors_batch1_sample_num_64/8_ids_double_colors_batch1_sample_num_64.yml' #'/home/lmeyers/ReID_complete/color_detect_experiments/_ids_batch1_sample_num_08/_ids_batch1_sample_num_08.yml'\n",
    "\n",
    "with open(config_file, 'r') as fo:\n",
    "    config = yaml.safe_load(fo)\n",
    "model_config = config['model_settings'] # settings for model building\n",
    "train_config = config['train_settings'] # settings for model training\n",
    "data_config = config['data_settings'] # settings for data loading\n",
    "eval_config = config['eval_settings'] # settings for evaluation\n",
    "torch_seed = config['torch_seed']\n",
    "verbose = config['verbose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from saved epoch: 200\n",
      "Loading saved checkpoint model ./8_ids_double_colors_batch1_sample_num_64/checkpoints/200.pth\n"
     ]
    }
   ],
   "source": [
    "run_to_restart =  '9xz07aa4' #'k4il16yj'\n",
    "check_point_to_use = 200\n",
    "\n",
    "\n",
    "train_config['wandb_run_id'] = run_to_restart\n",
    "train_config['checkpoint_to_load'] = check_point_to_use\n",
    "\n",
    "#Load model\n",
    "most_recent_epoch =  train_config['checkpoint_to_load']\n",
    "print(f'Resuming training from saved epoch: {most_recent_epoch}')\n",
    "most_recent_model = os.path.dirname(model_config['model_path'])+r'/checkpoints/'+str(most_recent_epoch)+'.pth'\n",
    "print(f'Loading saved checkpoint model {most_recent_model}')\n",
    "model = torch.load(most_recent_model)\n",
    "\n",
    "#resart logging\n",
    "#experiment = wandb.init(project= train_config[\"wandb_project_name\"],entity=train_config['wandb_entity_name'],resume=True,id=train_config['wandb_run_id'],dir=train_config['wandb_dir_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 1\n",
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout1): Dropout(p=0.5, inplace=True)\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (dropout2): Dropout(p=0.2, inplace=True)\n",
       "  )\n",
       "  (1): Linear(in_features=128, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SET GPU TO USE\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(train_config['gpu'])\n",
    "if verbose:\n",
    "    print('Using GPU',train_config['gpu'])\n",
    "\n",
    "\n",
    "# LOAD TO DEVICE\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if verbose:\n",
    "    print(f'Device: {device}')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = data_config['datafiles']['train']\n",
    "#train_file = root+r'/'+files[i]\n",
    "wandb_name = 'color_detect_'+ os.path.basename(os.path.dirname(train_file))\n",
    "run_str = os.path.basename(train_file)[36:-4]\n",
    "\n",
    "\n",
    "split_parts = run_str.rsplit('_', 1)\n",
    "# Check if there is at least one underscore in the string\n",
    "if len(split_parts) > 1:\n",
    "    # Get the substring after the last underscore\n",
    "    num_images = split_parts[1]\n",
    "    num_ids = split_parts[-1]\n",
    "else:\n",
    "    # Handle the case where there are no underscores in the string\n",
    "    num_images = run_str\n",
    "\n",
    "reference_file = config['data_settings']['datafiles']['reference']\n",
    "\n",
    "\n",
    "test_file = config['data_settings']['datafiles']['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Inference on Batch 0\n",
      "Performing Inference on Batch 1\n",
      "Performing Inference on Batch 2\n",
      "Performing Inference on Batch 3\n",
      "Performing Inference on Batch 4\n",
      "Performing Inference on Batch 5\n",
      "Performing Inference on Batch 6\n",
      "Performing Inference on Batch 7\n",
      "Performing Inference on Batch 8\n",
      "Performing Inference on Batch 9\n",
      "Performing Inference on Batch 10\n",
      "Performing Inference on Batch 11\n",
      "Performing Inference on Batch 12\n",
      "Performing Inference on Batch 13\n",
      "Performing Inference on Batch 14\n",
      "Performing Inference on Batch 15\n",
      "Performing Inference on Batch 16\n",
      "Performing Inference on Batch 17\n",
      "Performing Inference on Batch 18\n",
      "Performing Inference on Batch 19\n",
      "Performing Inference on Batch 20\n",
      "Performing Inference on Batch 21\n",
      "Performing Inference on Batch 22\n",
      "Performing Inference on Batch 23\n",
      "Performing Inference on Batch 24\n",
      "Performing Inference on Batch 25\n",
      "Performing Inference on Batch 26\n",
      "Performing Inference on Batch 27\n",
      "Performing Inference on Batch 28\n",
      "Performing Inference on Batch 29\n",
      "Performing Inference on Batch 30\n",
      "Performing Inference on Batch 31\n",
      "Performing Inference on Batch 32\n",
      "Performing Inference on Batch 33\n",
      "Performing Inference on Batch 34\n",
      "Performing Inference on Batch 35\n",
      "Performing Inference on Batch 36\n",
      "Performing Inference on Batch 37\n",
      "Performing Inference on Batch 38\n",
      "Performing Inference on Batch 39\n",
      "Performing Inference on Batch 40\n",
      "Performing Inference on Batch 41\n",
      "Performing Inference on Batch 42\n",
      "Performing Inference on Batch 43\n",
      "Performing Inference on Batch 44\n",
      "Performing Inference on Batch 45\n",
      "Performing Inference on Batch 46\n",
      "Performing Inference on Batch 47\n",
      "Performing Inference on Batch 48\n",
      "Performing Inference on Batch 49\n",
      "Performing Inference on Batch 50\n",
      "Performing Inference on Batch 51\n",
      "Performing Inference on Batch 52\n",
      "Performing Inference on Batch 53\n",
      "Performing Inference on Batch 54\n",
      "Performing Inference on Batch 55\n",
      "Performing Inference on Batch 56\n",
      "Performing Inference on Batch 57\n",
      "Performing Inference on Batch 58\n",
      "Performing Inference on Batch 59\n",
      "Performing Inference on Batch 60\n",
      "Performing Inference on Batch 61\n",
      "Performing Inference on Batch 62\n",
      "Performing Inference on Batch 63\n",
      "Performing Inference on Batch 64\n",
      "Performing Inference on Batch 65\n",
      "Performing Inference on Batch 66\n",
      "Performing Inference on Batch 67\n",
      "Performing Inference on Batch 68\n",
      "Performing Inference on Batch 69\n",
      "Performing Inference on Batch 70\n",
      "Performing Inference on Batch 71\n",
      "Performing Inference on Batch 72\n",
      "Performing Inference on Batch 73\n",
      "Performing Inference on Batch 74\n",
      "Performing Inference on Batch 75\n",
      "Performing Inference on Batch 76\n",
      "Performing Inference on Batch 77\n",
      "Performing Inference on Batch 78\n",
      "Performing Inference on Batch 79\n",
      "Performing Inference on Batch 80\n",
      "Performing Inference on Batch 81\n",
      "Performing Inference on Batch 82\n",
      "Performing Inference on Batch 83\n",
      "Performing Inference on Batch 84\n",
      "Performing Inference on Batch 85\n",
      "Performing Inference on Batch 86\n",
      "Performing Inference on Batch 87\n",
      "Performing Inference on Batch 88\n",
      "Performing Inference on Batch 89\n",
      "Performing Inference on Batch 90\n",
      "Performing Inference on Batch 91\n",
      "Performing Inference on Batch 92\n",
      "Performing Inference on Batch 93\n",
      "Performing Inference on Batch 94\n",
      "Performing Inference on Batch 95\n",
      "Performing Inference on Batch 96\n",
      "Performing Inference on Batch 97\n",
      "Performing Inference on Batch 98\n",
      "Performing Inference on Batch 99\n",
      "Performing Inference on Batch 100\n",
      "Performing Inference on Batch 101\n",
      "Performing Inference on Batch 102\n",
      "Performing Inference on Batch 103\n",
      "Performing Inference on Batch 104\n",
      "Performing Inference on Batch 105\n",
      "Performing Inference on Batch 106\n",
      "Performing Inference on Batch 107\n",
      "Performing Inference on Batch 108\n",
      "Performing Inference on Batch 109\n",
      "Performing Inference on Batch 110\n",
      "Performing Inference on Batch 111\n",
      "Performing Inference on Batch 112\n",
      "Performing Inference on Batch 113\n",
      "Performing Inference on Batch 114\n",
      "Performing Inference on Batch 115\n",
      "Performing Inference on Batch 116\n",
      "Performing Inference on Batch 117\n",
      "Performing Inference on Batch 118\n",
      "Performing Inference on Batch 119\n",
      "Performing Inference on Batch 120\n",
      "Performing Inference on Batch 121\n",
      "Class 0 TP: 183 FN: 931 FP: 1657 TN: 5019 Acc: tensor(0.6678) Precision: tensor(0.0995) Recall: tensor(0.1643)\n",
      "Class 1 TP: 669 FN: 788 FP: 211 TN: 6122 Acc: tensor(0.8718) Precision: tensor(0.7602) Recall: tensor(0.4592)\n",
      "Class 2 TP: 363 FN: 317 FP: 2163 TN: 4947 Acc: tensor(0.6816) Precision: tensor(0.1437) Recall: tensor(0.5338)\n",
      "Class 3 TP: 190 FN: 479 FP: 2175 TN: 4946 Acc: tensor(0.6593) Precision: tensor(0.0803) Recall: tensor(0.2840)\n",
      "Class 4 TP: 1143 FN: 163 FP: 1433 TN: 5051 Acc: tensor(0.7951) Precision: tensor(0.4437) Recall: tensor(0.8752)\n",
      "Class 5 TP: 540 FN: 37 FP: 2089 TN: 5124 Acc: tensor(0.7271) Precision: tensor(0.2054) Recall: tensor(0.9359)\n",
      "Class 6 TP: 393 FN: 317 FP: 2132 TN: 4948 Acc: tensor(0.6856) Precision: tensor(0.1556) Recall: tensor(0.5535)\n",
      "Class 7 TP: 785 FN: 492 FP: 1742 TN: 4771 Acc: tensor(0.7132) Precision: tensor(0.3106) Recall: tensor(0.6147)\n",
      "Class 8 TP: 376 FN: 619 FP: 2151 TN: 4644 Acc: tensor(0.6444) Precision: tensor(0.1488) Recall: tensor(0.3779)\n",
      "Class 9 TP: 1010 FN: 22 FP: 830 TN: 5928 Acc: tensor(0.8906) Precision: tensor(0.5489) Recall: tensor(0.9787)\n",
      "Class 10 TP: 165 FN: 714 FP: 715 TN: 6196 Acc: tensor(0.8166) Precision: tensor(0.1875) Recall: tensor(0.1877)\n",
      "Class 11 TP: 656 FN: 405 FP: 1868 TN: 4861 Acc: tensor(0.7082) Precision: tensor(0.2599) Recall: tensor(0.6183)\n",
      "Class 12 TP: 562 FN: 190 FP: 1808 TN: 5230 Acc: tensor(0.7435) Precision: tensor(0.2371) Recall: tensor(0.7473)\n",
      "Class 13 TP: 711 FN: 298 FP: 1861 TN: 4920 Acc: tensor(0.7228) Precision: tensor(0.2764) Recall: tensor(0.7047)\n",
      "Class 14 TP: 270 FN: 814 FP: 2351 TN: 4355 Acc: tensor(0.5937) Precision: tensor(0.1030) Recall: tensor(0.2491)\n",
      "Class 15 TP: 637 FN: 341 FP: 1889 TN: 4923 Acc: tensor(0.7137) Precision: tensor(0.2522) Recall: tensor(0.6513)\n",
      "Total Correct Samples 2155.0 out of 7790 = 0.2766367137355584\n",
      "Total Acc: tensor(0.7656)\n",
      "Total Precision: tensor(0.2626)\n",
      "Total Recall: tensor(0.4654)\n",
      "{'percent_correct_samples': 0.2766367137355584, 'Total Acc:': 0.7655529379844666, 'Total Precision:': 0.2625667452812195, 'Total Recall:': 0.46539226174354553, 'Class_dict': {0: {'acc:': tensor(0.6678), 'precision:': tensor(0.0995), 'recall:': tensor(0.1643)}, 1: {'acc:': tensor(0.8718), 'precision:': tensor(0.7602), 'recall:': tensor(0.4592)}, 2: {'acc:': tensor(0.6816), 'precision:': tensor(0.1437), 'recall:': tensor(0.5338)}, 3: {'acc:': tensor(0.6593), 'precision:': tensor(0.0803), 'recall:': tensor(0.2840)}, 4: {'acc:': tensor(0.7951), 'precision:': tensor(0.4437), 'recall:': tensor(0.8752)}, 5: {'acc:': tensor(0.7271), 'precision:': tensor(0.2054), 'recall:': tensor(0.9359)}, 6: {'acc:': tensor(0.6856), 'precision:': tensor(0.1556), 'recall:': tensor(0.5535)}, 7: {'acc:': tensor(0.7132), 'precision:': tensor(0.3106), 'recall:': tensor(0.6147)}, 8: {'acc:': tensor(0.6444), 'precision:': tensor(0.1488), 'recall:': tensor(0.3779)}, 9: {'acc:': tensor(0.8906), 'precision:': tensor(0.5489), 'recall:': tensor(0.9787)}, 10: {'acc:': tensor(0.8166), 'precision:': tensor(0.1875), 'recall:': tensor(0.1877)}, 11: {'acc:': tensor(0.7082), 'precision:': tensor(0.2599), 'recall:': tensor(0.6183)}, 12: {'acc:': tensor(0.7435), 'precision:': tensor(0.2371), 'recall:': tensor(0.7473)}, 13: {'acc:': tensor(0.7228), 'precision:': tensor(0.2764), 'recall:': tensor(0.7047)}, 14: {'acc:': tensor(0.5937), 'precision:': tensor(0.1030), 'recall:': tensor(0.2491)}, 15: {'acc:': tensor(0.7137), 'precision:': tensor(0.2522), 'recall:': tensor(0.6513)}}, 'train_loss': 'Null'}\n",
      "k4il16yj\n",
      "Saving model...\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31140/1156764684.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_dict[c]={'acc:':torch.tensor(class_acc).float().mean(),'precision:':torch.tensor(class_prec).float().mean(),'recall:':torch.tensor(class_rec).float().mean()}\n",
      "/tmp/ipykernel_31140/1156764684.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print('Class',c,'TP:',int(TP),'FN:',int(FN),'FP:',int(FP),'TN:',int(TN),'Acc:',torch.tensor(class_acc).float().mean(),'Precision:',torch.tensor(class_prec).float().mean(),'Recall:',torch.tensor(class_rec).float().mean(),)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate on test set\n",
    "if verbose:\n",
    "    print('Evaluating model...')\n",
    "\n",
    "## load test dataset \n",
    "test_fname = data_config['datafiles']['test']\n",
    "df_test = pd.read_csv(test_fname)\n",
    "\n",
    "dft_test = prepare_for_triplet_loss(df_test, data_config['label_col'], data_config['fname_col'])\n",
    "\n",
    "# BUILD DATASET AND DATALOADER\n",
    "test_dataset = ColorMap_w_Order(dft_test, 'filename', 'label',data_config['input_size'],'test',data_config['datafiles']['color_map'])\n",
    "bs=64\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "batch = next(iter(test_dataloader))\n",
    "\n",
    "# PERFORM INFERENCE\n",
    "with torch.no_grad():\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    vals = {}\n",
    "    corr = []\n",
    "    for k, data in enumerate(test_dataloader):\n",
    "        if verbose: \n",
    "            print('Performing Inference on Batch',k)\n",
    "        images = data['image'].to(device)\n",
    "        # get labels\n",
    "        labels = data['label'].to(device)\n",
    "        outputs = model(images)\n",
    "        #matches = (torch.round(outputs) == labels)\n",
    "        #print(matches.shape)\n",
    "        #correct = np.all(matches,axis=1,out=None)\n",
    "        #print(correct.shape)\n",
    "        #matches = torch.logical_and(torch.round(outputs),labels)\n",
    "        #predictions = torch.round(outputs) #larger than 0\n",
    "        predictions = torch.where(outputs > 0,1, 0)\n",
    "        mapping_array = np.zeros_like(predictions.cpu())  # Initialize with zero TN\n",
    "        # Set elements to 1 where both binary arrays have value 1\n",
    "        labels_cpu = labels.cpu()\n",
    "        #predictions = \n",
    "        mapping_array[(predictions.cpu() == 1) & (labels_cpu == 1)] = 1 #TP\n",
    "        mapping_array[(predictions.cpu() == 1) & (labels_cpu == 0)] = 2 #FP\n",
    "        mapping_array[(predictions.cpu() == 0) & (labels_cpu == 1)] = 3 #FN\n",
    "        #accuracy = (matches.float().mean())\n",
    "        accuracy, precision, recall = getMetrics(outputs,labels)\n",
    "        acc.append(accuracy)\n",
    "        prec.append(precision)\n",
    "        rec.append(recall)\n",
    "        corrects = [2 and 3 not in sample for sample in mapping_array] #in is expensive (replace!)\n",
    "        corr = np.concatenate((corr,corrects))\n",
    "        for i in range(len(labels[0])):\n",
    "            values_at_index = [subarray[i] for subarray in mapping_array]\n",
    "            #print('Batch',k,'Class',i,values_at_index)\n",
    "            if k == 0:\n",
    "                vals[i] = values_at_index  \n",
    "            else:\n",
    "                vals[i] = np.concatenate((vals[i],values_at_index))\n",
    "    class_dict = {}\n",
    "    for c in vals:\n",
    "            TP = torch.sum(torch.tensor(vals[c]) == 1)\n",
    "            TN = torch.sum(torch.tensor(vals[c]) == 0)\n",
    "            FP = torch.sum(torch.tensor(vals[c]) == 2)\n",
    "            FN = torch.sum(torch.tensor(vals[c]) == 3)\n",
    "            All = torch.tensor(len(vals[c]))\n",
    "            class_acc = (TP + TN)/ All\n",
    "            class_prec=  (TP)/(TP+FP)\n",
    "            class_rec = (TP)/(TP+FN)\n",
    "            class_dict[c]={'acc:':torch.tensor(class_acc).float().mean(),'precision:':torch.tensor(class_prec).float().mean(),'recall:':torch.tensor(class_rec).float().mean()}\n",
    "            print('Class',c,'TP:',int(TP),'FN:',int(FN),'FP:',int(FP),'TN:',int(TN),'Acc:',torch.tensor(class_acc).float().mean(),'Precision:',torch.tensor(class_prec).float().mean(),'Recall:',torch.tensor(class_rec).float().mean(),)\n",
    "    print('Total Correct Samples',np.sum(corr),\"out of\",len(corr),'=',(np.sum(corr)/len(corr)))\n",
    "    print(\"Total Acc:\",torch.tensor(acc).mean())\n",
    "    print(\"Total Precision:\",torch.tensor(prec).mean())\n",
    "    print(\"Total Recall:\",torch.tensor(rec).mean())\n",
    "\n",
    "results = {'percent_correct_samples':(np.sum(corr)/len(corr)),\"Total Acc:\":float(torch.tensor(acc).mean()),\"Total Precision:\":float(torch.tensor(prec).mean()),\"Total Recall:\":float(torch.tensor(rec).mean()),\"Class_dict\":class_dict}\n",
    "\n",
    "# Add total training loss to results \n",
    "results['train_loss'] = 'Null'\n",
    "print(results)\n",
    "\n",
    "# Adding other metrics to results to pass to csv\n",
    "results['valid_loss'] = 'Null'\n",
    "results['wandb_id'] = experiment.id\n",
    "print(experiment.id)\n",
    "results['start_time'] = experiment.start_time\n",
    "results['train_time'] = 'Null'\n",
    "results['stop_epoch'] = check_point_to_use\n",
    "\n",
    "\n",
    "# Save results to temporary file\n",
    "with open('/home/lmeyers/ReID_complete/color_detect_experiments/results.pkl','wb') as fi:\n",
    "    pickle.dump(results,fi)\n",
    "\n",
    "if model_config['model_path'] is not None:\n",
    "    print('Saving model...')\n",
    "    torch.save(model, model_config['model_path'])\n",
    "else:\n",
    "    print('model_path not provided. Not saving model')\n",
    "print('Finished')\n",
    "wandb.finish()\n",
    "\n",
    "\n",
    "# Save model to wandb file location to prevent overwriting\n",
    "#!cp {config['model_settings']['model_path']} {config['train_settings']['wandb_dir_path']+'/wandb/latest-run/files/'+os.path.basename(config['model_settings']['model_path'])}\n",
    "\n",
    "with open('/home/lmeyers/ReID_complete/color_detect_experiments/results.pkl','rb') as fi:\n",
    "    results = pickle.load(fi)\n",
    "\n",
    "# Write out run summary to results tracking document\n",
    "results_df = pd.read_csv(config['eval_settings']['results_file'])\n",
    "results_df.loc[len(results_df)] = {'run_str': run_str,\n",
    "                                    'wandb_id':results['wandb_id'],\n",
    "                                    'num_ids':num_ids,\n",
    "                                    'num_images_per_id':num_images,\n",
    "                                    'total_training_images':len(pd.read_csv(train_file)),\n",
    "                                    'batch_size':config['data_settings']['batch_size'],\n",
    "                                    'num_epochs':config['train_settings']['num_epochs'],\n",
    "                                    'train_loss':results['train_loss'],\n",
    "                                    'valid_loss':results['valid_loss'],\n",
    "                                    'percent_correct_samples':results['percent_correct_samples'],\n",
    "                                    'total_acc':results[\"Total Acc:\"],\n",
    "                                    'total_precision':results[\"Total Precision:\"],\n",
    "                                    'total_recall':results[\"Total Recall:\"],\n",
    "                                    'training_file':train_file,\n",
    "                                    'reference_file':reference_file,\n",
    "                                    'query_file':test_file,\n",
    "                                    'start_time':results['start_time'],\n",
    "                                    'train_time':results['train_time'],\n",
    "                                    'stop_epoch':results['stop_epoch']}\n",
    "results_df.to_csv(config['eval_settings']['results_file'],index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/lmeyers/ReID_complete/color_detect_experiments/results.pkl','rb') as fi:\n",
    "    results = pickle.load(fi)\n",
    "\n",
    "# Write out run summary to results tracking document\n",
    "results_df = pd.read_csv(config['eval_settings']['results_file'])\n",
    "results_df.loc[len(results_df)] = {'run_str': run_str,\n",
    "                                    'wandb_id':results['wandb_id'],\n",
    "                                    'num_ids':num_ids,\n",
    "                                    'num_images_per_id':num_images,\n",
    "                                    'total_training_images':len(pd.read_csv(train_file)),\n",
    "                                    'batch_size':config['data_settings']['batch_size'],\n",
    "                                    'num_epochs':config['train_settings']['num_epochs'],\n",
    "                                    'train_loss':results['train_loss'],\n",
    "                                    'valid_loss':results['valid_loss'],\n",
    "                                    'percent_correct_samples':results['percent_correct_samples'],\n",
    "                                    'total_acc':results[\"Total Acc:\"],\n",
    "                                    'total_precision':results[\"Total Precision:\"],\n",
    "                                    'total_recall':results[\"Total Recall:\"],\n",
    "                                    'training_file':train_file,\n",
    "                                    'reference_file':reference_file,\n",
    "                                    'query_file':test_file,\n",
    "                                    'start_time':results['start_time'],\n",
    "                                    'train_time':results['train_time'],\n",
    "                                    'stop_epoch':results['stop_epoch']}\n",
    "results_df.to_csv(config['eval_settings']['results_file'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
