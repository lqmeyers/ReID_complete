finished imports
beginning execution
Date and time when this experiment was started: 23-10-03 17:37
Creating train and valid dataloaders...
Batch image shape: torch.Size([64, 3, 200, 150])
Batch label shape: torch.Size([64])
Building model....
Found device: cuda
Training model...
[1,    10] train_loss: 0.2145 | val_loss: 0.1921
Saving checkpoint 0
[2,    10] train_loss: 0.2191 | val_loss: 0.1901
[3,    10] train_loss: 0.2033 | val_loss: 0.1801
[4,    10] train_loss: 0.2257 | val_loss: 0.2011
[5,    10] train_loss: 0.2131 | val_loss: 0.1834
[6,    10] train_loss: 0.2158 | val_loss: 0.1882
[7,    10] train_loss: 0.1985 | val_loss: 0.1845
[8,    10] train_loss: 0.2019 | val_loss: 0.1884
[9,    10] train_loss: 0.2049 | val_loss: 0.1787
[10,    10] train_loss: 0.2081 | val_loss: 0.1771
[11,    10] train_loss: 0.1961 | val_loss: 0.1704
[12,    10] train_loss: 0.2126 | val_loss: 0.1745
[13,    10] train_loss: 0.2062 | val_loss: 0.1822
[14,    10] train_loss: 0.2073 | val_loss: 0.1787
[15,    10] train_loss: 0.2076 | val_loss: 0.1714
[16,    10] train_loss: 0.2038 | val_loss: 0.1622
[17,    10] train_loss: 0.2068 | val_loss: 0.1812
[18,    10] train_loss: 0.2185 | val_loss: 0.1630
[19,    10] train_loss: 0.1893 | val_loss: 0.1680
[20,    10] train_loss: 0.2078 | val_loss: 0.1822
[21,    10] train_loss: 0.2010 | val_loss: 0.1926
[22,    10] train_loss: 0.1913 | val_loss: 0.1871
[23,    10] train_loss: 0.2219 | val_loss: 0.1770
[24,    10] train_loss: 0.2073 | val_loss: 0.1857
[25,    10] train_loss: 0.2049 | val_loss: 0.1772
[26,    10] train_loss: 0.2010 | val_loss: 0.1817
[27,    10] train_loss: 0.1938 | val_loss: 0.1802
[28,    10] train_loss: 0.2079 | val_loss: 0.1674
[29,    10] train_loss: 0.2065 | val_loss: 0.1771
[30,    10] train_loss: 0.1907 | val_loss: 0.1791
[31,    10] train_loss: 0.1963 | val_loss: 0.1734
[32,    10] train_loss: 0.1972 | val_loss: 0.1721
[33,    10] train_loss: 0.1945 | val_loss: 0.1774
[34,    10] train_loss: 0.2036 | val_loss: 0.1693
[35,    10] train_loss: 0.1968 | val_loss: 0.1811
[36,    10] train_loss: 0.2048 | val_loss: 0.1739
[37,    10] train_loss: 0.2040 | val_loss: 0.1786
[38,    10] train_loss: 0.1978 | val_loss: 0.1699
[39,    10] train_loss: 0.2064 | val_loss: 0.1702
[40,    10] train_loss: 0.1997 | val_loss: 0.1785
[41,    10] train_loss: 0.2047 | val_loss: 0.1683
[42,    10] train_loss: 0.1937 | val_loss: 0.1804
[43,    10] train_loss: 0.2037 | val_loss: 0.1887
[44,    10] train_loss: 0.1924 | val_loss: 0.1842
[45,    10] train_loss: 0.1899 | val_loss: 0.1792
[46,    10] train_loss: 0.1898 | val_loss: 0.1774
[47,    10] train_loss: 0.1962 | val_loss: 0.1774
[48,    10] train_loss: 0.1932 | val_loss: 0.1735
[49,    10] train_loss: 0.2111 | val_loss: 0.1759
[50,    10] train_loss: 0.1914 | val_loss: 0.1770
[51,    10] train_loss: 0.2046 | val_loss: 0.1765
Saving checkpoint 50
[52,    10] train_loss: 0.1957 | val_loss: 0.1747
[53,    10] train_loss: 0.2019 | val_loss: 0.1875
[54,    10] train_loss: 0.1995 | val_loss: 0.1819
[55,    10] train_loss: 0.1829 | val_loss: 0.1884
[56,    10] train_loss: 0.1926 | val_loss: 0.1880
[57,    10] train_loss: 0.1956 | val_loss: 0.2184
[58,    10] train_loss: 0.2055 | val_loss: 0.1952
[59,    10] train_loss: 0.1987 | val_loss: 0.2069
[60,    10] train_loss: 0.1892 | val_loss: 0.1880
[61,    10] train_loss: 0.1910 | val_loss: 0.2031
[62,    10] train_loss: 0.2006 | val_loss: 0.2125
[63,    10] train_loss: 0.1921 | val_loss: 0.1985
[64,    10] train_loss: 0.1985 | val_loss: 0.2158
[65,    10] train_loss: 0.1960 | val_loss: 0.1737
[66,    10] train_loss: 0.1824 | val_loss: 0.1844
[67,    10] train_loss: 0.1901 | val_loss: 0.2034
[68,    10] train_loss: 0.1990 | val_loss: 0.1873
[69,    10] train_loss: 0.2080 | val_loss: 0.1771
[70,    10] train_loss: 0.1944 | val_loss: 0.1807
[71,    10] train_loss: 0.1984 | val_loss: 0.1857
[72,    10] train_loss: 0.1879 | val_loss: 0.1817
[73,    10] train_loss: 0.1958 | val_loss: 0.1811
[74,    10] train_loss: 0.1904 | val_loss: 0.1811
[75,    10] train_loss: 0.2103 | val_loss: 0.1957
[76,    10] train_loss: 0.1826 | val_loss: 0.2015
[77,    10] train_loss: 0.1899 | val_loss: 0.1811
[78,    10] train_loss: 0.1938 | val_loss: 0.1804
[79,    10] train_loss: 0.2044 | val_loss: 0.1833
[80,    10] train_loss: 0.1934 | val_loss: 0.2029
[81,    10] train_loss: 0.1951 | val_loss: 0.1934
[82,    10] train_loss: 0.2036 | val_loss: 0.1824
[83,    10] train_loss: 0.2001 | val_loss: 0.1622
[84,    10] train_loss: 0.1858 | val_loss: 0.1695
[85,    10] train_loss: 0.1984 | val_loss: 0.1896
[86,    10] train_loss: 0.2000 | val_loss: 0.1945
[87,    10] train_loss: 0.2003 | val_loss: 0.1846
[88,    10] train_loss: 0.1916 | val_loss: 0.1880
[89,    10] train_loss: 0.1896 | val_loss: 0.1906
[90,    10] train_loss: 0.2295 | val_loss: 0.2128
[91,    10] train_loss: 0.1941 | val_loss: 0.1681
[92,    10] train_loss: 0.1848 | val_loss: 0.1698
[93,    10] train_loss: 0.1816 | val_loss: 0.2104
[94,    10] train_loss: 0.1917 | val_loss: 0.2127
[95,    10] train_loss: 0.1948 | val_loss: 0.2038
[96,    10] train_loss: 0.1983 | val_loss: 0.1852
[97,    10] train_loss: 0.1832 | val_loss: 0.1978
[98,    10] train_loss: 0.1820 | val_loss: 0.1958
[99,    10] train_loss: 0.1909 | val_loss: 0.1835
[100,    10] train_loss: 0.1799 | val_loss: 0.1748
[101,    10] train_loss: 0.1974 | val_loss: 0.1873
Saving checkpoint 100
[102,    10] train_loss: 0.1790 | val_loss: 0.1951
[103,    10] train_loss: 0.1785 | val_loss: 0.1822
[104,    10] train_loss: 0.1836 | val_loss: 0.1977
[105,    10] train_loss: 0.1757 | val_loss: 0.1820
[106,    10] train_loss: 0.1770 | val_loss: 0.1879
[107,    10] train_loss: 0.1837 | val_loss: 0.2036
[108,    10] train_loss: 0.1763 | val_loss: 0.1778
[109,    10] train_loss: 0.1804 | val_loss: 0.1755
[110,    10] train_loss: 0.1890 | val_loss: 0.1867
[111,    10] train_loss: 0.1734 | val_loss: 0.1949
[112,    10] train_loss: 0.1768 | val_loss: 0.1836
[113,    10] train_loss: 0.1900 | val_loss: 0.2009
[114,    10] train_loss: 0.1833 | val_loss: 0.1903
[115,    10] train_loss: 0.1718 | val_loss: 0.1944
[116,    10] train_loss: 0.1726 | val_loss: 0.2008
[117,    10] train_loss: 0.1831 | val_loss: 0.1958
[118,    10] train_loss: 0.1932 | val_loss: 0.1786
[119,    10] train_loss: 0.1823 | val_loss: 0.2038
[120,    10] train_loss: 0.1710 | val_loss: 0.1944
[121,    10] train_loss: 0.1792 | val_loss: 0.1905
[122,    10] train_loss: 0.1792 | val_loss: 0.1888
[123,    10] train_loss: 0.1804 | val_loss: 0.1655
[124,    10] train_loss: 0.1731 | val_loss: 0.1996
[125,    10] train_loss: 0.1684 | val_loss: 0.1848
[126,    10] train_loss: 0.1743 | val_loss: 0.1929
[127,    10] train_loss: 0.1691 | val_loss: 0.1860
[128,    10] train_loss: 0.1765 | val_loss: 0.2067
[129,    10] train_loss: 0.1749 | val_loss: 0.1747
[130,    10] train_loss: 0.1784 | val_loss: 0.1649
[131,    10] train_loss: 0.1768 | val_loss: 0.1853
[132,    10] train_loss: 0.1737 | val_loss: 0.1772
[133,    10] train_loss: 0.1620 | val_loss: 0.1870
[134,    10] train_loss: 0.1690 | val_loss: 0.1760
[135,    10] train_loss: 0.1705 | val_loss: 0.2152
[136,    10] train_loss: 0.1713 | val_loss: 0.1739
[137,    10] train_loss: 0.1684 | val_loss: 0.1830
[138,    10] train_loss: 0.1690 | val_loss: 0.1852
[139,    10] train_loss: 0.1756 | val_loss: 0.1965
[140,    10] train_loss: 0.1800 | val_loss: 0.1777
[141,    10] train_loss: 0.1850 | val_loss: 0.1866
[142,    10] train_loss: 0.1684 | val_loss: 0.1962
[143,    10] train_loss: 0.1692 | val_loss: 0.1926
[144,    10] train_loss: 0.1775 | val_loss: 0.1977
[145,    10] train_loss: 0.1702 | val_loss: 0.1663
[146,    10] train_loss: 0.1607 | val_loss: 0.1953
[147,    10] train_loss: 0.1626 | val_loss: 0.1735
[148,    10] train_loss: 0.1637 | val_loss: 0.1767
[149,    10] train_loss: 0.1752 | val_loss: 0.1761
[150,    10] train_loss: 0.1630 | val_loss: 0.1963
[151,    10] train_loss: 0.1777 | val_loss: 0.1894
Saving checkpoint 150
[152,    10] train_loss: 0.1692 | val_loss: 0.1909
[153,    10] train_loss: 0.1644 | val_loss: 0.1891
[154,    10] train_loss: 0.1689 | val_loss: 0.1824
[155,    10] train_loss: 0.1621 | val_loss: 0.1938
[156,    10] train_loss: 0.1686 | val_loss: 0.1895
[157,    10] train_loss: 0.1674 | val_loss: 0.2040
[158,    10] train_loss: 0.1651 | val_loss: 0.2078
[159,    10] train_loss: 0.1750 | val_loss: 0.1693
[160,    10] train_loss: 0.1697 | val_loss: 0.1972
[161,    10] train_loss: 0.1678 | val_loss: 0.1844
[162,    10] train_loss: 0.1695 | val_loss: 0.1860
[163,    10] train_loss: 0.1580 | val_loss: 0.1890
[164,    10] train_loss: 0.1611 | val_loss: 0.2006
[165,    10] train_loss: 0.1594 | val_loss: 0.1952
[166,    10] train_loss: 0.1737 | val_loss: 0.1703
[167,    10] train_loss: 0.1812 | val_loss: 0.1815
[168,    10] train_loss: 0.1620 | val_loss: 0.1771
[169,    10] train_loss: 0.1651 | val_loss: 0.1843
[170,    10] train_loss: 0.1545 | val_loss: 0.1834
[171,    10] train_loss: 0.1670 | val_loss: 0.1958
[172,    10] train_loss: 0.1744 | val_loss: 0.1967
[173,    10] train_loss: 0.1659 | val_loss: 0.1980
[174,    10] train_loss: 0.1571 | val_loss: 0.1842
[175,    10] train_loss: 0.1633 | val_loss: 0.1918
[176,    10] train_loss: 0.1649 | val_loss: 0.2093
[177,    10] train_loss: 0.1666 | val_loss: 0.1758
[178,    10] train_loss: 0.1549 | val_loss: 0.1879
[179,    10] train_loss: 0.1588 | val_loss: 0.2033
[180,    10] train_loss: 0.1735 | val_loss: 0.2021
[181,    10] train_loss: 0.1583 | val_loss: 0.2072
[182,    10] train_loss: 0.1713 | val_loss: 0.1798
[183,    10] train_loss: 0.1710 | val_loss: 0.1879
[184,    10] train_loss: 0.1778 | val_loss: 0.2053
[185,    10] train_loss: 0.1751 | val_loss: 0.1840
[186,    10] train_loss: 0.1716 | val_loss: 0.1837
[187,    10] train_loss: 0.1633 | val_loss: 0.1886
[188,    10] train_loss: 0.1558 | val_loss: 0.1868
[189,    10] train_loss: 0.1551 | val_loss: 0.1998
[190,    10] train_loss: 0.1569 | val_loss: 0.1979
[191,    10] train_loss: 0.1578 | val_loss: 0.1946
[192,    10] train_loss: 0.1561 | val_loss: 0.2240
[193,    10] train_loss: 0.1829 | val_loss: 0.2033
[194,    10] train_loss: 0.1657 | val_loss: 0.1674
[195,    10] train_loss: 0.1743 | val_loss: 0.1958
[196,    10] train_loss: 0.1601 | val_loss: 0.1577
[197,    10] train_loss: 0.1588 | val_loss: 0.1724
[198,    10] train_loss: 0.1576 | val_loss: 0.1863
[199,    10] train_loss: 0.1644 | val_loss: 0.2139
[200,    10] train_loss: 0.1657 | val_loss: 0.1729
Total train time: 16.903029115994773min
Evaluating model...
Reference (or Train) Loss: 0.0297
Test (or Query) Loss: 0.1134
Training kNN classifier with k=3
3NN test accuracy: 0.8403

Per label 3NN test accuracy:
0	1.00
1	1.00
2	1.00
3	1.00
4	1.00
5	0.00
6	0.86
7	1.00
8	1.00
9	0.86
10	nan
11	0.67
12	1.00
13	0.67
14	0.69
15	0.83
16	nan
17	0.64
18	0.90
19	0.97
20	0.42
21	0.93
22	0.62
23	1.00
24	0.73
25	0.81
26	1.00
27	1.00
28	1.00
29	0.95
30	0.74
31	1.00
32	1.00
33	1.00
34	1.00
35	0.50
36	0.95
37	0.60
38	0.20
39	0.91
40	1.00
41	1.00
42	0.44
43	1.00
44	0.95
45	1.00
46	0.00
47	1.00
48	0.85
49	0.88
50	1.00
51	1.00
52	0.91
53	0.60
54	0.90
55	nan
56	0.40
57	1.00
58	nan
59	0.00
60	1.00
61	1.00
62	nan
63	0.50
64	nan
65	0.75
66	nan
67	nan

Printing Confusion Matrix:
[[12  0  0 ...  0  0  0]
 [ 0 14  0 ...  0  0  0]
 [ 0  0  9 ...  0  0  0]
 ...
 [ 0  0  0 ...  0  0  0]
 [ 0  0  0 ...  0  3  0]
 [ 0  0  0 ...  0  0  0]]
Saving model...
Finished
