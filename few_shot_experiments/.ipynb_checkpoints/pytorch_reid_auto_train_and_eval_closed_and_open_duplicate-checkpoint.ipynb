{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a95221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d54ee",
   "metadata": {},
   "source": [
    "# closed set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bbc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = '/home/gsantiago/summer_bee_data/closed_sets_4_ids_all_colors_once_batch2'\n",
    "dir = '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2'\n",
    "#dir to start working with \n",
    "\n",
    "#make new wandb project based on dir name\n",
    "\n",
    "\n",
    "test_file = '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv'\n",
    "#test on all of batch 2 (open set) gonna also test on all of batch 1 \n",
    "\n",
    "valid_file = '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'\n",
    "# run valid on smaller subset of test_set to speed training \n",
    "\n",
    "reference_file = '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'\n",
    "#reference knn on smaller subset of batch 1\n",
    "\n",
    "results_file = '/home/lmeyers/ReID_complete/few_shot_experiments/Few_shot_expirament_results_tracking.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897a1581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_4.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_2.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_8.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_16.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_20.csv\n",
      "/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_max.csv\n"
     ]
    }
   ],
   "source": [
    "# Get file list \n",
    "for root, dirs, files in os.walk(dir):\n",
    "    files = files\n",
    "for f in files:\n",
    "    print(root+r'/'+f)\n",
    "    train_file = root+r'/'+f\n",
    "#     continue\n",
    "\n",
    "#files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2 = '/home/gsantiago/summer_bee_data/closed_sets_8_ids_monocolor_batch2'\n",
    "for root2, dirs2, files2 in os.walk(dir):\n",
    "    files2 = files2\n",
    "for f2 in files2:\n",
    "    print(root+r'/'+f2)\n",
    "    train_file2 = root2+r'/'+f2\n",
    "#     continue\n",
    "\n",
    "files = np.concatenate((files,files2))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e737d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels  8\n",
      "Updated batch to contain all Data. Size =  32\n",
      "2023-10-20 03:13:10.820823: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:13:11.957203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_4/wandb/run-20231020_031315-1ljl8gy5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33matomic-cosmos-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/1ljl8gy5\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 03:13\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 32, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_4.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 600, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_4/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_4/8_ids_double_colors_batch2_sample_num_4.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([32, 3, 250, 250])\n",
      "Batch label shape: torch.Size([32])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Total train time: 4.369924020767212min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.7726\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0544\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2537\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1509\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.56\n",
      "1\t0.29\n",
      "2\t0.54\n",
      "3\t0.47\n",
      "4\t0.53\n",
      "5\t0.79\n",
      "6\t0.29\n",
      "7\t0.22\n",
      "8\t0.81\n",
      "9\t0.12\n",
      "10\t0.27\n",
      "11\t0.12\n",
      "12\t0.07\n",
      "13\t0.20\n",
      "14\t0.00\n",
      "15\t0.07\n",
      "16\t0.41\n",
      "17\t0.01\n",
      "18\t0.13\n",
      "19\t0.11\n",
      "20\t0.25\n",
      "21\t0.26\n",
      "22\t0.12\n",
      "23\t0.05\n",
      "24\t0.09\n",
      "25\t0.00\n",
      "26\t0.19\n",
      "27\t0.03\n",
      "28\t0.47\n",
      "29\t0.28\n",
      "30\t0.01\n",
      "31\t0.02\n",
      "32\t0.02\n",
      "33\t0.07\n",
      "34\t0.31\n",
      "35\t0.00\n",
      "36\t0.01\n",
      "37\t0.01\n",
      "38\t0.17\n",
      "39\t0.02\n",
      "40\t0.20\n",
      "41\t0.00\n",
      "42\t0.03\n",
      "43\t0.08\n",
      "44\t0.22\n",
      "45\t0.03\n",
      "46\t0.00\n",
      "47\t0.07\n",
      "48\t0.00\n",
      "49\t0.33\n",
      "50\t0.00\n",
      "51\t0.00\n",
      "52\t0.00\n",
      "53\t0.00\n",
      "54\t0.01\n",
      "55\t0.21\n",
      "56\t0.51\n",
      "57\t0.00\n",
      "58\t0.19\n",
      "59\t0.12\n",
      "61\t0.00\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[ 47   0   1 ...   0   0   0]\n",
      " [  0  35   2 ...   0   0   0]\n",
      " [  0   0 112 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [ 49   2   2 ...   0   0   0]\n",
      " [  6   2   0 ...   0   0   0]]\n",
      "{'1NN_acc': 0.2537, '3NN_acc': 0.1509, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.5595, 0.2917, 0.5385, 0.4684, 0.5333, 0.7871, 0.293 , 0.2181,\n",
      "       0.8067, 0.1244, 0.2654, 0.1186, 0.0732, 0.2   , 0.0043, 0.0743,\n",
      "       0.4074, 0.0083, 0.1324, 0.1053, 0.2537, 0.2617, 0.1176, 0.0495,\n",
      "       0.0863, 0.    , 0.1932, 0.0326, 0.4717, 0.2796, 0.0077, 0.0241,\n",
      "       0.0222, 0.0662, 0.3125, 0.    , 0.0093, 0.0076, 0.1726, 0.0181,\n",
      "       0.2039, 0.    , 0.0345, 0.0833, 0.2212, 0.025 , 0.    , 0.0661,\n",
      "       0.    , 0.3261, 0.    , 0.    , 0.    , 0.    , 0.0087, 0.2073,\n",
      "       0.5056, 0.    , 0.1923, 0.1176, 0.    , 0.    , 0.    ]), 'knn_conf': array([[ 47,   0,   1, ...,   0,   0,   0],\n",
      "       [  0,  35,   2, ...,   0,   0,   0],\n",
      "       [  0,   0, 112, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  0,   0,   0, ...,   0,   0,   0],\n",
      "       [ 49,   2,   2, ...,   0,   0,   0],\n",
      "       [  6,   2,   0, ...,   0,   0,   0]]), 'train_loss': 0.2022264450788498}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.20223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33matomic-cosmos-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/1ljl8gy5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_4/wandb/run-20231020_031315-1ljl8gy5/logs\u001b[0m\n",
      "Num labels  8\n",
      "Updated batch to contain all Data. Size =  16\n",
      "2023-10-20 03:19:25.605297: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:19:26.596873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_2/wandb/run-20231020_031930-vhl0vrzc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfallen-cloud-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/vhl0vrzc\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 03:19\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 16, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_2.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 600, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_2/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_2/8_ids_double_colors_batch2_sample_num_2.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([16, 3, 250, 250])\n",
      "Batch label shape: torch.Size([16])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Total train time: 2.294791316986084min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.7380\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0538\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.1878\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1014\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.43\n",
      "1\t0.17\n",
      "2\t0.38\n",
      "3\t0.38\n",
      "4\t0.53\n",
      "5\t0.37\n",
      "6\t0.09\n",
      "7\t0.13\n",
      "8\t0.21\n",
      "9\t0.03\n",
      "10\t0.18\n",
      "11\t0.21\n",
      "12\t0.22\n",
      "13\t0.44\n",
      "14\t0.03\n",
      "15\t0.14\n",
      "16\t0.30\n",
      "17\t0.19\n",
      "18\t0.13\n",
      "19\t0.03\n",
      "20\t0.06\n",
      "21\t0.23\n",
      "22\t0.18\n",
      "23\t0.02\n",
      "24\t0.00\n",
      "25\t0.04\n",
      "26\t0.02\n",
      "27\t0.09\n",
      "28\t0.04\n",
      "29\t0.27\n",
      "30\t0.00\n",
      "31\t0.14\n",
      "32\t0.00\n",
      "33\t0.04\n",
      "34\t0.03\n",
      "35\t0.16\n",
      "36\t0.41\n",
      "37\t0.00\n",
      "38\t0.02\n",
      "39\t0.01\n",
      "40\t0.04\n",
      "41\t0.00\n",
      "42\t0.00\n",
      "43\t0.00\n",
      "44\t0.69\n",
      "45\t0.03\n",
      "46\t0.00\n",
      "47\t0.02\n",
      "48\t0.00\n",
      "49\t0.00\n",
      "50\t0.00\n",
      "51\t0.00\n",
      "52\t0.00\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.01\n",
      "56\t0.00\n",
      "57\t0.02\n",
      "58\t0.00\n",
      "59\t0.00\n",
      "61\t0.00\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[36  8  0 ...  0  0  0]\n",
      " [ 3 21 23 ...  0  0  0]\n",
      " [26  8 78 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [29 27  8 ...  0  0  0]\n",
      " [ 0  0 22 ...  0  0  0]]\n",
      "{'1NN_acc': 0.1878, '3NN_acc': 0.1014, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.4286, 0.175 , 0.375 , 0.3797, 0.5333, 0.3742, 0.0879, 0.133 ,\n",
      "       0.2067, 0.0287, 0.179 , 0.2102, 0.2195, 0.4417, 0.0303, 0.1362,\n",
      "       0.2963, 0.1917, 0.1324, 0.0263, 0.0597, 0.2336, 0.1765, 0.0248,\n",
      "       0.    , 0.042 , 0.0227, 0.087 , 0.0377, 0.2688, 0.    , 0.1446,\n",
      "       0.    , 0.0379, 0.0312, 0.1624, 0.4074, 0.    , 0.0152, 0.0068,\n",
      "       0.0388, 0.    , 0.    , 0.    , 0.6923, 0.025 , 0.    , 0.0176,\n",
      "       0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.0122,\n",
      "       0.    , 0.0162, 0.    , 0.    , 0.    , 0.    , 0.    ]), 'knn_conf': array([[36,  8,  0, ...,  0,  0,  0],\n",
      "       [ 3, 21, 23, ...,  0,  0,  0],\n",
      "       [26,  8, 78, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ...,  0,  0,  0],\n",
      "       [29, 27,  8, ...,  0,  0,  0],\n",
      "       [ 0,  0, 22, ...,  0,  0,  0]]), 'train_loss': 0.17027822136878967}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.17028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfallen-cloud-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/vhl0vrzc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_2/wandb/run-20231020_031930-vhl0vrzc/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 03:23:36.367693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:23:37.373147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_8/wandb/run-20231020_032340-rwxibn2s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcolorful-eon-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/rwxibn2s\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 03:23\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_8.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 600, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_8/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_8/8_ids_double_colors_batch2_sample_num_8.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Total train time: 7.531417500972748min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.4255\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0425\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2882\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1873\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.60\n",
      "1\t0.36\n",
      "2\t0.25\n",
      "3\t0.65\n",
      "4\t0.57\n",
      "5\t0.17\n",
      "6\t0.29\n",
      "7\t0.35\n",
      "8\t0.72\n",
      "9\t0.18\n",
      "10\t0.01\n",
      "11\t0.50\n",
      "12\t0.13\n",
      "13\t0.47\n",
      "14\t0.03\n",
      "15\t0.03\n",
      "16\t0.00\n",
      "17\t0.04\n",
      "18\t0.18\n",
      "19\t0.76\n",
      "20\t0.60\n",
      "21\t0.32\n",
      "22\t0.18\n",
      "23\t0.00\n",
      "24\t0.10\n",
      "25\t0.00\n",
      "26\t0.16\n",
      "27\t0.03\n",
      "28\t0.44\n",
      "29\t0.15\n",
      "30\t0.02\n",
      "31\t0.18\n",
      "32\t0.16\n",
      "33\t0.03\n",
      "34\t0.01\n",
      "35\t0.21\n",
      "36\t0.58\n",
      "37\t0.01\n",
      "38\t0.01\n",
      "39\t0.20\n",
      "40\t0.30\n",
      "41\t0.07\n",
      "42\t0.03\n",
      "43\t0.00\n",
      "44\t0.56\n",
      "45\t0.00\n",
      "46\t0.29\n",
      "47\t0.00\n",
      "48\t0.28\n",
      "49\t0.00\n",
      "50\t0.01\n",
      "51\t0.00\n",
      "52\t0.26\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.00\n",
      "56\t0.90\n",
      "57\t0.00\n",
      "58\t0.08\n",
      "59\t0.34\n",
      "61\t0.07\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[50  0  8 ...  0  0  0]\n",
      " [ 0 43 32 ...  0  0  0]\n",
      " [ 4  1 53 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  8  0  0]\n",
      " [ 5  0 34 ...  0  0  0]\n",
      " [44  5 30 ...  0  0  0]]\n",
      "{'1NN_acc': 0.2882, '3NN_acc': 0.1873, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.5952, 0.3583, 0.2548, 0.6456, 0.5714, 0.1742, 0.2857, 0.3511,\n",
      "       0.72  , 0.177 , 0.0062, 0.5017, 0.128 , 0.475 , 0.0303, 0.0341,\n",
      "       0.    , 0.0417, 0.1765, 0.7632, 0.597 , 0.3178, 0.1765, 0.    ,\n",
      "       0.1007, 0.    , 0.1591, 0.0272, 0.4371, 0.1505, 0.0154, 0.1807,\n",
      "       0.16  , 0.0284, 0.0052, 0.2137, 0.5833, 0.0076, 0.0051, 0.2041,\n",
      "       0.301 , 0.0699, 0.0345, 0.    , 0.5577, 0.    , 0.2941, 0.0044,\n",
      "       0.2788, 0.    , 0.0125, 0.    , 0.2595, 0.    , 0.    , 0.    ,\n",
      "       0.8989, 0.    , 0.0769, 0.3382, 0.0741, 0.    , 0.    ]), 'knn_conf': array([[50,  0,  8, ...,  0,  0,  0],\n",
      "       [ 0, 43, 32, ...,  0,  0,  0],\n",
      "       [ 4,  1, 53, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ...,  8,  0,  0],\n",
      "       [ 5,  0, 34, ...,  0,  0,  0],\n",
      "       [44,  5, 30, ...,  0,  0,  0]]), 'train_loss': 0.15371032059192657}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.15371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mcolorful-eon-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/rwxibn2s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_8/wandb/run-20231020_032340-rwxibn2s/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 03:33:12.809635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:33:13.899445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_16/wandb/run-20231020_033317-rdymq6zx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mblooming-frog-21\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/rdymq6zx\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 03:33\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_16.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 600, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_16/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_16/8_ids_double_colors_batch2_sample_num_16.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Total train time: 18.33404510418574min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.6624\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0464\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2576\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.194\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.21\n",
      "1\t0.58\n",
      "2\t0.16\n",
      "3\t0.29\n",
      "4\t0.46\n",
      "5\t0.05\n",
      "6\t0.14\n",
      "7\t0.18\n",
      "8\t0.34\n",
      "9\t0.36\n",
      "10\t0.25\n",
      "11\t0.59\n",
      "12\t0.59\n",
      "13\t0.77\n",
      "14\t0.15\n",
      "15\t0.12\n",
      "16\t0.26\n",
      "17\t0.12\n",
      "18\t0.03\n",
      "19\t0.68\n",
      "20\t0.58\n",
      "21\t0.15\n",
      "22\t0.09\n",
      "23\t0.09\n",
      "24\t0.47\n",
      "25\t0.01\n",
      "26\t0.80\n",
      "27\t0.29\n",
      "28\t0.40\n",
      "29\t0.37\n",
      "30\t0.06\n",
      "31\t0.35\n",
      "32\t0.03\n",
      "33\t0.05\n",
      "34\t0.22\n",
      "35\t0.16\n",
      "36\t0.18\n",
      "37\t0.02\n",
      "38\t0.09\n",
      "39\t0.15\n",
      "40\t0.47\n",
      "41\t0.00\n",
      "42\t0.00\n",
      "43\t0.02\n",
      "44\t0.06\n",
      "45\t0.00\n",
      "46\t0.28\n",
      "47\t0.04\n",
      "48\t0.00\n",
      "49\t0.12\n",
      "50\t0.00\n",
      "51\t0.00\n",
      "52\t0.00\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.37\n",
      "56\t0.08\n",
      "57\t0.19\n",
      "58\t0.12\n",
      "59\t0.29\n",
      "61\t0.08\n",
      "62\t0.06\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[18  0 19 ...  0  0  0]\n",
      " [ 0 70  0 ...  0  0  0]\n",
      " [54  0 34 ...  0  1  0]\n",
      " ...\n",
      " [ 0  0  0 ...  9  0  0]\n",
      " [ 4  1 19 ...  0 20  0]\n",
      " [ 5  0  0 ...  0  2  0]]\n",
      "{'1NN_acc': 0.2576, '3NN_acc': 0.194, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.2143, 0.5833, 0.1635, 0.2911, 0.4571, 0.0516, 0.1429, 0.1755,\n",
      "       0.34  , 0.3589, 0.2531, 0.5898, 0.5854, 0.7667, 0.1515, 0.1176,\n",
      "       0.2593, 0.1167, 0.0294, 0.6842, 0.5821, 0.1495, 0.0882, 0.0941,\n",
      "       0.4748, 0.0084, 0.7955, 0.288 , 0.3962, 0.3656, 0.0615, 0.3494,\n",
      "       0.0267, 0.0473, 0.224 , 0.1624, 0.1806, 0.0227, 0.0914, 0.1451,\n",
      "       0.466 , 0.    , 0.    , 0.0238, 0.0577, 0.    , 0.2824, 0.0352,\n",
      "       0.    , 0.1159, 0.    , 0.    , 0.    , 0.    , 0.    , 0.3659,\n",
      "       0.0787, 0.1892, 0.1154, 0.2941, 0.0833, 0.0583, 0.    ]), 'knn_conf': array([[18,  0, 19, ...,  0,  0,  0],\n",
      "       [ 0, 70,  0, ...,  0,  0,  0],\n",
      "       [54,  0, 34, ...,  0,  1,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ...,  9,  0,  0],\n",
      "       [ 4,  1, 19, ...,  0, 20,  0],\n",
      "       [ 5,  0,  0, ...,  0,  2,  0]]), 'train_loss': 0.23654712736606598}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.11926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mblooming-frog-21\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/rdymq6zx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_16/wandb/run-20231020_033317-rdymq6zx/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 03:53:23.976831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:53:25.109913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_20/wandb/run-20231020_035328-mjusfzcn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfloral-galaxy-22\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/mjusfzcn\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 03:53\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_20.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 600, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_20/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_20/8_ids_double_colors_batch2_sample_num_20.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Total train time: 20.237993204593657min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.4282\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0447\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2355\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1677\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.42\n",
      "1\t0.18\n",
      "2\t0.34\n",
      "3\t0.23\n",
      "4\t0.57\n",
      "5\t0.56\n",
      "6\t0.27\n",
      "7\t0.13\n",
      "8\t0.73\n",
      "9\t0.25\n",
      "10\t0.99\n",
      "11\t0.44\n",
      "12\t0.21\n",
      "13\t0.60\n",
      "14\t0.12\n",
      "15\t0.02\n",
      "16\t0.26\n",
      "17\t0.00\n",
      "18\t0.32\n",
      "19\t0.04\n",
      "20\t0.36\n",
      "21\t0.46\n",
      "22\t0.03\n",
      "23\t0.13\n",
      "24\t0.01\n",
      "25\t0.07\n",
      "26\t0.38\n",
      "27\t0.01\n",
      "28\t0.01\n",
      "29\t0.34\n",
      "30\t0.00\n",
      "31\t0.30\n",
      "32\t0.03\n",
      "33\t0.00\n",
      "34\t0.10\n",
      "35\t0.06\n",
      "36\t0.34\n",
      "37\t0.02\n",
      "38\t0.36\n",
      "39\t0.04\n",
      "40\t0.05\n",
      "41\t0.00\n",
      "42\t0.03\n",
      "43\t0.11\n",
      "44\t0.47\n",
      "45\t0.25\n",
      "46\t0.00\n",
      "47\t0.00\n",
      "48\t0.00\n",
      "49\t0.12\n",
      "50\t0.00\n",
      "51\t0.00\n",
      "52\t0.00\n",
      "53\t0.05\n",
      "54\t0.00\n",
      "55\t0.37\n",
      "56\t0.53\n",
      "57\t0.00\n",
      "58\t0.08\n",
      "59\t0.00\n",
      "61\t0.00\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[35  0 11 ...  0  0  0]\n",
      " [ 0 22  0 ...  0  0  0]\n",
      " [39  0 71 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [37  0  7 ...  0  0  0]\n",
      " [15  0 29 ...  0  0  0]]\n",
      "{'1NN_acc': 0.2355, '3NN_acc': 0.1677, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.4167, 0.1833, 0.3413, 0.2278, 0.5714, 0.5613, 0.2711, 0.133 ,\n",
      "       0.7267, 0.2488, 0.9877, 0.4441, 0.2073, 0.6   , 0.1212, 0.0217,\n",
      "       0.2593, 0.    , 0.3235, 0.0395, 0.3582, 0.4579, 0.0294, 0.1287,\n",
      "       0.0072, 0.0672, 0.375 , 0.0054, 0.0126, 0.3441, 0.    , 0.3012,\n",
      "       0.0267, 0.0032, 0.099 , 0.0598, 0.338 , 0.0227, 0.3604, 0.0408,\n",
      "       0.0485, 0.    , 0.0345, 0.1071, 0.4712, 0.25  , 0.    , 0.    ,\n",
      "       0.    , 0.1232, 0.    , 0.    , 0.    , 0.0486, 0.    , 0.3659,\n",
      "       0.5281, 0.    , 0.0769, 0.    , 0.    , 0.    , 0.    ]), 'knn_conf': array([[35,  0, 11, ...,  0,  0,  0],\n",
      "       [ 0, 22,  0, ...,  0,  0,  0],\n",
      "       [39,  0, 71, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ...,  0,  0,  0],\n",
      "       [37,  0,  7, ...,  0,  0,  0],\n",
      "       [15,  0, 29, ...,  0,  0,  0]]), 'train_loss': 0.38467617332935333}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.022 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.12462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfloral-galaxy-22\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/mjusfzcn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_20/wandb/run-20231020_035328-mjusfzcn/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 04:15:30.962253: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 04:15:32.123988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_max/wandb/run-20231020_041537-4vxgc13s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlilac-elevator-23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/4vxgc13s\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 04:15\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_max.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 600, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_max/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_max/8_ids_double_colors_batch2_sample_num_max.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "[1,    10] train_loss: 0.2085 | val_loss: 0.2944\n",
      "Saving checkpoint 0\n",
      "[2,    10] train_loss: 0.2018 | val_loss: 0.3389\n",
      "[3,    10] train_loss: 0.1989 | val_loss: 0.3003\n",
      "[4,    10] train_loss: 0.2148 | val_loss: 0.4082\n",
      "[5,    10] train_loss: 0.2098 | val_loss: 0.3035\n",
      "[6,    10] train_loss: 0.1940 | val_loss: 0.3235\n",
      "[7,    10] train_loss: 0.2084 | val_loss: 0.3340\n",
      "[8,    10] train_loss: 0.2040 | val_loss: 0.3191\n",
      "[9,    10] train_loss: 0.1979 | val_loss: 0.3281\n",
      "[10,    10] train_loss: 0.2015 | val_loss: 0.3652\n",
      "[11,    10] train_loss: 0.1947 | val_loss: 0.3410\n",
      "[12,    10] train_loss: 0.1996 | val_loss: 0.3526\n",
      "[13,    10] train_loss: 0.2041 | val_loss: 0.3488\n",
      "[14,    10] train_loss: 0.2023 | val_loss: 0.3408\n",
      "[15,    10] train_loss: 0.2027 | val_loss: 0.3474\n",
      "[16,    10] train_loss: 0.2052 | val_loss: 0.3720\n",
      "[17,    10] train_loss: 0.1898 | val_loss: 0.3320\n",
      "[18,    10] train_loss: 0.1859 | val_loss: 0.3476\n",
      "[19,    10] train_loss: 0.1764 | val_loss: 0.3484\n",
      "[20,    10] train_loss: 0.1898 | val_loss: 0.3733\n",
      "[21,    10] train_loss: 0.1787 | val_loss: 0.3280\n",
      "[22,    10] train_loss: 0.1749 | val_loss: 0.3453\n",
      "[23,    10] train_loss: 0.1715 | val_loss: 0.3764\n",
      "[24,    10] train_loss: 0.1729 | val_loss: 0.4061\n",
      "[25,    10] train_loss: 0.1704 | val_loss: 0.3782\n",
      "[26,    10] train_loss: 0.1512 | val_loss: 0.3706\n",
      "[27,    10] train_loss: 0.1805 | val_loss: 0.3621\n",
      "[28,    10] train_loss: 0.1885 | val_loss: 0.3776\n",
      "[29,    10] train_loss: 0.1977 | val_loss: 0.3861\n",
      "[30,    10] train_loss: 0.1600 | val_loss: 0.3309\n",
      "[31,    10] train_loss: 0.1623 | val_loss: 0.4023\n",
      "[32,    10] train_loss: 0.1825 | val_loss: 0.4114\n",
      "[33,    10] train_loss: 0.1555 | val_loss: 0.4131\n",
      "[34,    10] train_loss: 0.1775 | val_loss: 0.3943\n",
      "[35,    10] train_loss: 0.1577 | val_loss: 0.4464\n",
      "[36,    10] train_loss: 0.1563 | val_loss: 0.4337\n",
      "[37,    10] train_loss: 0.1478 | val_loss: 0.4084\n",
      "[38,    10] train_loss: 0.1514 | val_loss: 0.4220\n",
      "[39,    10] train_loss: 0.1533 | val_loss: 0.4861\n",
      "[40,    10] train_loss: 0.1592 | val_loss: 0.4000\n",
      "[41,    10] train_loss: 0.1438 | val_loss: 0.4718\n",
      "[42,    10] train_loss: 0.1447 | val_loss: 0.4152\n",
      "[43,    10] train_loss: 0.1445 | val_loss: 0.4751\n",
      "[44,    10] train_loss: 0.1775 | val_loss: 0.5138\n",
      "[45,    10] train_loss: 0.1807 | val_loss: 0.3564\n",
      "[46,    10] train_loss: 0.1631 | val_loss: 0.3586\n",
      "[47,    10] train_loss: 0.1333 | val_loss: 0.3781\n",
      "[48,    10] train_loss: 0.1692 | val_loss: 0.4466\n",
      "[49,    10] train_loss: 0.1713 | val_loss: 0.4556\n",
      "[50,    10] train_loss: 0.1396 | val_loss: 0.4151\n",
      "[51,    10] train_loss: 0.1504 | val_loss: 0.4436\n",
      "Saving checkpoint 50\n",
      "[52,    10] train_loss: 0.1870 | val_loss: 0.4238\n",
      "[53,    10] train_loss: 0.1494 | val_loss: 0.4702\n",
      "[54,    10] train_loss: 0.2042 | val_loss: 0.3276\n",
      "[55,    10] train_loss: 0.1674 | val_loss: 0.4302\n",
      "[56,    10] train_loss: 0.1442 | val_loss: 0.4833\n",
      "[57,    10] train_loss: 0.1402 | val_loss: 0.3798\n",
      "[58,    10] train_loss: 0.1482 | val_loss: 0.4224\n",
      "[59,    10] train_loss: 0.1499 | val_loss: 0.4095\n",
      "[60,    10] train_loss: 0.1488 | val_loss: 0.4188\n",
      "[61,    10] train_loss: 0.1434 | val_loss: 0.4250\n",
      "[62,    10] train_loss: 0.1380 | val_loss: 0.4367\n",
      "[63,    10] train_loss: 0.1426 | val_loss: 0.4546\n",
      "[64,    10] train_loss: 0.1572 | val_loss: 0.4009\n",
      "[65,    10] train_loss: 0.1780 | val_loss: 0.4226\n",
      "[66,    10] train_loss: 0.1424 | val_loss: 0.3994\n",
      "[67,    10] train_loss: 0.1566 | val_loss: 0.4404\n",
      "[68,    10] train_loss: 0.1510 | val_loss: 0.3494\n",
      "[69,    10] train_loss: 0.1759 | val_loss: 0.5343\n",
      "[70,    10] train_loss: 0.1553 | val_loss: 0.4448\n",
      "[71,    10] train_loss: 0.1495 | val_loss: 0.3845\n",
      "[72,    10] train_loss: 0.1863 | val_loss: 0.3964\n",
      "[73,    10] train_loss: 0.1549 | val_loss: 0.4658\n",
      "[74,    10] train_loss: 0.1434 | val_loss: 0.4199\n",
      "[75,    10] train_loss: 0.1432 | val_loss: 0.4414\n",
      "[76,    10] train_loss: 0.1362 | val_loss: 0.4606\n",
      "[77,    10] train_loss: 0.2041 | val_loss: 0.4211\n",
      "[78,    10] train_loss: 0.1656 | val_loss: 0.4035\n",
      "[79,    10] train_loss: 0.1500 | val_loss: 0.3752\n",
      "[80,    10] train_loss: 0.1382 | val_loss: 0.4066\n",
      "[81,    10] train_loss: 0.1340 | val_loss: 0.4257\n",
      "[82,    10] train_loss: 0.1415 | val_loss: 0.4240\n",
      "[83,    10] train_loss: 0.1196 | val_loss: 0.4570\n",
      "[84,    10] train_loss: 0.1322 | val_loss: 0.4182\n",
      "[85,    10] train_loss: 0.1256 | val_loss: 0.3914\n",
      "[86,    10] train_loss: 0.1515 | val_loss: 0.4606\n",
      "[87,    10] train_loss: 0.1201 | val_loss: 0.4494\n",
      "[88,    10] train_loss: 0.1387 | val_loss: 0.4258\n",
      "[89,    10] train_loss: 0.1232 | val_loss: 0.4265\n",
      "[90,    10] train_loss: 0.1421 | val_loss: 0.4523\n",
      "[91,    10] train_loss: 0.1500 | val_loss: 0.5203\n",
      "[92,    10] train_loss: 0.1278 | val_loss: 0.4404\n",
      "[93,    10] train_loss: 0.1364 | val_loss: 0.4265\n",
      "[94,    10] train_loss: 0.1289 | val_loss: 0.4263\n",
      "[95,    10] train_loss: 0.1314 | val_loss: 0.4758\n",
      "[96,    10] train_loss: 0.1365 | val_loss: 0.4504\n",
      "[97,    10] train_loss: 0.1287 | val_loss: 0.4719\n",
      "[98,    10] train_loss: 0.1216 | val_loss: 0.4165\n",
      "[99,    10] train_loss: 0.1243 | val_loss: 0.4298\n",
      "[100,    10] train_loss: 0.1170 | val_loss: 0.4130\n",
      "[101,    10] train_loss: 0.1239 | val_loss: 0.4554\n",
      "Saving checkpoint 100\n",
      "[102,    10] train_loss: 0.1398 | val_loss: 0.4429\n",
      "[103,    10] train_loss: 0.1208 | val_loss: 0.4363\n",
      "[104,    10] train_loss: 0.1333 | val_loss: 0.4873\n",
      "[105,    10] train_loss: 0.1318 | val_loss: 0.4619\n",
      "[106,    10] train_loss: 0.1300 | val_loss: 0.4621\n",
      "[107,    10] train_loss: 0.1330 | val_loss: 0.4668\n",
      "[108,    10] train_loss: 0.1351 | val_loss: 0.5015\n",
      "[109,    10] train_loss: 0.1256 | val_loss: 0.4441\n",
      "[110,    10] train_loss: 0.1330 | val_loss: 0.4378\n",
      "[111,    10] train_loss: 0.1361 | val_loss: 0.4842\n",
      "[112,    10] train_loss: 0.1599 | val_loss: 0.4723\n",
      "[113,    10] train_loss: 0.1937 | val_loss: 0.4208\n",
      "[114,    10] train_loss: 0.1387 | val_loss: 0.3727\n",
      "[115,    10] train_loss: 0.1362 | val_loss: 0.4025\n",
      "[116,    10] train_loss: 0.1075 | val_loss: 0.4565\n",
      "[117,    10] train_loss: 0.1051 | val_loss: 0.4530\n",
      "[118,    10] train_loss: 0.1266 | val_loss: 0.4905\n",
      "[119,    10] train_loss: 0.1303 | val_loss: 0.5277\n",
      "[120,    10] train_loss: 0.1435 | val_loss: 0.4579\n",
      "[121,    10] train_loss: 0.1801 | val_loss: 0.4266\n",
      "[122,    10] train_loss: 0.1620 | val_loss: 0.4417\n",
      "[123,    10] train_loss: 0.1986 | val_loss: 0.4778\n",
      "[124,    10] train_loss: 0.1235 | val_loss: 0.3662\n",
      "[125,    10] train_loss: 0.1256 | val_loss: 0.4646\n",
      "[126,    10] train_loss: 0.1285 | val_loss: 0.5169\n",
      "[127,    10] train_loss: 0.1314 | val_loss: 0.4527\n",
      "[128,    10] train_loss: 0.1147 | val_loss: 0.4259\n",
      "[129,    10] train_loss: 0.0835 | val_loss: 0.4606\n",
      "[130,    10] train_loss: 0.1145 | val_loss: 0.3752\n",
      "[131,    10] train_loss: 0.1140 | val_loss: 0.5202\n",
      "[132,    10] train_loss: 0.1075 | val_loss: 0.3799\n",
      "[133,    10] train_loss: 0.1092 | val_loss: 0.4270\n",
      "[134,    10] train_loss: 0.1223 | val_loss: 0.4605\n",
      "[135,    10] train_loss: 0.1460 | val_loss: 0.4404\n",
      "[136,    10] train_loss: 0.1197 | val_loss: 0.4562\n",
      "[137,    10] train_loss: 0.1495 | val_loss: 0.4349\n",
      "[138,    10] train_loss: 0.1226 | val_loss: 0.4484\n",
      "[139,    10] train_loss: 0.1521 | val_loss: 0.3951\n",
      "[140,    10] train_loss: 0.1490 | val_loss: 0.3979\n",
      "[141,    10] train_loss: 0.1101 | val_loss: 0.4102\n",
      "[142,    10] train_loss: 0.0992 | val_loss: 0.3777\n",
      "[143,    10] train_loss: 0.1038 | val_loss: 0.3423\n",
      "[144,    10] train_loss: 0.1143 | val_loss: 0.4220\n",
      "[145,    10] train_loss: 0.1238 | val_loss: 0.4316\n",
      "[146,    10] train_loss: 0.1200 | val_loss: 0.5069\n",
      "[147,    10] train_loss: 0.0963 | val_loss: 0.4437\n",
      "[148,    10] train_loss: 0.1054 | val_loss: 0.4670\n",
      "[149,    10] train_loss: 0.1103 | val_loss: 0.4528\n",
      "[150,    10] train_loss: 0.1241 | val_loss: 0.4310\n",
      "[151,    10] train_loss: 0.1240 | val_loss: 0.3889\n",
      "Saving checkpoint 150\n",
      "[152,    10] train_loss: 0.1115 | val_loss: 0.4226\n",
      "[153,    10] train_loss: 0.0944 | val_loss: 0.4157\n",
      "[154,    10] train_loss: 0.0726 | val_loss: 0.4314\n",
      "[155,    10] train_loss: 0.1100 | val_loss: 0.4575\n",
      "[156,    10] train_loss: 0.1120 | val_loss: 0.4238\n",
      "[157,    10] train_loss: 0.0697 | val_loss: 0.4646\n",
      "[158,    10] train_loss: 0.0823 | val_loss: 0.4100\n",
      "[159,    10] train_loss: 0.0808 | val_loss: 0.4466\n",
      "[160,    10] train_loss: 0.0954 | val_loss: 0.4564\n",
      "[161,    10] train_loss: 0.1400 | val_loss: 0.4800\n",
      "[162,    10] train_loss: 0.1069 | val_loss: 0.4872\n",
      "[163,    10] train_loss: 0.0826 | val_loss: 0.4793\n",
      "[164,    10] train_loss: 0.1335 | val_loss: 0.4572\n",
      "[165,    10] train_loss: 0.1015 | val_loss: 0.4633\n",
      "[166,    10] train_loss: 0.1191 | val_loss: 0.4347\n",
      "[167,    10] train_loss: 0.0879 | val_loss: 0.4383\n",
      "[168,    10] train_loss: 0.1357 | val_loss: 0.4218\n",
      "[169,    10] train_loss: 0.1027 | val_loss: 0.4019\n",
      "[170,    10] train_loss: 0.1312 | val_loss: 0.4028\n",
      "[171,    10] train_loss: 0.0724 | val_loss: 0.4271\n",
      "[172,    10] train_loss: 0.0904 | val_loss: 0.3957\n",
      "[173,    10] train_loss: 0.1117 | val_loss: 0.4671\n",
      "[174,    10] train_loss: 0.1146 | val_loss: 0.4430\n",
      "[175,    10] train_loss: 0.0881 | val_loss: 0.4335\n",
      "[176,    10] train_loss: 0.1270 | val_loss: 0.4712\n",
      "[177,    10] train_loss: 0.0821 | val_loss: 0.4024\n",
      "[178,    10] train_loss: 0.0812 | val_loss: 0.4450\n",
      "[179,    10] train_loss: 0.0839 | val_loss: 0.4298\n",
      "[180,    10] train_loss: 0.0966 | val_loss: 0.4936\n",
      "[181,    10] train_loss: 0.0300 | val_loss: 0.4069\n",
      "[182,    10] train_loss: 0.0864 | val_loss: 0.4330\n",
      "[183,    10] train_loss: 0.0766 | val_loss: 0.5018\n",
      "[184,    10] train_loss: 0.0972 | val_loss: 0.4677\n",
      "[185,    10] train_loss: 0.0561 | val_loss: 0.4487\n",
      "[186,    10] train_loss: 0.0962 | val_loss: 0.4615\n",
      "[187,    10] train_loss: 0.0855 | val_loss: 0.4276\n",
      "[188,    10] train_loss: 0.0834 | val_loss: 0.4076\n",
      "[189,    10] train_loss: 0.0656 | val_loss: 0.4572\n",
      "[190,    10] train_loss: 0.0626 | val_loss: 0.4307\n",
      "[191,    10] train_loss: 0.0882 | val_loss: 0.4558\n",
      "[192,    10] train_loss: 0.0997 | val_loss: 0.4351\n",
      "[193,    10] train_loss: 0.0799 | val_loss: 0.5000\n",
      "[194,    10] train_loss: 0.0673 | val_loss: 0.4180\n",
      "[195,    10] train_loss: 0.1051 | val_loss: 0.3931\n",
      "[196,    10] train_loss: 0.0730 | val_loss: 0.4206\n",
      "[197,    10] train_loss: 0.0460 | val_loss: 0.4309\n",
      "[198,    10] train_loss: 0.0536 | val_loss: 0.3968\n",
      "[199,    10] train_loss: 0.0572 | val_loss: 0.4075\n",
      "[200,    10] train_loss: 0.1172 | val_loss: 0.4093\n",
      "[201,    10] train_loss: 0.0943 | val_loss: 0.4484\n",
      "Saving checkpoint 200\n",
      "[202,    10] train_loss: 0.1129 | val_loss: 0.4615\n",
      "[203,    10] train_loss: 0.0965 | val_loss: 0.4432\n",
      "[204,    10] train_loss: 0.0900 | val_loss: 0.4553\n",
      "[205,    10] train_loss: 0.0876 | val_loss: 0.4398\n",
      "[206,    10] train_loss: 0.0549 | val_loss: 0.3691\n",
      "[207,    10] train_loss: 0.0676 | val_loss: 0.4373\n",
      "[208,    10] train_loss: 0.0685 | val_loss: 0.4003\n",
      "[209,    10] train_loss: 0.0837 | val_loss: 0.3731\n",
      "[210,    10] train_loss: 0.0720 | val_loss: 0.4055\n",
      "[211,    10] train_loss: 0.1015 | val_loss: 0.4120\n",
      "[212,    10] train_loss: 0.0506 | val_loss: 0.4300\n",
      "[213,    10] train_loss: 0.0624 | val_loss: 0.4392\n",
      "[214,    10] train_loss: 0.0564 | val_loss: 0.4826\n",
      "[215,    10] train_loss: 0.0735 | val_loss: 0.5353\n",
      "[216,    10] train_loss: 0.1083 | val_loss: 0.5040\n",
      "[217,    10] train_loss: 0.0926 | val_loss: 0.4617\n",
      "[218,    10] train_loss: 0.0471 | val_loss: 0.3832\n",
      "[219,    10] train_loss: 0.0495 | val_loss: 0.4359\n",
      "[220,    10] train_loss: 0.0717 | val_loss: 0.4490\n",
      "[221,    10] train_loss: 0.0461 | val_loss: 0.4008\n",
      "[222,    10] train_loss: 0.0129 | val_loss: 0.3653\n",
      "[223,    10] train_loss: 0.0506 | val_loss: 0.3540\n",
      "[224,    10] train_loss: 0.0826 | val_loss: 0.4111\n",
      "[225,    10] train_loss: 0.0662 | val_loss: 0.4216\n",
      "[226,    10] train_loss: 0.0478 | val_loss: 0.4235\n",
      "[227,    10] train_loss: 0.0337 | val_loss: 0.3713\n",
      "[228,    10] train_loss: 0.0401 | val_loss: 0.4674\n",
      "[229,    10] train_loss: 0.0362 | val_loss: 0.4801\n",
      "[230,    10] train_loss: 0.0349 | val_loss: 0.4399\n",
      "[231,    10] train_loss: 0.0355 | val_loss: 0.4382\n",
      "[232,    10] train_loss: 0.0000 | val_loss: 0.4443\n",
      "[233,    10] train_loss: 0.0000 | val_loss: 0.4323\n",
      "[234,    10] train_loss: 0.0231 | val_loss: 0.4243\n",
      "[235,    10] train_loss: 0.0246 | val_loss: 0.4097\n",
      "[236,    10] train_loss: 0.0000 | val_loss: 0.3897\n",
      "[237,    10] train_loss: 0.0106 | val_loss: 0.4051\n",
      "[238,    10] train_loss: 0.0283 | val_loss: 0.4006\n",
      "[239,    10] train_loss: 0.0000 | val_loss: 0.4040\n",
      "[240,    10] train_loss: 0.0216 | val_loss: 0.5053\n",
      "[241,    10] train_loss: 0.0485 | val_loss: 0.4776\n",
      "[242,    10] train_loss: 0.0345 | val_loss: 0.3928\n",
      "[243,    10] train_loss: 0.0000 | val_loss: 0.4134\n",
      "[244,    10] train_loss: 0.0246 | val_loss: 0.3978\n",
      "[245,    10] train_loss: 0.0442 | val_loss: 0.4308\n",
      "[246,    10] train_loss: 0.0949 | val_loss: 0.3553\n",
      "[247,    10] train_loss: 0.0363 | val_loss: 0.4125\n",
      "[248,    10] train_loss: 0.0388 | val_loss: 0.3800\n",
      "[249,    10] train_loss: 0.0615 | val_loss: 0.3613\n",
      "[250,    10] train_loss: 0.0842 | val_loss: 0.4527\n",
      "[251,    10] train_loss: 0.0120 | val_loss: 0.3894\n",
      "Saving checkpoint 250\n",
      "[252,    10] train_loss: 0.0226 | val_loss: 0.4127\n",
      "[253,    10] train_loss: 0.0364 | val_loss: 0.3633\n",
      "[254,    10] train_loss: 0.0653 | val_loss: 0.4585\n",
      "[255,    10] train_loss: 0.0882 | val_loss: 0.4635\n",
      "[256,    10] train_loss: 0.0682 | val_loss: 0.4615\n",
      "[257,    10] train_loss: 0.0991 | val_loss: 0.4106\n",
      "[258,    10] train_loss: 0.0386 | val_loss: 0.4189\n",
      "[259,    10] train_loss: 0.0364 | val_loss: 0.3777\n",
      "[260,    10] train_loss: 0.0892 | val_loss: 0.3716\n",
      "[261,    10] train_loss: 0.0772 | val_loss: 0.4727\n",
      "[262,    10] train_loss: 0.0378 | val_loss: 0.4853\n",
      "[263,    10] train_loss: 0.0979 | val_loss: 0.4416\n",
      "[264,    10] train_loss: 0.0635 | val_loss: 0.3682\n",
      "[265,    10] train_loss: 0.0408 | val_loss: 0.4467\n",
      "[266,    10] train_loss: 0.0117 | val_loss: 0.3789\n",
      "[267,    10] train_loss: 0.0224 | val_loss: 0.4388\n",
      "[268,    10] train_loss: 0.0243 | val_loss: 0.4133\n",
      "[269,    10] train_loss: 0.0317 | val_loss: 0.4409\n",
      "[270,    10] train_loss: 0.0385 | val_loss: 0.4842\n",
      "[271,    10] train_loss: 0.0111 | val_loss: 0.5029\n",
      "[272,    10] train_loss: 0.0227 | val_loss: 0.4776\n",
      "[273,    10] train_loss: 0.0723 | val_loss: 0.4202\n",
      "[274,    10] train_loss: 0.0669 | val_loss: 0.4769\n",
      "[275,    10] train_loss: 0.1423 | val_loss: 0.4106\n",
      "[276,    10] train_loss: 0.0703 | val_loss: 0.4202\n",
      "[277,    10] train_loss: 0.0541 | val_loss: 0.4290\n",
      "[278,    10] train_loss: 0.0101 | val_loss: 0.4040\n",
      "[279,    10] train_loss: 0.0326 | val_loss: 0.4765\n",
      "[280,    10] train_loss: 0.0302 | val_loss: 0.4672\n",
      "[281,    10] train_loss: 0.2425 | val_loss: 0.3947\n",
      "[282,    10] train_loss: 0.0729 | val_loss: 0.4109\n",
      "[283,    10] train_loss: 0.1543 | val_loss: 0.4531\n",
      "[284,    10] train_loss: 0.0926 | val_loss: 0.3863\n",
      "[285,    10] train_loss: 0.0464 | val_loss: 0.3802\n",
      "[286,    10] train_loss: 0.1323 | val_loss: 0.3834\n",
      "[287,    10] train_loss: 0.0828 | val_loss: 0.4536\n",
      "[288,    10] train_loss: 0.0572 | val_loss: 0.4189\n",
      "[289,    10] train_loss: 0.0399 | val_loss: 0.3650\n",
      "[290,    10] train_loss: 0.0610 | val_loss: 0.4011\n",
      "[291,    10] train_loss: 0.0332 | val_loss: 0.4303\n",
      "[292,    10] train_loss: 0.0711 | val_loss: 0.3442\n",
      "[293,    10] train_loss: 0.0603 | val_loss: 0.3776\n",
      "[294,    10] train_loss: 0.0238 | val_loss: 0.3604\n",
      "[295,    10] train_loss: 0.0390 | val_loss: 0.3585\n",
      "[296,    10] train_loss: 0.0226 | val_loss: 0.3327\n",
      "[297,    10] train_loss: 0.0447 | val_loss: 0.3861\n",
      "[298,    10] train_loss: 0.0222 | val_loss: 0.3548\n",
      "[299,    10] train_loss: 0.0104 | val_loss: 0.3449\n",
      "[300,    10] train_loss: 0.0439 | val_loss: 0.4016\n",
      "[301,    10] train_loss: 0.0115 | val_loss: 0.4247\n",
      "Saving checkpoint 300\n",
      "[302,    10] train_loss: 0.0396 | val_loss: 0.3992\n",
      "[303,    10] train_loss: 0.0356 | val_loss: 0.3612\n",
      "[304,    10] train_loss: 0.0344 | val_loss: 0.4033\n",
      "[305,    10] train_loss: 0.0233 | val_loss: 0.3583\n",
      "[306,    10] train_loss: 0.0371 | val_loss: 0.4428\n",
      "[307,    10] train_loss: 0.0649 | val_loss: 0.3817\n",
      "[308,    10] train_loss: 0.0000 | val_loss: 0.3773\n",
      "[309,    10] train_loss: 0.0103 | val_loss: 0.3880\n",
      "[310,    10] train_loss: 0.0249 | val_loss: 0.3639\n",
      "[311,    10] train_loss: 0.0396 | val_loss: 0.4133\n",
      "[312,    10] train_loss: 0.0502 | val_loss: 0.4663\n",
      "[313,    10] train_loss: 0.0129 | val_loss: 0.4559\n",
      "[314,    10] train_loss: 0.0561 | val_loss: 0.4223\n",
      "[315,    10] train_loss: 0.0103 | val_loss: 0.3800\n",
      "[316,    10] train_loss: 0.0362 | val_loss: 0.3688\n",
      "[317,    10] train_loss: 0.0328 | val_loss: 0.3666\n",
      "[318,    10] train_loss: 0.0000 | val_loss: 0.4156\n",
      "[319,    10] train_loss: 0.0279 | val_loss: 0.4259\n",
      "[320,    10] train_loss: 0.0277 | val_loss: 0.4222\n",
      "[321,    10] train_loss: 0.0278 | val_loss: 0.4076\n",
      "[322,    10] train_loss: 0.0133 | val_loss: 0.3760\n",
      "[323,    10] train_loss: 0.0343 | val_loss: 0.4429\n",
      "[324,    10] train_loss: 0.0118 | val_loss: 0.4007\n",
      "[325,    10] train_loss: 0.0353 | val_loss: 0.3828\n",
      "[326,    10] train_loss: 0.0415 | val_loss: 0.3732\n",
      "[327,    10] train_loss: 0.0691 | val_loss: 0.4307\n",
      "[328,    10] train_loss: 0.0337 | val_loss: 0.4136\n",
      "[329,    10] train_loss: 0.0548 | val_loss: 0.4350\n",
      "[330,    10] train_loss: 0.0849 | val_loss: 0.5074\n",
      "[331,    10] train_loss: 0.0803 | val_loss: 0.4212\n",
      "[332,    10] train_loss: 0.0707 | val_loss: 0.3645\n",
      "[333,    10] train_loss: 0.0375 | val_loss: 0.3511\n",
      "[334,    10] train_loss: 0.0105 | val_loss: 0.3471\n",
      "[335,    10] train_loss: 0.0700 | val_loss: 0.3753\n",
      "[336,    10] train_loss: 0.0451 | val_loss: 0.3520\n",
      "[337,    10] train_loss: 0.0115 | val_loss: 0.3683\n",
      "[338,    10] train_loss: 0.0433 | val_loss: 0.3912\n",
      "[339,    10] train_loss: 0.0454 | val_loss: 0.3984\n",
      "[340,    10] train_loss: 0.0739 | val_loss: 0.4250\n",
      "[341,    10] train_loss: 0.0767 | val_loss: 0.4064\n",
      "[342,    10] train_loss: 0.0598 | val_loss: 0.3835\n",
      "[343,    10] train_loss: 0.0114 | val_loss: 0.3904\n",
      "[344,    10] train_loss: 0.0000 | val_loss: 0.3954\n",
      "[345,    10] train_loss: 0.0109 | val_loss: 0.3634\n",
      "[346,    10] train_loss: 0.0245 | val_loss: 0.4043\n",
      "[347,    10] train_loss: 0.0000 | val_loss: 0.3858\n",
      "[348,    10] train_loss: 0.0519 | val_loss: 0.3634\n",
      "[349,    10] train_loss: 0.0219 | val_loss: 0.3072\n",
      "[350,    10] train_loss: 0.0222 | val_loss: 0.3336\n",
      "[351,    10] train_loss: 0.0103 | val_loss: 0.3367\n",
      "Saving checkpoint 350\n",
      "[352,    10] train_loss: 0.2038 | val_loss: 0.4563\n",
      "[353,    10] train_loss: 0.1178 | val_loss: 0.4010\n",
      "[354,    10] train_loss: 0.0837 | val_loss: 0.4449\n",
      "[355,    10] train_loss: 0.0274 | val_loss: 0.4339\n",
      "[356,    10] train_loss: 0.0343 | val_loss: 0.4640\n",
      "[357,    10] train_loss: 0.0853 | val_loss: 0.3890\n",
      "[358,    10] train_loss: 0.0654 | val_loss: 0.3702\n",
      "[359,    10] train_loss: 0.0809 | val_loss: 0.4286\n",
      "[360,    10] train_loss: 0.0398 | val_loss: 0.4552\n",
      "[361,    10] train_loss: 0.0739 | val_loss: 0.4290\n",
      "[362,    10] train_loss: 0.0413 | val_loss: 0.3900\n",
      "[363,    10] train_loss: 0.1231 | val_loss: 0.4553\n",
      "[364,    10] train_loss: 0.0502 | val_loss: 0.4703\n",
      "[365,    10] train_loss: 0.0337 | val_loss: 0.4568\n",
      "[366,    10] train_loss: 0.0254 | val_loss: 0.4022\n",
      "[367,    10] train_loss: 0.0239 | val_loss: 0.4444\n",
      "[368,    10] train_loss: 0.0221 | val_loss: 0.3961\n",
      "[369,    10] train_loss: 0.0573 | val_loss: 0.3628\n",
      "[370,    10] train_loss: 0.0239 | val_loss: 0.3638\n",
      "[371,    10] train_loss: 0.0221 | val_loss: 0.4346\n",
      "[372,    10] train_loss: 0.0113 | val_loss: 0.4481\n",
      "[373,    10] train_loss: 0.0449 | val_loss: 0.3981\n",
      "[374,    10] train_loss: 0.0000 | val_loss: 0.4426\n",
      "[375,    10] train_loss: 0.0101 | val_loss: 0.4223\n",
      "[376,    10] train_loss: 0.0106 | val_loss: 0.4192\n",
      "[377,    10] train_loss: 0.0000 | val_loss: 0.3791\n",
      "[378,    10] train_loss: 0.0127 | val_loss: 0.4596\n",
      "[379,    10] train_loss: 0.0316 | val_loss: 0.5196\n",
      "[380,    10] train_loss: 0.0369 | val_loss: 0.4247\n",
      "[381,    10] train_loss: 0.0210 | val_loss: 0.4606\n",
      "[382,    10] train_loss: 0.0000 | val_loss: 0.4369\n",
      "[383,    10] train_loss: 0.0110 | val_loss: 0.4421\n",
      "[384,    10] train_loss: 0.0000 | val_loss: 0.4585\n",
      "[385,    10] train_loss: 0.0000 | val_loss: 0.4450\n",
      "[386,    10] train_loss: 0.0105 | val_loss: 0.4339\n",
      "[387,    10] train_loss: 0.0000 | val_loss: 0.4569\n",
      "[388,    10] train_loss: 0.0089 | val_loss: 0.4188\n",
      "[389,    10] train_loss: 0.0576 | val_loss: 0.4194\n",
      "[390,    10] train_loss: 0.0122 | val_loss: 0.4079\n",
      "[391,    10] train_loss: 0.0402 | val_loss: 0.4440\n",
      "[392,    10] train_loss: 0.0254 | val_loss: 0.4679\n",
      "[393,    10] train_loss: 0.0224 | val_loss: 0.4237\n",
      "[394,    10] train_loss: 0.0130 | val_loss: 0.4549\n",
      "[395,    10] train_loss: 0.0102 | val_loss: 0.4680\n",
      "[396,    10] train_loss: 0.0000 | val_loss: 0.4544\n",
      "[397,    10] train_loss: 0.0103 | val_loss: 0.4667\n",
      "[398,    10] train_loss: 0.0000 | val_loss: 0.4743\n",
      "[399,    10] train_loss: 0.0102 | val_loss: 0.5153\n",
      "[400,    10] train_loss: 0.0109 | val_loss: 0.4717\n",
      "[401,    10] train_loss: 0.0103 | val_loss: 0.4572\n",
      "Saving checkpoint 400\n",
      "[402,    10] train_loss: 0.0000 | val_loss: 0.4426\n",
      "[403,    10] train_loss: 0.0101 | val_loss: 0.4641\n",
      "[404,    10] train_loss: 0.0000 | val_loss: 0.4212\n",
      "[405,    10] train_loss: 0.0120 | val_loss: 0.4171\n",
      "[406,    10] train_loss: 0.0112 | val_loss: 0.4277\n",
      "[407,    10] train_loss: 0.0227 | val_loss: 0.4567\n",
      "[408,    10] train_loss: 0.0557 | val_loss: 0.4419\n",
      "[409,    10] train_loss: 0.0112 | val_loss: 0.4371\n",
      "[410,    10] train_loss: 0.0083 | val_loss: 0.4406\n",
      "[411,    10] train_loss: 0.0378 | val_loss: 0.5464\n",
      "[412,    10] train_loss: 0.0230 | val_loss: 0.4594\n",
      "[413,    10] train_loss: 0.0642 | val_loss: 0.3990\n",
      "[414,    10] train_loss: 0.0492 | val_loss: 0.4597\n",
      "[415,    10] train_loss: 0.0000 | val_loss: 0.4762\n",
      "[416,    10] train_loss: 0.0120 | val_loss: 0.4772\n",
      "[417,    10] train_loss: 0.0000 | val_loss: 0.4745\n",
      "[418,    10] train_loss: 0.0117 | val_loss: 0.4543\n",
      "[419,    10] train_loss: 0.0000 | val_loss: 0.4778\n",
      "[420,    10] train_loss: 0.0223 | val_loss: 0.4195\n",
      "[421,    10] train_loss: 0.0258 | val_loss: 0.4547\n",
      "[422,    10] train_loss: 0.0274 | val_loss: 0.4736\n",
      "[423,    10] train_loss: 0.0557 | val_loss: 0.4245\n",
      "[424,    10] train_loss: 0.0000 | val_loss: 0.4598\n",
      "[425,    10] train_loss: 0.0246 | val_loss: 0.4322\n",
      "[426,    10] train_loss: 0.0397 | val_loss: 0.4193\n",
      "[427,    10] train_loss: 0.0478 | val_loss: 0.4075\n",
      "[428,    10] train_loss: 0.0128 | val_loss: 0.4442\n",
      "[429,    10] train_loss: 0.0149 | val_loss: 0.4900\n",
      "[430,    10] train_loss: 0.0113 | val_loss: 0.4827\n",
      "[431,    10] train_loss: 0.0459 | val_loss: 0.5123\n",
      "[432,    10] train_loss: 0.0244 | val_loss: 0.4338\n",
      "[433,    10] train_loss: 0.0209 | val_loss: 0.3851\n",
      "[434,    10] train_loss: 0.0000 | val_loss: 0.3901\n",
      "[435,    10] train_loss: 0.0000 | val_loss: 0.3753\n",
      "[436,    10] train_loss: 0.0101 | val_loss: 0.3810\n",
      "[437,    10] train_loss: 0.0000 | val_loss: 0.4066\n",
      "[438,    10] train_loss: 0.0210 | val_loss: 0.4236\n",
      "[439,    10] train_loss: 0.0142 | val_loss: 0.4383\n",
      "[440,    10] train_loss: 0.0000 | val_loss: 0.4602\n",
      "[441,    10] train_loss: 0.0000 | val_loss: 0.4475\n",
      "[442,    10] train_loss: 0.0121 | val_loss: 0.4470\n",
      "[443,    10] train_loss: 0.0348 | val_loss: 0.4928\n",
      "[444,    10] train_loss: 0.0210 | val_loss: 0.4352\n",
      "[445,    10] train_loss: 0.0228 | val_loss: 0.4649\n",
      "[446,    10] train_loss: 0.0113 | val_loss: 0.4345\n",
      "[447,    10] train_loss: 0.0269 | val_loss: 0.4601\n",
      "[448,    10] train_loss: 0.0000 | val_loss: 0.4516\n",
      "[449,    10] train_loss: 0.0238 | val_loss: 0.4689\n",
      "[450,    10] train_loss: 0.0123 | val_loss: 0.4552\n",
      "[451,    10] train_loss: 0.0000 | val_loss: 0.4611\n",
      "Saving checkpoint 450\n",
      "[452,    10] train_loss: 0.0000 | val_loss: 0.4500\n",
      "[453,    10] train_loss: 0.0122 | val_loss: 0.3924\n",
      "[454,    10] train_loss: 0.0000 | val_loss: 0.3504\n",
      "[455,    10] train_loss: 0.0222 | val_loss: 0.3381\n",
      "[456,    10] train_loss: 0.0100 | val_loss: 0.3819\n",
      "[457,    10] train_loss: 0.0113 | val_loss: 0.3792\n",
      "[458,    10] train_loss: 0.0427 | val_loss: 0.3719\n",
      "[459,    10] train_loss: 0.0108 | val_loss: 0.3681\n",
      "[460,    10] train_loss: 0.0000 | val_loss: 0.3678\n",
      "[461,    10] train_loss: 0.0000 | val_loss: 0.3584\n",
      "[462,    10] train_loss: 0.0753 | val_loss: 0.3859\n",
      "[463,    10] train_loss: 0.0618 | val_loss: 0.4391\n",
      "[464,    10] train_loss: 0.0596 | val_loss: 0.3764\n",
      "[465,    10] train_loss: 0.0861 | val_loss: 0.4985\n",
      "[466,    10] train_loss: 0.0508 | val_loss: 0.4801\n",
      "[467,    10] train_loss: 0.1254 | val_loss: 0.4306\n",
      "[468,    10] train_loss: 0.1148 | val_loss: 0.4409\n",
      "[469,    10] train_loss: 0.0592 | val_loss: 0.4503\n",
      "[470,    10] train_loss: 0.0524 | val_loss: 0.4886\n",
      "[471,    10] train_loss: 0.1505 | val_loss: 0.5054\n",
      "[472,    10] train_loss: 0.0554 | val_loss: 0.4768\n",
      "[473,    10] train_loss: 0.0704 | val_loss: 0.4350\n",
      "[474,    10] train_loss: 0.0800 | val_loss: 0.3820\n",
      "[475,    10] train_loss: 0.0304 | val_loss: 0.4233\n",
      "[476,    10] train_loss: 0.0000 | val_loss: 0.4481\n",
      "[477,    10] train_loss: 0.0589 | val_loss: 0.3930\n",
      "[478,    10] train_loss: 0.0115 | val_loss: 0.4103\n",
      "[479,    10] train_loss: 0.0387 | val_loss: 0.3816\n",
      "[480,    10] train_loss: 0.0498 | val_loss: 0.4656\n",
      "[481,    10] train_loss: 0.0315 | val_loss: 0.4335\n",
      "[482,    10] train_loss: 0.0362 | val_loss: 0.4601\n",
      "[483,    10] train_loss: 0.0105 | val_loss: 0.4762\n",
      "[484,    10] train_loss: 0.0000 | val_loss: 0.4908\n",
      "[485,    10] train_loss: 0.0115 | val_loss: 0.4713\n",
      "[486,    10] train_loss: 0.0120 | val_loss: 0.4985\n",
      "[487,    10] train_loss: 0.0132 | val_loss: 0.5061\n",
      "[488,    10] train_loss: 0.0000 | val_loss: 0.5224\n",
      "[489,    10] train_loss: 0.0427 | val_loss: 0.4527\n",
      "[490,    10] train_loss: 0.0204 | val_loss: 0.4215\n",
      "[491,    10] train_loss: 0.0132 | val_loss: 0.4080\n",
      "[492,    10] train_loss: 0.0208 | val_loss: 0.4231\n",
      "[493,    10] train_loss: 0.0121 | val_loss: 0.4268\n",
      "[494,    10] train_loss: 0.0249 | val_loss: 0.4177\n",
      "[495,    10] train_loss: 0.0382 | val_loss: 0.4224\n",
      "[496,    10] train_loss: 0.0148 | val_loss: 0.3849\n",
      "[497,    10] train_loss: 0.0498 | val_loss: 0.4603\n",
      "[498,    10] train_loss: 0.0772 | val_loss: 0.4168\n",
      "[499,    10] train_loss: 0.0417 | val_loss: 0.3962\n",
      "[500,    10] train_loss: 0.0214 | val_loss: 0.3889\n",
      "[501,    10] train_loss: 0.0385 | val_loss: 0.3970\n",
      "Saving checkpoint 500\n",
      "[502,    10] train_loss: 0.0106 | val_loss: 0.3580\n",
      "[503,    10] train_loss: 0.0195 | val_loss: 0.3704\n",
      "[504,    10] train_loss: 0.0895 | val_loss: 0.3943\n",
      "[505,    10] train_loss: 0.0576 | val_loss: 0.3889\n",
      "[506,    10] train_loss: 0.0349 | val_loss: 0.3747\n",
      "[507,    10] train_loss: 0.0148 | val_loss: 0.3804\n",
      "[508,    10] train_loss: 0.0431 | val_loss: 0.3901\n",
      "[509,    10] train_loss: 0.0130 | val_loss: 0.4008\n",
      "[510,    10] train_loss: 0.0105 | val_loss: 0.3959\n",
      "[511,    10] train_loss: 0.0246 | val_loss: 0.3203\n",
      "[512,    10] train_loss: 0.0122 | val_loss: 0.4033\n",
      "[513,    10] train_loss: 0.0000 | val_loss: 0.4062\n",
      "[514,    10] train_loss: 0.0000 | val_loss: 0.4172\n",
      "[515,    10] train_loss: 0.0000 | val_loss: 0.4341\n",
      "[516,    10] train_loss: 0.0000 | val_loss: 0.4366\n",
      "[517,    10] train_loss: 0.0107 | val_loss: 0.4036\n",
      "[518,    10] train_loss: 0.0235 | val_loss: 0.3662\n",
      "[519,    10] train_loss: 0.0147 | val_loss: 0.3873\n",
      "[520,    10] train_loss: 0.0117 | val_loss: 0.3509\n",
      "[521,    10] train_loss: 0.0000 | val_loss: 0.3242\n",
      "[522,    10] train_loss: 0.0113 | val_loss: 0.3329\n",
      "[523,    10] train_loss: 0.0000 | val_loss: 0.3281\n",
      "[524,    10] train_loss: 0.0000 | val_loss: 0.3303\n",
      "[525,    10] train_loss: 0.0229 | val_loss: 0.3301\n",
      "[526,    10] train_loss: 0.0000 | val_loss: 0.3444\n",
      "[527,    10] train_loss: 0.0230 | val_loss: 0.3307\n",
      "[528,    10] train_loss: 0.0261 | val_loss: 0.4357\n",
      "[529,    10] train_loss: 0.0171 | val_loss: 0.4395\n",
      "[530,    10] train_loss: 0.0145 | val_loss: 0.4780\n",
      "[531,    10] train_loss: 0.0100 | val_loss: 0.4230\n",
      "[532,    10] train_loss: 0.0135 | val_loss: 0.3761\n",
      "[533,    10] train_loss: 0.0798 | val_loss: 0.3717\n",
      "[534,    10] train_loss: 0.0578 | val_loss: 0.3525\n",
      "[535,    10] train_loss: 0.0134 | val_loss: 0.3452\n",
      "[536,    10] train_loss: 0.0397 | val_loss: 0.4198\n",
      "[537,    10] train_loss: 0.0117 | val_loss: 0.4386\n",
      "[538,    10] train_loss: 0.0123 | val_loss: 0.3517\n",
      "[539,    10] train_loss: 0.0000 | val_loss: 0.3551\n",
      "[540,    10] train_loss: 0.0119 | val_loss: 0.3966\n",
      "[541,    10] train_loss: 0.0109 | val_loss: 0.3812\n",
      "[542,    10] train_loss: 0.0000 | val_loss: 0.3732\n",
      "[543,    10] train_loss: 0.0123 | val_loss: 0.3695\n",
      "[544,    10] train_loss: 0.0437 | val_loss: 0.3946\n",
      "[545,    10] train_loss: 0.0990 | val_loss: 0.4013\n",
      "[546,    10] train_loss: 0.0597 | val_loss: 0.3461\n",
      "[547,    10] train_loss: 0.0856 | val_loss: 0.3868\n",
      "[548,    10] train_loss: 0.0221 | val_loss: 0.3936\n",
      "[549,    10] train_loss: 0.0226 | val_loss: 0.3952\n",
      "[550,    10] train_loss: 0.0307 | val_loss: 0.3463\n",
      "[551,    10] train_loss: 0.0386 | val_loss: 0.3604\n",
      "Saving checkpoint 550\n",
      "[552,    10] train_loss: 0.0000 | val_loss: 0.4096\n",
      "[553,    10] train_loss: 0.0204 | val_loss: 0.3834\n",
      "[554,    10] train_loss: 0.0509 | val_loss: 0.4145\n",
      "[555,    10] train_loss: 0.0984 | val_loss: 0.5336\n",
      "[556,    10] train_loss: 0.0130 | val_loss: 0.4666\n",
      "[557,    10] train_loss: 0.0416 | val_loss: 0.4843\n",
      "[558,    10] train_loss: 0.0384 | val_loss: 0.4598\n",
      "[559,    10] train_loss: 0.0243 | val_loss: 0.5062\n",
      "[560,    10] train_loss: 0.0250 | val_loss: 0.4990\n",
      "[561,    10] train_loss: 0.0310 | val_loss: 0.4989\n",
      "[562,    10] train_loss: 0.0213 | val_loss: 0.4067\n",
      "[563,    10] train_loss: 0.0104 | val_loss: 0.4324\n",
      "[564,    10] train_loss: 0.0469 | val_loss: 0.4744\n",
      "[565,    10] train_loss: 0.0233 | val_loss: 0.4328\n",
      "[566,    10] train_loss: 0.0119 | val_loss: 0.4664\n",
      "[567,    10] train_loss: 0.0159 | val_loss: 0.4660\n",
      "[568,    10] train_loss: 0.0000 | val_loss: 0.4721\n",
      "[569,    10] train_loss: 0.0116 | val_loss: 0.4505\n",
      "[570,    10] train_loss: 0.0206 | val_loss: 0.4430\n",
      "[571,    10] train_loss: 0.0102 | val_loss: 0.4251\n",
      "[572,    10] train_loss: 0.0000 | val_loss: 0.4141\n",
      "[573,    10] train_loss: 0.0000 | val_loss: 0.4342\n",
      "[574,    10] train_loss: 0.0244 | val_loss: 0.4443\n",
      "[575,    10] train_loss: 0.0364 | val_loss: 0.4309\n",
      "[576,    10] train_loss: 0.0000 | val_loss: 0.4128\n",
      "[577,    10] train_loss: 0.0126 | val_loss: 0.3929\n",
      "[578,    10] train_loss: 0.0000 | val_loss: 0.4164\n",
      "[579,    10] train_loss: 0.0000 | val_loss: 0.4200\n",
      "[580,    10] train_loss: 0.0000 | val_loss: 0.4028\n",
      "[581,    10] train_loss: 0.0356 | val_loss: 0.4644\n",
      "[582,    10] train_loss: 0.0128 | val_loss: 0.4859\n",
      "[583,    10] train_loss: 0.0112 | val_loss: 0.4303\n",
      "[584,    10] train_loss: 0.0214 | val_loss: 0.4729\n",
      "[585,    10] train_loss: 0.0119 | val_loss: 0.3992\n",
      "[586,    10] train_loss: 0.0162 | val_loss: 0.4303\n",
      "[587,    10] train_loss: 0.0000 | val_loss: 0.4512\n",
      "[588,    10] train_loss: 0.0000 | val_loss: 0.4417\n",
      "[589,    10] train_loss: 0.0000 | val_loss: 0.4018\n",
      "[590,    10] train_loss: 0.0220 | val_loss: 0.4089\n",
      "[591,    10] train_loss: 0.0198 | val_loss: 0.3688\n",
      "[592,    10] train_loss: 0.0000 | val_loss: 0.3822\n",
      "[593,    10] train_loss: 0.0111 | val_loss: 0.3943\n",
      "[594,    10] train_loss: 0.0000 | val_loss: 0.3964\n",
      "[595,    10] train_loss: 0.0404 | val_loss: 0.4823\n",
      "[596,    10] train_loss: 0.0195 | val_loss: 0.4383\n",
      "[597,    10] train_loss: 0.1088 | val_loss: 0.4607\n",
      "[598,    10] train_loss: 0.0436 | val_loss: 0.4754\n",
      "[599,    10] train_loss: 0.0252 | val_loss: 0.5110\n",
      "[600,    10] train_loss: 0.0241 | val_loss: 0.5293\n",
      "Total train time: 220.23407316207886min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.4574\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0435\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2966\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.2159\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.50\n",
      "1\t0.62\n",
      "2\t0.09\n",
      "3\t0.77\n",
      "4\t0.38\n",
      "5\t0.32\n",
      "6\t0.26\n",
      "7\t0.03\n",
      "8\t0.40\n",
      "9\t0.21\n",
      "10\t0.02\n",
      "11\t0.06\n",
      "12\t0.51\n",
      "13\t0.42\n",
      "14\t0.23\n",
      "15\t0.06\n",
      "16\t0.26\n",
      "17\t0.28\n",
      "18\t0.22\n",
      "19\t0.76\n",
      "20\t0.43\n",
      "21\t0.33\n",
      "22\t0.06\n",
      "23\t0.21\n",
      "24\t0.27\n",
      "25\t0.07\n",
      "26\t0.76\n",
      "27\t0.76\n",
      "28\t0.06\n",
      "29\t0.09\n",
      "30\t0.32\n",
      "31\t0.07\n",
      "32\t0.03\n",
      "33\t0.01\n",
      "34\t0.20\n",
      "35\t0.08\n",
      "36\t0.66\n",
      "37\t0.01\n",
      "38\t0.34\n",
      "39\t0.34\n",
      "40\t0.67\n",
      "41\t0.01\n",
      "42\t0.17\n",
      "43\t0.08\n",
      "44\t0.76\n",
      "45\t0.15\n",
      "46\t0.42\n",
      "47\t0.00\n",
      "48\t0.01\n",
      "49\t0.46\n",
      "50\t0.05\n",
      "51\t0.00\n",
      "52\t0.10\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.21\n",
      "56\t0.96\n",
      "57\t0.00\n",
      "58\t0.00\n",
      "59\t0.12\n",
      "61\t0.00\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[42  0  2 ...  0  0  0]\n",
      " [ 0 75  0 ...  0  0  0]\n",
      " [14 17 18 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 7 13 39 ...  0  0  0]\n",
      " [27  0 12 ...  0  0  1]]\n",
      "{'1NN_acc': 0.2966, '3NN_acc': 0.2159, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.5   , 0.625 , 0.0865, 0.7722, 0.381 , 0.3226, 0.2564, 0.0266,\n",
      "       0.4   , 0.2057, 0.0247, 0.0576, 0.5122, 0.425 , 0.2251, 0.0557,\n",
      "       0.2593, 0.2833, 0.2206, 0.7632, 0.4328, 0.3271, 0.0588, 0.2129,\n",
      "       0.2734, 0.0672, 0.7614, 0.7609, 0.0566, 0.086 , 0.3154, 0.0723,\n",
      "       0.0311, 0.0126, 0.1979, 0.0769, 0.6574, 0.0076, 0.335 , 0.3401,\n",
      "       0.6699, 0.0108, 0.1724, 0.0833, 0.7596, 0.15  , 0.4235, 0.    ,\n",
      "       0.0096, 0.4638, 0.05  , 0.    , 0.0973, 0.    , 0.    , 0.2073,\n",
      "       0.9551, 0.    , 0.    , 0.1176, 0.    , 0.    , 0.0041]), 'knn_conf': array([[42,  0,  2, ...,  0,  0,  0],\n",
      "       [ 0, 75,  0, ...,  0,  0,  0],\n",
      "       [14, 17, 18, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ...,  0,  0,  0],\n",
      "       [ 7, 13, 39, ...,  0,  0,  0],\n",
      "       [27,  0, 12, ...,  0,  0,  1]]), 'train_loss': 0.0}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.005 MB of 0.047 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid loss ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid loss 0.52934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mlilac-elevator-23\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/4vxgc13s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_max/wandb/run-20231020_041537-4vxgc13s/logs\u001b[0m\n",
      "Num labels  8\n",
      "Updated batch to contain all Data. Size =  32\n",
      "2023-10-20 07:59:13.470555: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 07:59:14.548621: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_4/wandb/run-20231020_075917-lhqlv9qz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdashing-aardvark-24\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/lhqlv9qz\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 07:59\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 32, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_4.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_4/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_4/8_ids_double_colors_batch2_sample_num_4.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([32, 3, 250, 250])\n",
      "Batch label shape: torch.Size([32])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Saving checkpoint 600\n",
      "Saving checkpoint 650\n",
      "Saving checkpoint 700\n",
      "Saving checkpoint 750\n",
      "Saving checkpoint 800\n",
      "Saving checkpoint 850\n",
      "Saving checkpoint 900\n",
      "Saving checkpoint 950\n",
      "Saving checkpoint 1000\n",
      "Saving checkpoint 1050\n",
      "Saving checkpoint 1100\n",
      "Saving checkpoint 1150\n",
      "Saving checkpoint 1200\n",
      "Saving checkpoint 1250\n",
      "Saving checkpoint 1300\n",
      "Saving checkpoint 1350\n",
      "Saving checkpoint 1400\n",
      "Saving checkpoint 1450\n",
      "Total train time: 10.477281057834626min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.7038\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0719\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2398\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1305\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.63\n",
      "1\t0.31\n",
      "2\t0.38\n",
      "3\t0.27\n",
      "4\t0.42\n",
      "5\t0.36\n",
      "6\t0.21\n",
      "7\t0.31\n",
      "8\t0.27\n",
      "9\t0.09\n",
      "10\t0.48\n",
      "11\t0.11\n",
      "12\t0.10\n",
      "13\t0.40\n",
      "14\t0.06\n",
      "15\t0.08\n",
      "16\t0.48\n",
      "17\t0.14\n",
      "18\t0.22\n",
      "19\t0.08\n",
      "20\t0.16\n",
      "21\t0.35\n",
      "22\t0.24\n",
      "23\t0.14\n",
      "24\t0.18\n",
      "25\t0.08\n",
      "26\t0.11\n",
      "27\t0.02\n",
      "28\t0.16\n",
      "29\t0.02\n",
      "30\t0.05\n",
      "31\t0.02\n",
      "32\t0.03\n",
      "33\t0.00\n",
      "34\t0.00\n",
      "35\t0.01\n",
      "36\t0.56\n",
      "37\t0.06\n",
      "38\t0.00\n",
      "39\t0.14\n",
      "40\t0.00\n",
      "41\t0.07\n",
      "42\t0.00\n",
      "43\t0.06\n",
      "44\t0.04\n",
      "45\t0.00\n",
      "46\t0.01\n",
      "47\t0.00\n",
      "48\t0.02\n",
      "49\t0.00\n",
      "50\t0.00\n",
      "51\t0.12\n",
      "52\t0.00\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.01\n",
      "56\t0.78\n",
      "57\t0.00\n",
      "58\t0.00\n",
      "59\t0.07\n",
      "61\t0.00\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[53  6  0 ...  0  0  0]\n",
      " [ 4 37  2 ...  0  0  0]\n",
      " [ 0  0 79 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " [ 0  0 19 ...  0  0  0]\n",
      " [ 3  6 13 ...  0  0  0]]\n",
      "{'1NN_acc': 0.2398, '3NN_acc': 0.1305, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.631 , 0.3083, 0.3798, 0.2658, 0.419 , 0.3613, 0.2125, 0.3138,\n",
      "       0.2733, 0.0861, 0.4815, 0.1085, 0.0976, 0.4   , 0.0606, 0.0836,\n",
      "       0.4815, 0.1417, 0.2206, 0.0789, 0.1642, 0.3458, 0.2353, 0.1436,\n",
      "       0.1799, 0.0756, 0.1136, 0.0163, 0.1635, 0.0215, 0.0462, 0.0241,\n",
      "       0.0267, 0.0032, 0.    , 0.0085, 0.5602, 0.0606, 0.    , 0.1383,\n",
      "       0.    , 0.0699, 0.    , 0.0595, 0.0385, 0.    , 0.0118, 0.    ,\n",
      "       0.0192, 0.    , 0.    , 0.1242, 0.    , 0.    , 0.    , 0.0122,\n",
      "       0.7753, 0.    , 0.    , 0.0735, 0.    , 0.    , 0.    ]), 'knn_conf': array([[53,  6,  0, ...,  0,  0,  0],\n",
      "       [ 4, 37,  2, ...,  0,  0,  0],\n",
      "       [ 0,  0, 79, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  1, ...,  0,  0,  0],\n",
      "       [ 0,  0, 19, ...,  0,  0,  0],\n",
      "       [ 3,  6, 13, ...,  0,  0,  0]]), 'train_loss': 0.1667938381433487}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.006 MB of 0.022 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.16679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdashing-aardvark-24\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/lhqlv9qz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_4/wandb/run-20231020_075917-lhqlv9qz/logs\u001b[0m\n",
      "Num labels  8\n",
      "Updated batch to contain all Data. Size =  16\n",
      "2023-10-20 08:11:35.194839: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 08:11:36.329867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_2/wandb/run-20231020_081139-le904117\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevout-haze-25\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/le904117\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 08:11\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 16, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_2.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_2/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_2/8_ids_double_colors_batch2_sample_num_2.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([16, 3, 250, 250])\n",
      "Batch label shape: torch.Size([16])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Saving checkpoint 600\n",
      "Saving checkpoint 650\n",
      "Saving checkpoint 700\n",
      "Saving checkpoint 750\n",
      "Saving checkpoint 800\n",
      "Saving checkpoint 850\n",
      "Saving checkpoint 900\n",
      "Saving checkpoint 950\n",
      "Saving checkpoint 1000\n",
      "Saving checkpoint 1050\n",
      "Saving checkpoint 1100\n",
      "Saving checkpoint 1150\n",
      "Saving checkpoint 1200\n",
      "Saving checkpoint 1250\n",
      "Saving checkpoint 1300\n",
      "Saving checkpoint 1350\n",
      "Saving checkpoint 1400\n",
      "Saving checkpoint 1450\n",
      "Total train time: 5.4471978664398195min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 1.0721\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0926\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.1632\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1063\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.62\n",
      "1\t0.31\n",
      "2\t0.33\n",
      "3\t0.42\n",
      "4\t0.30\n",
      "5\t0.39\n",
      "6\t0.17\n",
      "7\t0.09\n",
      "8\t0.00\n",
      "9\t0.02\n",
      "10\t0.14\n",
      "11\t0.10\n",
      "12\t0.23\n",
      "13\t0.38\n",
      "14\t0.02\n",
      "15\t0.11\n",
      "16\t0.04\n",
      "17\t0.15\n",
      "18\t0.13\n",
      "19\t0.01\n",
      "20\t0.39\n",
      "21\t0.23\n",
      "22\t0.00\n",
      "23\t0.09\n",
      "24\t0.03\n",
      "25\t0.05\n",
      "26\t0.11\n",
      "27\t0.00\n",
      "28\t0.00\n",
      "29\t0.22\n",
      "30\t0.00\n",
      "31\t0.07\n",
      "32\t0.22\n",
      "33\t0.01\n",
      "34\t0.16\n",
      "35\t0.09\n",
      "36\t0.77\n",
      "37\t0.03\n",
      "38\t0.00\n",
      "39\t0.09\n",
      "40\t0.01\n",
      "41\t0.03\n",
      "42\t0.00\n",
      "43\t0.04\n",
      "44\t0.00\n",
      "45\t0.00\n",
      "46\t0.00\n",
      "47\t0.00\n",
      "48\t0.00\n",
      "49\t0.12\n",
      "50\t0.00\n",
      "51\t0.09\n",
      "52\t0.00\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.00\n",
      "56\t0.00\n",
      "57\t0.00\n",
      "58\t0.00\n",
      "59\t0.00\n",
      "61\t0.00\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[52  7  0 ...  0  0  0]\n",
      " [ 2 37  4 ...  0  0  0]\n",
      " [27 32 68 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [48 38 23 ...  0  0  0]\n",
      " [13  8  0 ...  0  0  0]]\n",
      "{'1NN_acc': 0.1632, '3NN_acc': 0.1063, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.619 , 0.3083, 0.3269, 0.4177, 0.3048, 0.3871, 0.1722, 0.0851,\n",
      "       0.    , 0.0191, 0.142 , 0.0983, 0.2256, 0.3833, 0.0216, 0.1115,\n",
      "       0.037 , 0.15  , 0.1324, 0.0132, 0.3881, 0.2336, 0.    , 0.0941,\n",
      "       0.0288, 0.0504, 0.1136, 0.    , 0.0031, 0.2151, 0.    , 0.0723,\n",
      "       0.2178, 0.0126, 0.1615, 0.0855, 0.7685, 0.0303, 0.    , 0.0862,\n",
      "       0.0097, 0.0269, 0.    , 0.0357, 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.1232, 0.    , 0.087 , 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ]), 'knn_conf': array([[52,  7,  0, ...,  0,  0,  0],\n",
      "       [ 2, 37,  4, ...,  0,  0,  0],\n",
      "       [27, 32, 68, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ...,  0,  0,  0],\n",
      "       [48, 38, 23, ...,  0,  0,  0],\n",
      "       [13,  8,  0, ...,  0,  0,  0]]), 'train_loss': 0.17214232683181763}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.022 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.17214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdevout-haze-25\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/le904117\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_2/wandb/run-20231020_081139-le904117/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 08:18:54.332492: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 08:18:55.591816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_8/wandb/run-20231020_081859-u5p45rdy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msunny-moon-26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/u5p45rdy\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 08:19\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_8.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_8/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_8/8_ids_double_colors_batch2_sample_num_8.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Saving checkpoint 600\n",
      "Saving checkpoint 650\n",
      "Saving checkpoint 700\n",
      "Saving checkpoint 750\n",
      "Saving checkpoint 800\n",
      "Saving checkpoint 850\n",
      "Saving checkpoint 900\n",
      "Saving checkpoint 950\n",
      "Saving checkpoint 1000\n",
      "Saving checkpoint 1050\n",
      "Saving checkpoint 1100\n",
      "Saving checkpoint 1150\n",
      "Saving checkpoint 1200\n",
      "Saving checkpoint 1250\n",
      "Saving checkpoint 1300\n",
      "Saving checkpoint 1350\n",
      "Saving checkpoint 1400\n",
      "Saving checkpoint 1450\n",
      "Total train time: 18.410719100634257min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.4089\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0573\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2641\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.1972\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.23\n",
      "1\t0.38\n",
      "2\t0.19\n",
      "3\t0.38\n",
      "4\t0.60\n",
      "5\t0.11\n",
      "6\t0.39\n",
      "7\t0.14\n",
      "8\t0.29\n",
      "9\t0.14\n",
      "10\t0.38\n",
      "11\t0.67\n",
      "12\t0.74\n",
      "13\t0.49\n",
      "14\t0.13\n",
      "15\t0.09\n",
      "16\t0.22\n",
      "17\t0.06\n",
      "18\t0.10\n",
      "19\t0.34\n",
      "20\t0.13\n",
      "21\t0.50\n",
      "22\t0.12\n",
      "23\t0.12\n",
      "24\t0.28\n",
      "25\t0.00\n",
      "26\t0.00\n",
      "27\t0.12\n",
      "28\t0.14\n",
      "29\t0.34\n",
      "30\t0.02\n",
      "31\t0.18\n",
      "32\t0.14\n",
      "33\t0.01\n",
      "34\t0.07\n",
      "35\t0.09\n",
      "36\t0.61\n",
      "37\t0.00\n",
      "38\t0.12\n",
      "39\t0.35\n",
      "40\t0.63\n",
      "41\t0.00\n",
      "42\t0.00\n",
      "43\t0.01\n",
      "44\t0.38\n",
      "45\t0.00\n",
      "46\t0.22\n",
      "47\t0.10\n",
      "48\t0.37\n",
      "49\t0.02\n",
      "50\t0.00\n",
      "51\t0.00\n",
      "52\t0.00\n",
      "53\t0.02\n",
      "54\t0.00\n",
      "55\t0.17\n",
      "56\t0.10\n",
      "57\t0.00\n",
      "58\t0.00\n",
      "59\t0.04\n",
      "61\t0.25\n",
      "62\t0.16\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[19  2 12 ...  0  4  0]\n",
      " [ 0 46  0 ...  0  0  0]\n",
      " [ 8  2 40 ...  0  5  0]\n",
      " ...\n",
      " [ 0  0  0 ... 27  0  0]\n",
      " [ 7  2  2 ...  0 55  0]\n",
      " [19  3 13 ...  0 15  0]]\n",
      "{'1NN_acc': 0.2641, '3NN_acc': 0.1972, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.2262, 0.3833, 0.1923, 0.3797, 0.6   , 0.1097, 0.3919, 0.1436,\n",
      "       0.2867, 0.1388, 0.3765, 0.6678, 0.7439, 0.4917, 0.1255, 0.0867,\n",
      "       0.2222, 0.0583, 0.1029, 0.3421, 0.1343, 0.5047, 0.1176, 0.1238,\n",
      "       0.2806, 0.    , 0.    , 0.1196, 0.1384, 0.3441, 0.0154, 0.1807,\n",
      "       0.1422, 0.0126, 0.0677, 0.094 , 0.6111, 0.    , 0.1168, 0.3537,\n",
      "       0.6311, 0.    , 0.    , 0.0119, 0.375 , 0.    , 0.2235, 0.1013,\n",
      "       0.3654, 0.0217, 0.    , 0.    , 0.    , 0.0162, 0.    , 0.1707,\n",
      "       0.1011, 0.    , 0.    , 0.0441, 0.25  , 0.1603, 0.    ]), 'knn_conf': array([[19,  2, 12, ...,  0,  4,  0],\n",
      "       [ 0, 46,  0, ...,  0,  0,  0],\n",
      "       [ 8,  2, 40, ...,  0,  5,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ..., 27,  0,  0],\n",
      "       [ 7,  2,  2, ...,  0, 55,  0],\n",
      "       [19,  3, 13, ...,  0, 15,  0]]), 'train_loss': 0.12850427627563477}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.1285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33msunny-moon-26\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/u5p45rdy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_8/wandb/run-20231020_081859-u5p45rdy/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 08:39:13.095474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 08:39:14.233901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_16/wandb/run-20231020_083917-hhmns3w3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-dream-27\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/hhmns3w3\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 08:39\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_16.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_16/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_16/8_ids_double_colors_batch2_sample_num_16.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Saving checkpoint 600\n",
      "Saving checkpoint 650\n",
      "Saving checkpoint 700\n",
      "Saving checkpoint 750\n",
      "Saving checkpoint 800\n",
      "Saving checkpoint 850\n",
      "Saving checkpoint 900\n",
      "Saving checkpoint 950\n",
      "Saving checkpoint 1000\n",
      "Saving checkpoint 1050\n",
      "Saving checkpoint 1100\n",
      "Saving checkpoint 1150\n",
      "Saving checkpoint 1200\n",
      "Saving checkpoint 1250\n",
      "Saving checkpoint 1300\n",
      "Saving checkpoint 1350\n",
      "Saving checkpoint 1400\n",
      "Saving checkpoint 1450\n",
      "Total train time: 68.22599437236786min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.4068\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0525\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.3225\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.2406\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.37\n",
      "1\t0.35\n",
      "2\t0.39\n",
      "3\t0.18\n",
      "4\t0.68\n",
      "5\t0.14\n",
      "6\t0.15\n",
      "7\t0.23\n",
      "8\t0.77\n",
      "9\t0.11\n",
      "10\t0.58\n",
      "11\t0.48\n",
      "12\t0.45\n",
      "13\t0.85\n",
      "14\t0.28\n",
      "15\t0.02\n",
      "16\t0.26\n",
      "17\t0.00\n",
      "18\t0.04\n",
      "19\t0.13\n",
      "20\t0.66\n",
      "21\t0.14\n",
      "22\t0.15\n",
      "23\t0.14\n",
      "24\t0.33\n",
      "25\t0.13\n",
      "26\t0.68\n",
      "27\t0.39\n",
      "28\t0.66\n",
      "29\t0.43\n",
      "30\t0.00\n",
      "31\t0.02\n",
      "32\t0.06\n",
      "33\t0.17\n",
      "34\t0.12\n",
      "35\t0.21\n",
      "36\t0.87\n",
      "37\t0.01\n",
      "38\t0.24\n",
      "39\t0.04\n",
      "40\t0.20\n",
      "41\t0.01\n",
      "42\t0.86\n",
      "43\t0.00\n",
      "44\t0.25\n",
      "45\t0.00\n",
      "46\t0.56\n",
      "47\t0.04\n",
      "48\t0.00\n",
      "49\t0.04\n",
      "50\t0.00\n",
      "51\t0.00\n",
      "52\t0.00\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.18\n",
      "56\t0.99\n",
      "57\t0.00\n",
      "58\t0.00\n",
      "59\t0.56\n",
      "61\t0.49\n",
      "62\t0.20\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[31  0 15 ...  0  0  0]\n",
      " [ 0 42  0 ...  0  0  0]\n",
      " [37  0 82 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 53  0  0]\n",
      " [32  0  2 ...  0 70  0]\n",
      " [31  0 24 ...  0  2  0]]\n",
      "{'1NN_acc': 0.3225, '3NN_acc': 0.2406, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.369 , 0.35  , 0.3942, 0.1772, 0.6762, 0.1355, 0.1538, 0.2287,\n",
      "       0.7667, 0.11  , 0.5802, 0.478 , 0.4512, 0.85  , 0.2814, 0.0217,\n",
      "       0.2593, 0.    , 0.0441, 0.1316, 0.6567, 0.1402, 0.1471, 0.1386,\n",
      "       0.3309, 0.1261, 0.6818, 0.3859, 0.6635, 0.4301, 0.    , 0.0241,\n",
      "       0.0622, 0.1703, 0.1198, 0.2051, 0.8704, 0.0076, 0.2437, 0.0408,\n",
      "       0.2039, 0.0054, 0.8621, 0.    , 0.25  , 0.    , 0.5647, 0.0396,\n",
      "       0.    , 0.0362, 0.    , 0.    , 0.    , 0.    , 0.    , 0.1829,\n",
      "       0.9888, 0.    , 0.    , 0.5588, 0.4907, 0.2041, 0.    ]), 'knn_conf': array([[31,  0, 15, ...,  0,  0,  0],\n",
      "       [ 0, 42,  0, ...,  0,  0,  0],\n",
      "       [37,  0, 82, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 0,  0,  0, ..., 53,  0,  0],\n",
      "       [32,  0,  2, ...,  0, 70,  0],\n",
      "       [31,  0, 24, ...,  0,  2,  0]]), 'train_loss': 0.2329179048538208}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.23292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdry-dream-27\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/hhmns3w3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_16/wandb/run-20231020_083917-hhmns3w3/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 09:50:43.706502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 09:50:44.870064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_20/wandb/run-20231020_095048-0mfytka1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvivid-silence-28\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/0mfytka1\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 09:50\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_20.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_20/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_20/8_ids_double_colors_batch2_sample_num_20.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "Saving checkpoint 0\n",
      "Saving checkpoint 50\n",
      "Saving checkpoint 100\n",
      "Saving checkpoint 150\n",
      "Saving checkpoint 200\n",
      "Saving checkpoint 250\n",
      "Saving checkpoint 300\n",
      "Saving checkpoint 350\n",
      "Saving checkpoint 400\n",
      "Saving checkpoint 450\n",
      "Saving checkpoint 500\n",
      "Saving checkpoint 550\n",
      "Saving checkpoint 600\n",
      "Saving checkpoint 650\n",
      "Saving checkpoint 700\n",
      "Saving checkpoint 750\n",
      "Saving checkpoint 800\n",
      "Saving checkpoint 850\n",
      "Saving checkpoint 900\n",
      "Saving checkpoint 950\n",
      "Saving checkpoint 1000\n",
      "Saving checkpoint 1050\n",
      "Saving checkpoint 1100\n",
      "Saving checkpoint 1150\n",
      "Saving checkpoint 1200\n",
      "Saving checkpoint 1250\n",
      "Saving checkpoint 1300\n",
      "Saving checkpoint 1350\n",
      "Saving checkpoint 1400\n",
      "Saving checkpoint 1450\n",
      "Total train time: 88.43058775663376min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.3998\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0427\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.2782\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.2121\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.79\n",
      "1\t0.11\n",
      "2\t0.28\n",
      "3\t0.47\n",
      "4\t0.70\n",
      "5\t0.31\n",
      "6\t0.31\n",
      "7\t0.12\n",
      "8\t0.30\n",
      "9\t0.43\n",
      "10\t0.99\n",
      "11\t0.23\n",
      "12\t0.89\n",
      "13\t0.23\n",
      "14\t0.06\n",
      "15\t0.05\n",
      "16\t0.11\n",
      "17\t0.10\n",
      "18\t0.26\n",
      "19\t0.07\n",
      "20\t0.13\n",
      "21\t0.01\n",
      "22\t0.03\n",
      "23\t0.05\n",
      "24\t0.19\n",
      "25\t0.00\n",
      "26\t0.31\n",
      "27\t0.34\n",
      "28\t0.40\n",
      "29\t0.51\n",
      "30\t0.01\n",
      "31\t0.01\n",
      "32\t0.04\n",
      "33\t0.24\n",
      "34\t0.47\n",
      "35\t0.05\n",
      "36\t0.49\n",
      "37\t0.21\n",
      "38\t0.24\n",
      "39\t0.10\n",
      "40\t0.79\n",
      "41\t0.02\n",
      "42\t0.00\n",
      "43\t0.06\n",
      "44\t0.48\n",
      "45\t0.00\n",
      "46\t0.22\n",
      "47\t0.00\n",
      "48\t0.00\n",
      "49\t0.01\n",
      "50\t0.01\n",
      "51\t0.00\n",
      "52\t0.12\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.62\n",
      "56\t0.04\n",
      "57\t0.25\n",
      "58\t0.00\n",
      "59\t0.00\n",
      "61\t0.10\n",
      "62\t0.00\n",
      "63\t0.00\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[ 66   0   0 ...   0   0   0]\n",
      " [ 11  13   0 ...   0   0   0]\n",
      " [  7   0  58 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  11   0   0]\n",
      " [ 61   0   7 ...   0   0   0]\n",
      " [115   0  12 ...   0   0   1]]\n",
      "{'1NN_acc': 0.2782, '3NN_acc': 0.2121, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.7857, 0.1083, 0.2788, 0.4684, 0.7048, 0.3097, 0.3114, 0.1223,\n",
      "       0.3   , 0.4258, 0.9877, 0.2305, 0.8902, 0.225 , 0.0649, 0.0464,\n",
      "       0.1111, 0.1   , 0.2647, 0.0658, 0.1343, 0.0093, 0.0294, 0.0545,\n",
      "       0.1871, 0.    , 0.3068, 0.337 , 0.3994, 0.5054, 0.0077, 0.012 ,\n",
      "       0.0356, 0.2366, 0.4688, 0.0513, 0.4907, 0.2121, 0.2386, 0.1043,\n",
      "       0.7864, 0.0161, 0.    , 0.0595, 0.4808, 0.    , 0.2235, 0.    ,\n",
      "       0.    , 0.0072, 0.0125, 0.    , 0.1189, 0.    , 0.    , 0.622 ,\n",
      "       0.0449, 0.2486, 0.    , 0.    , 0.1019, 0.    , 0.0041]), 'knn_conf': array([[ 66,   0,   0, ...,   0,   0,   0],\n",
      "       [ 11,  13,   0, ...,   0,   0,   0],\n",
      "       [  7,   0,  58, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  0,   0,   0, ...,  11,   0,   0],\n",
      "       [ 61,   0,   7, ...,   0,   0,   0],\n",
      "       [115,   0,  12, ...,   0,   0,   1]]), 'train_loss': 0.39577969163656235}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.005 MB of 0.022 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.15562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mvivid-silence-28\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/0mfytka1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_20/wandb/run-20231020_095048-0mfytka1/logs\u001b[0m\n",
      "Num labels  8\n",
      "2023-10-20 11:22:34.705763: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 11:22:35.905323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "finished imports\n",
      "beginning execution\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlqmeyers\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_max/wandb/run-20231020_112239-mhd81vuy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfresh-shadow-29\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/mhd81vuy\u001b[0m\n",
      "Date and time when this experiment was started: 23-10-20 11:22\n",
      "Data Settings:\n",
      "{'aug_p': 0.3, 'batch_size': 64, 'crop_height': None, 'crop_left': None, 'crop_top': None, 'crop_width': None, 'cropped': False, 'datafiles': {'gallery': '/home/lmeyers/ReID_complete/summer_2023_reid_galleries_closed.csv', 'query': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'reference': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv', 'test': '/home/gsantiago/summer_bee_data/open_sets/open_max_ids_batch1/summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv', 'train': '/home/gsantiago/summer_bee_data/closed_sets_8_ids_double_color_batch2/summer_bee_dataset_closed_train_bee_8_ids_double_colors_batch2_sample_num_max.csv', 'valid': '/home/gsantiago/summer_bee_data/closed_sets_max_ids_batch1/summer_bee_dataset_closed_train_bee_balanced_sample_num_2.csv'}, 'dataset': 'summer_2023', 'fname_col': 'filepath', 'gallery_id': 'gallery_id', 'image_id_col': 'image_id', 'input_size': [250, 250], 'iteration_id': 'iteration_id', 'label_col': 'color_num', 'n_distractors': 9, 'split_type': 'closed'}\n",
      "Train Settings:\n",
      "{'checkpoint_to_load': None, 'gpu': 0, 'learning_rate': 0.001, 'margin': 0.2, 'num_epochs': 1500, 'print_k': 10, 'save_checkpoint_freq': 50, 'wandb_dir_path': '/home/lmeyers/ReID_complete/few_shot_experiments/8_ids_double_colors_batch2_sample_num_max/', 'wandb_entity_name': 'meyers_luke_lab', 'wandb_project_name': 'closed_sets_8_ids_double_color_batch2', 'wandb_resume': False, 'wandb_run_id': None}\n",
      "Model Settings:\n",
      "{'latent_dim': 128, 'model_class': 'resnet50_conv3', 'model_path': './8_ids_double_colors_batch2_sample_num_max/8_ids_double_colors_batch2_sample_num_max.pth', 'num_labels': '8'}\n",
      "Using GPU 0\n",
      "Creating train and valid dataloaders...\n",
      "Batch image shape: torch.Size([64, 3, 250, 250])\n",
      "Batch label shape: torch.Size([64])\n",
      "Building model....\n",
      "Loss: TripletMarginLoss(\n",
      "  (distance): CosineSimilarity()\n",
      "  (reducer): AvgNonZeroReducer()\n",
      ")\n",
      "Found device: cuda\n",
      "Training model...\n",
      "[1,    10] train_loss: 0.2082 | val_loss: 0.2961\n",
      "Saving checkpoint 0\n",
      "[2,    10] train_loss: 0.2010 | val_loss: 0.3334\n",
      "[3,    10] train_loss: 0.2021 | val_loss: 0.3241\n",
      "[4,    10] train_loss: 0.2134 | val_loss: 0.3459\n",
      "[5,    10] train_loss: 0.2055 | val_loss: 0.3776\n",
      "[6,    10] train_loss: 0.1982 | val_loss: 0.3214\n",
      "[7,    10] train_loss: 0.2114 | val_loss: 0.2979\n",
      "[8,    10] train_loss: 0.2008 | val_loss: 0.3138\n",
      "[9,    10] train_loss: 0.1951 | val_loss: 0.3199\n",
      "[10,    10] train_loss: 0.2013 | val_loss: 0.3537\n",
      "[11,    10] train_loss: 0.1939 | val_loss: 0.3484\n",
      "[12,    10] train_loss: 0.2034 | val_loss: 0.3616\n",
      "[13,    10] train_loss: 0.2005 | val_loss: 0.3458\n",
      "[14,    10] train_loss: 0.2010 | val_loss: 0.3629\n",
      "[15,    10] train_loss: 0.1978 | val_loss: 0.3005\n",
      "[16,    10] train_loss: 0.2042 | val_loss: 0.3169\n",
      "[17,    10] train_loss: 0.1949 | val_loss: 0.3115\n",
      "[18,    10] train_loss: 0.2042 | val_loss: 0.3588\n",
      "[19,    10] train_loss: 0.1958 | val_loss: 0.3333\n",
      "[20,    10] train_loss: 0.2056 | val_loss: 0.3148\n",
      "[21,    10] train_loss: 0.1909 | val_loss: 0.3907\n",
      "[22,    10] train_loss: 0.1935 | val_loss: 0.3175\n",
      "[23,    10] train_loss: 0.1765 | val_loss: 0.2908\n",
      "[24,    10] train_loss: 0.1650 | val_loss: 0.2979\n",
      "[25,    10] train_loss: 0.1601 | val_loss: 0.3213\n",
      "[26,    10] train_loss: 0.1760 | val_loss: 0.2831\n",
      "[27,    10] train_loss: 0.1591 | val_loss: 0.3566\n",
      "[28,    10] train_loss: 0.1678 | val_loss: 0.3807\n",
      "[29,    10] train_loss: 0.1720 | val_loss: 0.3063\n",
      "[30,    10] train_loss: 0.1675 | val_loss: 0.2991\n",
      "[31,    10] train_loss: 0.1738 | val_loss: 0.3982\n",
      "[32,    10] train_loss: 0.1622 | val_loss: 0.3443\n",
      "[33,    10] train_loss: 0.1687 | val_loss: 0.3638\n",
      "[34,    10] train_loss: 0.1995 | val_loss: 0.4763\n",
      "[35,    10] train_loss: 0.1523 | val_loss: 0.3392\n",
      "[36,    10] train_loss: 0.1594 | val_loss: 0.4146\n",
      "[37,    10] train_loss: 0.2039 | val_loss: 0.3589\n",
      "[38,    10] train_loss: 0.1578 | val_loss: 0.3413\n",
      "[39,    10] train_loss: 0.1574 | val_loss: 0.4004\n",
      "[40,    10] train_loss: 0.1984 | val_loss: 0.3597\n",
      "[41,    10] train_loss: 0.1499 | val_loss: 0.3114\n",
      "[42,    10] train_loss: 0.1764 | val_loss: 0.3052\n",
      "[43,    10] train_loss: 0.1771 | val_loss: 0.3682\n",
      "[44,    10] train_loss: 0.1734 | val_loss: 0.3725\n",
      "[45,    10] train_loss: 0.1561 | val_loss: 0.3239\n",
      "[46,    10] train_loss: 0.1776 | val_loss: 0.3890\n",
      "[47,    10] train_loss: 0.1563 | val_loss: 0.3364\n",
      "[48,    10] train_loss: 0.2346 | val_loss: 0.3633\n",
      "[49,    10] train_loss: 0.1647 | val_loss: 0.3285\n",
      "[50,    10] train_loss: 0.1606 | val_loss: 0.3334\n",
      "[51,    10] train_loss: 0.1600 | val_loss: 0.3305\n",
      "Saving checkpoint 50\n",
      "[52,    10] train_loss: 0.1866 | val_loss: 0.3326\n",
      "[53,    10] train_loss: 0.1710 | val_loss: 0.3484\n",
      "[54,    10] train_loss: 0.1700 | val_loss: 0.3389\n",
      "[55,    10] train_loss: 0.1704 | val_loss: 0.3461\n",
      "[56,    10] train_loss: 0.1686 | val_loss: 0.3336\n",
      "[57,    10] train_loss: 0.1650 | val_loss: 0.3538\n",
      "[58,    10] train_loss: 0.1529 | val_loss: 0.3147\n",
      "[59,    10] train_loss: 0.1673 | val_loss: 0.3356\n",
      "[60,    10] train_loss: 0.1723 | val_loss: 0.3843\n",
      "[61,    10] train_loss: 0.1641 | val_loss: 0.2973\n",
      "[62,    10] train_loss: 0.1962 | val_loss: 0.3582\n",
      "[63,    10] train_loss: 0.1625 | val_loss: 0.3168\n",
      "[64,    10] train_loss: 0.1718 | val_loss: 0.3398\n",
      "[65,    10] train_loss: 0.1569 | val_loss: 0.3302\n",
      "[66,    10] train_loss: 0.1605 | val_loss: 0.3372\n",
      "[67,    10] train_loss: 0.1679 | val_loss: 0.3610\n",
      "[68,    10] train_loss: 0.1636 | val_loss: 0.4299\n",
      "[69,    10] train_loss: 0.1535 | val_loss: 0.3396\n",
      "[70,    10] train_loss: 0.1497 | val_loss: 0.3616\n",
      "[71,    10] train_loss: 0.2090 | val_loss: 0.3568\n",
      "[72,    10] train_loss: 0.1708 | val_loss: 0.3298\n",
      "[73,    10] train_loss: 0.1676 | val_loss: 0.3446\n",
      "[74,    10] train_loss: 0.1465 | val_loss: 0.3597\n",
      "[75,    10] train_loss: 0.1480 | val_loss: 0.3327\n",
      "[76,    10] train_loss: 0.1570 | val_loss: 0.3250\n",
      "[77,    10] train_loss: 0.2066 | val_loss: 0.3732\n",
      "[78,    10] train_loss: 0.1533 | val_loss: 0.3314\n",
      "[79,    10] train_loss: 0.1478 | val_loss: 0.3346\n",
      "[80,    10] train_loss: 0.1441 | val_loss: 0.3434\n",
      "[81,    10] train_loss: 0.1395 | val_loss: 0.3523\n",
      "[82,    10] train_loss: 0.1594 | val_loss: 0.3389\n",
      "[83,    10] train_loss: 0.1491 | val_loss: 0.3985\n",
      "[84,    10] train_loss: 0.1776 | val_loss: 0.3978\n",
      "[85,    10] train_loss: 0.1792 | val_loss: 0.3657\n",
      "[86,    10] train_loss: 0.1790 | val_loss: 0.3338\n",
      "[87,    10] train_loss: 0.1474 | val_loss: 0.4041\n",
      "[88,    10] train_loss: 0.1597 | val_loss: 0.3131\n",
      "[89,    10] train_loss: 0.1453 | val_loss: 0.4083\n",
      "[90,    10] train_loss: 0.1984 | val_loss: 0.4381\n",
      "[91,    10] train_loss: 0.1815 | val_loss: 0.3237\n",
      "[92,    10] train_loss: 0.1353 | val_loss: 0.3303\n",
      "[93,    10] train_loss: 0.1460 | val_loss: 0.3500\n",
      "[94,    10] train_loss: 0.1438 | val_loss: 0.3762\n",
      "[95,    10] train_loss: 0.1316 | val_loss: 0.3380\n",
      "[96,    10] train_loss: 0.1765 | val_loss: 0.3285\n",
      "[97,    10] train_loss: 0.1784 | val_loss: 0.3290\n",
      "[98,    10] train_loss: 0.1558 | val_loss: 0.3415\n",
      "[99,    10] train_loss: 0.1834 | val_loss: 0.3163\n",
      "[100,    10] train_loss: 0.1454 | val_loss: 0.3321\n",
      "[101,    10] train_loss: 0.1712 | val_loss: 0.3187\n",
      "Saving checkpoint 100\n",
      "[102,    10] train_loss: 0.1619 | val_loss: 0.3576\n",
      "[103,    10] train_loss: 0.1356 | val_loss: 0.3580\n",
      "[104,    10] train_loss: 0.1406 | val_loss: 0.3877\n",
      "[105,    10] train_loss: 0.1497 | val_loss: 0.3875\n",
      "[106,    10] train_loss: 0.1419 | val_loss: 0.3711\n",
      "[107,    10] train_loss: 0.1319 | val_loss: 0.4116\n",
      "[108,    10] train_loss: 0.1351 | val_loss: 0.3881\n",
      "[109,    10] train_loss: 0.1104 | val_loss: 0.3644\n",
      "[110,    10] train_loss: 0.1295 | val_loss: 0.3564\n",
      "[111,    10] train_loss: 0.1355 | val_loss: 0.3931\n",
      "[112,    10] train_loss: 0.1509 | val_loss: 0.3680\n",
      "[113,    10] train_loss: 0.1436 | val_loss: 0.4316\n",
      "[114,    10] train_loss: 0.1532 | val_loss: 0.3576\n",
      "[115,    10] train_loss: 0.1701 | val_loss: 0.3950\n",
      "[116,    10] train_loss: 0.1481 | val_loss: 0.3663\n",
      "[117,    10] train_loss: 0.1434 | val_loss: 0.3961\n",
      "[118,    10] train_loss: 0.1624 | val_loss: 0.4049\n",
      "[119,    10] train_loss: 0.1272 | val_loss: 0.3349\n",
      "[120,    10] train_loss: 0.1318 | val_loss: 0.3796\n",
      "[121,    10] train_loss: 0.1354 | val_loss: 0.3977\n",
      "[122,    10] train_loss: 0.1380 | val_loss: 0.3870\n",
      "[123,    10] train_loss: 0.1685 | val_loss: 0.4349\n",
      "[124,    10] train_loss: 0.1565 | val_loss: 0.3499\n",
      "[125,    10] train_loss: 0.1335 | val_loss: 0.3273\n",
      "[126,    10] train_loss: 0.1482 | val_loss: 0.4077\n",
      "[127,    10] train_loss: 0.1389 | val_loss: 0.3823\n",
      "[128,    10] train_loss: 0.1535 | val_loss: 0.4048\n",
      "[129,    10] train_loss: 0.1304 | val_loss: 0.4477\n",
      "[130,    10] train_loss: 0.1319 | val_loss: 0.3838\n",
      "[131,    10] train_loss: 0.1285 | val_loss: 0.4348\n",
      "[132,    10] train_loss: 0.1550 | val_loss: 0.4020\n",
      "[133,    10] train_loss: 0.1359 | val_loss: 0.4578\n",
      "[134,    10] train_loss: 0.1564 | val_loss: 0.4305\n",
      "[135,    10] train_loss: 0.1532 | val_loss: 0.3852\n",
      "[136,    10] train_loss: 0.1490 | val_loss: 0.3425\n",
      "[137,    10] train_loss: 0.1607 | val_loss: 0.3967\n",
      "[138,    10] train_loss: 0.1308 | val_loss: 0.3925\n",
      "[139,    10] train_loss: 0.1596 | val_loss: 0.4001\n",
      "[140,    10] train_loss: 0.1324 | val_loss: 0.3335\n",
      "[141,    10] train_loss: 0.1243 | val_loss: 0.3612\n",
      "[142,    10] train_loss: 0.1196 | val_loss: 0.3737\n",
      "[143,    10] train_loss: 0.1277 | val_loss: 0.3937\n",
      "[144,    10] train_loss: 0.1433 | val_loss: 0.4040\n",
      "[145,    10] train_loss: 0.1352 | val_loss: 0.4260\n",
      "[146,    10] train_loss: 0.1654 | val_loss: 0.4157\n",
      "[147,    10] train_loss: 0.1601 | val_loss: 0.3462\n",
      "[148,    10] train_loss: 0.1900 | val_loss: 0.3536\n",
      "[149,    10] train_loss: 0.1631 | val_loss: 0.3627\n",
      "[150,    10] train_loss: 0.1139 | val_loss: 0.3775\n",
      "[151,    10] train_loss: 0.1659 | val_loss: 0.3902\n",
      "Saving checkpoint 150\n",
      "[152,    10] train_loss: 0.1390 | val_loss: 0.4261\n",
      "[153,    10] train_loss: 0.1581 | val_loss: 0.3738\n",
      "[154,    10] train_loss: 0.1301 | val_loss: 0.4213\n",
      "[155,    10] train_loss: 0.1729 | val_loss: 0.4582\n",
      "[156,    10] train_loss: 0.1436 | val_loss: 0.4703\n",
      "[157,    10] train_loss: 0.1597 | val_loss: 0.3956\n",
      "[158,    10] train_loss: 0.2033 | val_loss: 0.4212\n",
      "[159,    10] train_loss: 0.1804 | val_loss: 0.3235\n",
      "[160,    10] train_loss: 0.1466 | val_loss: 0.3827\n",
      "[161,    10] train_loss: 0.1373 | val_loss: 0.4107\n",
      "[162,    10] train_loss: 0.1410 | val_loss: 0.4088\n",
      "[163,    10] train_loss: 0.1284 | val_loss: 0.4344\n",
      "[164,    10] train_loss: 0.1349 | val_loss: 0.4591\n",
      "[165,    10] train_loss: 0.1223 | val_loss: 0.4497\n",
      "[166,    10] train_loss: 0.1298 | val_loss: 0.4647\n",
      "[167,    10] train_loss: 0.1326 | val_loss: 0.4102\n",
      "[168,    10] train_loss: 0.1256 | val_loss: 0.4247\n",
      "[169,    10] train_loss: 0.1506 | val_loss: 0.4311\n",
      "[170,    10] train_loss: 0.1399 | val_loss: 0.4092\n",
      "[171,    10] train_loss: 0.1143 | val_loss: 0.4280\n",
      "[172,    10] train_loss: 0.1418 | val_loss: 0.4287\n",
      "[173,    10] train_loss: 0.1531 | val_loss: 0.4307\n",
      "[174,    10] train_loss: 0.1350 | val_loss: 0.3796\n",
      "[175,    10] train_loss: 0.1290 | val_loss: 0.4474\n",
      "[176,    10] train_loss: 0.1323 | val_loss: 0.4213\n",
      "[177,    10] train_loss: 0.1780 | val_loss: 0.4144\n",
      "[178,    10] train_loss: 0.1254 | val_loss: 0.3952\n",
      "[179,    10] train_loss: 0.1433 | val_loss: 0.4046\n",
      "[180,    10] train_loss: 0.1323 | val_loss: 0.3841\n",
      "[181,    10] train_loss: 0.1290 | val_loss: 0.3881\n",
      "[182,    10] train_loss: 0.1178 | val_loss: 0.4186\n",
      "[183,    10] train_loss: 0.1214 | val_loss: 0.4072\n",
      "[184,    10] train_loss: 0.1202 | val_loss: 0.4326\n",
      "[185,    10] train_loss: 0.1077 | val_loss: 0.4177\n",
      "[186,    10] train_loss: 0.1293 | val_loss: 0.4526\n",
      "[187,    10] train_loss: 0.0996 | val_loss: 0.3881\n",
      "[188,    10] train_loss: 0.1354 | val_loss: 0.4034\n",
      "[189,    10] train_loss: 0.1170 | val_loss: 0.4281\n",
      "[190,    10] train_loss: 0.1345 | val_loss: 0.4946\n",
      "[191,    10] train_loss: 0.0820 | val_loss: 0.4415\n",
      "[192,    10] train_loss: 0.1367 | val_loss: 0.4140\n",
      "[193,    10] train_loss: 0.1154 | val_loss: 0.3901\n",
      "[194,    10] train_loss: 0.1416 | val_loss: 0.4804\n",
      "[195,    10] train_loss: 0.1046 | val_loss: 0.4398\n",
      "[196,    10] train_loss: 0.1777 | val_loss: 0.4418\n",
      "[197,    10] train_loss: 0.1543 | val_loss: 0.4177\n",
      "[198,    10] train_loss: 0.1181 | val_loss: 0.4238\n",
      "[199,    10] train_loss: 0.1318 | val_loss: 0.4126\n",
      "[200,    10] train_loss: 0.1524 | val_loss: 0.4176\n",
      "[201,    10] train_loss: 0.1213 | val_loss: 0.4093\n",
      "Saving checkpoint 200\n",
      "[202,    10] train_loss: 0.1194 | val_loss: 0.3982\n",
      "[203,    10] train_loss: 0.1182 | val_loss: 0.3980\n",
      "[204,    10] train_loss: 0.1036 | val_loss: 0.4486\n",
      "[205,    10] train_loss: 0.1100 | val_loss: 0.4302\n",
      "[206,    10] train_loss: 0.0714 | val_loss: 0.4309\n",
      "[207,    10] train_loss: 0.1045 | val_loss: 0.4307\n",
      "[208,    10] train_loss: 0.0463 | val_loss: 0.4422\n",
      "[209,    10] train_loss: 0.0807 | val_loss: 0.5710\n",
      "[210,    10] train_loss: 0.0988 | val_loss: 0.4877\n",
      "[211,    10] train_loss: 0.1025 | val_loss: 0.4665\n",
      "[212,    10] train_loss: 0.1211 | val_loss: 0.4848\n",
      "[213,    10] train_loss: 0.1139 | val_loss: 0.4394\n",
      "[214,    10] train_loss: 0.0844 | val_loss: 0.5102\n",
      "[215,    10] train_loss: 0.1130 | val_loss: 0.4337\n",
      "[216,    10] train_loss: 0.1240 | val_loss: 0.4504\n",
      "[217,    10] train_loss: 0.1548 | val_loss: 0.5054\n",
      "[218,    10] train_loss: 0.1198 | val_loss: 0.4671\n",
      "[219,    10] train_loss: 0.1031 | val_loss: 0.5182\n",
      "[220,    10] train_loss: 0.1346 | val_loss: 0.4803\n",
      "[221,    10] train_loss: 0.2195 | val_loss: 0.3952\n",
      "[222,    10] train_loss: 0.1117 | val_loss: 0.4207\n",
      "[223,    10] train_loss: 0.1000 | val_loss: 0.4840\n",
      "[224,    10] train_loss: 0.1148 | val_loss: 0.4200\n",
      "[225,    10] train_loss: 0.1006 | val_loss: 0.4504\n",
      "[226,    10] train_loss: 0.0928 | val_loss: 0.4608\n",
      "[227,    10] train_loss: 0.1222 | val_loss: 0.4548\n",
      "[228,    10] train_loss: 0.1522 | val_loss: 0.4416\n",
      "[229,    10] train_loss: 0.0868 | val_loss: 0.4156\n",
      "[230,    10] train_loss: 0.0969 | val_loss: 0.5196\n",
      "[231,    10] train_loss: 0.1142 | val_loss: 0.4666\n",
      "[232,    10] train_loss: 0.0860 | val_loss: 0.4290\n",
      "[233,    10] train_loss: 0.1378 | val_loss: 0.4609\n",
      "[234,    10] train_loss: 0.0450 | val_loss: 0.4454\n",
      "[235,    10] train_loss: 0.0607 | val_loss: 0.4357\n",
      "[236,    10] train_loss: 0.0453 | val_loss: 0.4531\n",
      "[237,    10] train_loss: 0.0778 | val_loss: 0.4729\n",
      "[238,    10] train_loss: 0.1141 | val_loss: 0.4749\n",
      "[239,    10] train_loss: 0.1322 | val_loss: 0.4445\n",
      "[240,    10] train_loss: 0.1024 | val_loss: 0.4865\n",
      "[241,    10] train_loss: 0.1095 | val_loss: 0.4841\n",
      "[242,    10] train_loss: 0.1026 | val_loss: 0.4481\n",
      "[243,    10] train_loss: 0.0746 | val_loss: 0.5094\n",
      "[244,    10] train_loss: 0.0831 | val_loss: 0.4874\n",
      "[245,    10] train_loss: 0.0859 | val_loss: 0.4007\n",
      "[246,    10] train_loss: 0.0892 | val_loss: 0.4745\n",
      "[247,    10] train_loss: 0.0580 | val_loss: 0.4104\n",
      "[248,    10] train_loss: 0.0833 | val_loss: 0.3912\n",
      "[249,    10] train_loss: 0.0556 | val_loss: 0.4154\n",
      "[250,    10] train_loss: 0.0741 | val_loss: 0.4484\n",
      "[251,    10] train_loss: 0.0787 | val_loss: 0.4028\n",
      "Saving checkpoint 250\n",
      "[252,    10] train_loss: 0.0811 | val_loss: 0.4112\n",
      "[253,    10] train_loss: 0.0812 | val_loss: 0.3993\n",
      "[254,    10] train_loss: 0.0374 | val_loss: 0.4331\n",
      "[255,    10] train_loss: 0.0849 | val_loss: 0.4432\n",
      "[256,    10] train_loss: 0.0924 | val_loss: 0.4220\n",
      "[257,    10] train_loss: 0.1292 | val_loss: 0.4756\n",
      "[258,    10] train_loss: 0.1117 | val_loss: 0.4255\n",
      "[259,    10] train_loss: 0.1220 | val_loss: 0.3652\n",
      "[260,    10] train_loss: 0.0746 | val_loss: 0.3949\n",
      "[261,    10] train_loss: 0.1130 | val_loss: 0.3461\n",
      "[262,    10] train_loss: 0.0732 | val_loss: 0.4132\n",
      "[263,    10] train_loss: 0.1224 | val_loss: 0.4389\n",
      "[264,    10] train_loss: 0.0922 | val_loss: 0.4765\n",
      "[265,    10] train_loss: 0.0985 | val_loss: 0.4383\n",
      "[266,    10] train_loss: 0.1153 | val_loss: 0.4143\n",
      "[267,    10] train_loss: 0.0745 | val_loss: 0.4627\n",
      "[268,    10] train_loss: 0.1484 | val_loss: 0.4541\n",
      "[269,    10] train_loss: 0.0469 | val_loss: 0.3786\n",
      "[270,    10] train_loss: 0.0505 | val_loss: 0.3874\n",
      "[271,    10] train_loss: 0.0637 | val_loss: 0.4237\n",
      "[272,    10] train_loss: 0.0796 | val_loss: 0.4944\n",
      "[273,    10] train_loss: 0.0914 | val_loss: 0.4047\n",
      "[274,    10] train_loss: 0.0945 | val_loss: 0.4045\n",
      "[275,    10] train_loss: 0.1875 | val_loss: 0.5133\n",
      "[276,    10] train_loss: 0.0955 | val_loss: 0.4145\n",
      "[277,    10] train_loss: 0.1236 | val_loss: 0.4077\n",
      "[278,    10] train_loss: 0.0390 | val_loss: 0.4208\n",
      "[279,    10] train_loss: 0.0498 | val_loss: 0.4182\n",
      "[280,    10] train_loss: 0.0237 | val_loss: 0.4494\n",
      "[281,    10] train_loss: 0.0213 | val_loss: 0.4487\n",
      "[282,    10] train_loss: 0.0593 | val_loss: 0.4117\n",
      "[283,    10] train_loss: 0.0706 | val_loss: 0.4235\n",
      "[284,    10] train_loss: 0.0659 | val_loss: 0.4592\n",
      "[285,    10] train_loss: 0.0534 | val_loss: 0.4514\n",
      "[286,    10] train_loss: 0.0497 | val_loss: 0.4532\n",
      "[287,    10] train_loss: 0.0128 | val_loss: 0.4531\n",
      "[288,    10] train_loss: 0.0453 | val_loss: 0.4759\n",
      "[289,    10] train_loss: 0.0837 | val_loss: 0.4292\n",
      "[290,    10] train_loss: 0.0821 | val_loss: 0.4649\n",
      "[291,    10] train_loss: 0.1170 | val_loss: 0.4748\n",
      "[292,    10] train_loss: 0.0880 | val_loss: 0.4709\n",
      "[293,    10] train_loss: 0.1076 | val_loss: 0.4090\n",
      "[294,    10] train_loss: 0.0717 | val_loss: 0.4128\n",
      "[295,    10] train_loss: 0.0927 | val_loss: 0.4876\n",
      "[296,    10] train_loss: 0.0915 | val_loss: 0.4037\n",
      "[297,    10] train_loss: 0.0660 | val_loss: 0.4092\n",
      "[298,    10] train_loss: 0.0117 | val_loss: 0.4144\n",
      "[299,    10] train_loss: 0.0545 | val_loss: 0.3839\n",
      "[300,    10] train_loss: 0.0477 | val_loss: 0.4070\n",
      "[301,    10] train_loss: 0.0538 | val_loss: 0.4808\n",
      "Saving checkpoint 300\n",
      "[302,    10] train_loss: 0.0493 | val_loss: 0.4293\n",
      "[303,    10] train_loss: 0.0390 | val_loss: 0.4354\n",
      "[304,    10] train_loss: 0.0267 | val_loss: 0.4576\n",
      "[305,    10] train_loss: 0.0495 | val_loss: 0.4550\n",
      "[306,    10] train_loss: 0.0729 | val_loss: 0.3760\n",
      "[307,    10] train_loss: 0.1067 | val_loss: 0.3714\n",
      "[308,    10] train_loss: 0.0464 | val_loss: 0.3816\n",
      "[309,    10] train_loss: 0.0394 | val_loss: 0.4178\n",
      "[310,    10] train_loss: 0.0628 | val_loss: 0.4696\n",
      "[311,    10] train_loss: 0.0361 | val_loss: 0.4989\n",
      "[312,    10] train_loss: 0.0101 | val_loss: 0.4682\n",
      "[313,    10] train_loss: 0.0261 | val_loss: 0.4323\n",
      "[314,    10] train_loss: 0.0398 | val_loss: 0.4349\n",
      "[315,    10] train_loss: 0.0494 | val_loss: 0.4685\n",
      "[316,    10] train_loss: 0.0466 | val_loss: 0.4196\n",
      "[317,    10] train_loss: 0.0944 | val_loss: 0.3921\n",
      "[318,    10] train_loss: 0.0999 | val_loss: 0.4446\n",
      "[319,    10] train_loss: 0.1126 | val_loss: 0.4581\n",
      "[320,    10] train_loss: 0.0713 | val_loss: 0.4418\n",
      "[321,    10] train_loss: 0.1062 | val_loss: 0.3610\n",
      "[322,    10] train_loss: 0.0831 | val_loss: 0.4259\n",
      "[323,    10] train_loss: 0.0841 | val_loss: 0.3877\n",
      "[324,    10] train_loss: 0.0513 | val_loss: 0.4219\n",
      "[325,    10] train_loss: 0.0127 | val_loss: 0.4058\n",
      "[326,    10] train_loss: 0.0982 | val_loss: 0.4007\n",
      "[327,    10] train_loss: 0.0330 | val_loss: 0.3975\n",
      "[328,    10] train_loss: 0.0407 | val_loss: 0.3805\n",
      "[329,    10] train_loss: 0.0500 | val_loss: 0.3847\n",
      "[330,    10] train_loss: 0.0809 | val_loss: 0.4241\n",
      "[331,    10] train_loss: 0.0532 | val_loss: 0.4094\n",
      "[332,    10] train_loss: 0.0249 | val_loss: 0.4128\n",
      "[333,    10] train_loss: 0.0377 | val_loss: 0.4245\n",
      "[334,    10] train_loss: 0.0340 | val_loss: 0.4308\n",
      "[335,    10] train_loss: 0.0232 | val_loss: 0.4254\n",
      "[336,    10] train_loss: 0.0427 | val_loss: 0.4202\n",
      "[337,    10] train_loss: 0.0444 | val_loss: 0.4048\n",
      "[338,    10] train_loss: 0.0216 | val_loss: 0.4418\n",
      "[339,    10] train_loss: 0.0115 | val_loss: 0.4010\n",
      "[340,    10] train_loss: 0.0210 | val_loss: 0.4372\n",
      "[341,    10] train_loss: 0.0582 | val_loss: 0.4448\n",
      "[342,    10] train_loss: 0.0666 | val_loss: 0.4718\n",
      "[343,    10] train_loss: 0.0342 | val_loss: 0.4190\n",
      "[344,    10] train_loss: 0.0437 | val_loss: 0.4452\n",
      "[345,    10] train_loss: 0.0149 | val_loss: 0.4314\n",
      "[346,    10] train_loss: 0.0941 | val_loss: 0.4349\n",
      "[347,    10] train_loss: 0.1083 | val_loss: 0.4145\n",
      "[348,    10] train_loss: 0.0782 | val_loss: 0.3849\n",
      "[349,    10] train_loss: 0.0243 | val_loss: 0.3764\n",
      "[350,    10] train_loss: 0.0336 | val_loss: 0.4010\n",
      "[351,    10] train_loss: 0.0345 | val_loss: 0.4002\n",
      "Saving checkpoint 350\n",
      "[352,    10] train_loss: 0.0644 | val_loss: 0.4225\n",
      "[353,    10] train_loss: 0.0922 | val_loss: 0.4599\n",
      "[354,    10] train_loss: 0.0692 | val_loss: 0.4621\n",
      "[355,    10] train_loss: 0.0534 | val_loss: 0.4455\n",
      "[356,    10] train_loss: 0.0561 | val_loss: 0.4787\n",
      "[357,    10] train_loss: 0.0699 | val_loss: 0.4808\n",
      "[358,    10] train_loss: 0.0469 | val_loss: 0.4562\n",
      "[359,    10] train_loss: 0.0529 | val_loss: 0.4640\n",
      "[360,    10] train_loss: 0.0707 | val_loss: 0.4333\n",
      "[361,    10] train_loss: 0.0623 | val_loss: 0.3989\n",
      "[362,    10] train_loss: 0.0698 | val_loss: 0.4168\n",
      "[363,    10] train_loss: 0.0498 | val_loss: 0.3703\n",
      "[364,    10] train_loss: 0.0105 | val_loss: 0.4236\n",
      "[365,    10] train_loss: 0.0000 | val_loss: 0.4659\n",
      "[366,    10] train_loss: 0.0585 | val_loss: 0.4598\n",
      "[367,    10] train_loss: 0.0529 | val_loss: 0.4155\n",
      "[368,    10] train_loss: 0.0657 | val_loss: 0.3936\n",
      "[369,    10] train_loss: 0.0694 | val_loss: 0.3910\n",
      "[370,    10] train_loss: 0.0236 | val_loss: 0.3930\n",
      "[371,    10] train_loss: 0.0541 | val_loss: 0.3834\n",
      "[372,    10] train_loss: 0.0216 | val_loss: 0.3823\n",
      "[373,    10] train_loss: 0.0478 | val_loss: 0.3692\n",
      "[374,    10] train_loss: 0.1026 | val_loss: 0.4207\n",
      "[375,    10] train_loss: 0.0489 | val_loss: 0.4237\n",
      "[376,    10] train_loss: 0.0743 | val_loss: 0.4356\n",
      "[377,    10] train_loss: 0.0907 | val_loss: 0.4008\n",
      "[378,    10] train_loss: 0.1197 | val_loss: 0.4089\n",
      "[379,    10] train_loss: 0.1040 | val_loss: 0.4287\n",
      "[380,    10] train_loss: 0.0215 | val_loss: 0.4446\n",
      "[381,    10] train_loss: 0.0350 | val_loss: 0.3872\n",
      "[382,    10] train_loss: 0.0634 | val_loss: 0.3764\n",
      "[383,    10] train_loss: 0.0547 | val_loss: 0.4136\n",
      "[384,    10] train_loss: 0.0327 | val_loss: 0.4255\n",
      "[385,    10] train_loss: 0.0000 | val_loss: 0.4086\n",
      "[386,    10] train_loss: 0.0361 | val_loss: 0.4237\n",
      "[387,    10] train_loss: 0.0338 | val_loss: 0.4532\n",
      "[388,    10] train_loss: 0.0147 | val_loss: 0.4202\n",
      "[389,    10] train_loss: 0.0143 | val_loss: 0.4003\n",
      "[390,    10] train_loss: 0.0448 | val_loss: 0.4012\n",
      "[391,    10] train_loss: 0.0340 | val_loss: 0.4251\n",
      "[392,    10] train_loss: 0.0211 | val_loss: 0.4322\n",
      "[393,    10] train_loss: 0.0000 | val_loss: 0.4224\n",
      "[394,    10] train_loss: 0.0372 | val_loss: 0.3713\n",
      "[395,    10] train_loss: 0.0000 | val_loss: 0.3888\n",
      "[396,    10] train_loss: 0.0335 | val_loss: 0.3656\n",
      "[397,    10] train_loss: 0.0339 | val_loss: 0.3642\n",
      "[398,    10] train_loss: 0.0559 | val_loss: 0.4488\n",
      "[399,    10] train_loss: 0.0250 | val_loss: 0.4440\n",
      "[400,    10] train_loss: 0.0263 | val_loss: 0.4265\n",
      "[401,    10] train_loss: 0.0341 | val_loss: 0.4501\n",
      "Saving checkpoint 400\n",
      "[402,    10] train_loss: 0.0230 | val_loss: 0.4492\n",
      "[403,    10] train_loss: 0.0430 | val_loss: 0.4239\n",
      "[404,    10] train_loss: 0.0121 | val_loss: 0.4547\n",
      "[405,    10] train_loss: 0.0497 | val_loss: 0.4363\n",
      "[406,    10] train_loss: 0.0260 | val_loss: 0.4226\n",
      "[407,    10] train_loss: 0.0401 | val_loss: 0.4097\n",
      "[408,    10] train_loss: 0.0267 | val_loss: 0.4419\n",
      "[409,    10] train_loss: 0.0401 | val_loss: 0.4637\n",
      "[410,    10] train_loss: 0.0929 | val_loss: 0.4226\n",
      "[411,    10] train_loss: 0.0486 | val_loss: 0.5036\n",
      "[412,    10] train_loss: 0.0705 | val_loss: 0.4209\n",
      "[413,    10] train_loss: 0.0859 | val_loss: 0.4574\n",
      "[414,    10] train_loss: 0.0443 | val_loss: 0.5416\n",
      "[415,    10] train_loss: 0.0374 | val_loss: 0.4740\n",
      "[416,    10] train_loss: 0.0391 | val_loss: 0.4864\n",
      "[417,    10] train_loss: 0.0271 | val_loss: 0.4596\n",
      "[418,    10] train_loss: 0.0402 | val_loss: 0.3953\n",
      "[419,    10] train_loss: 0.0267 | val_loss: 0.4731\n",
      "[420,    10] train_loss: 0.0110 | val_loss: 0.4799\n",
      "[421,    10] train_loss: 0.0366 | val_loss: 0.4180\n",
      "[422,    10] train_loss: 0.0234 | val_loss: 0.4358\n",
      "[423,    10] train_loss: 0.0378 | val_loss: 0.4039\n",
      "[424,    10] train_loss: 0.0000 | val_loss: 0.3943\n",
      "[425,    10] train_loss: 0.0149 | val_loss: 0.3892\n",
      "[426,    10] train_loss: 0.0360 | val_loss: 0.3861\n",
      "[427,    10] train_loss: 0.0353 | val_loss: 0.3808\n",
      "[428,    10] train_loss: 0.0000 | val_loss: 0.4048\n",
      "[429,    10] train_loss: 0.0000 | val_loss: 0.3949\n",
      "[430,    10] train_loss: 0.0151 | val_loss: 0.4115\n",
      "[431,    10] train_loss: 0.0121 | val_loss: 0.4360\n",
      "[432,    10] train_loss: 0.0109 | val_loss: 0.4366\n",
      "[433,    10] train_loss: 0.0405 | val_loss: 0.4346\n",
      "[434,    10] train_loss: 0.0000 | val_loss: 0.4296\n",
      "[435,    10] train_loss: 0.0144 | val_loss: 0.4584\n",
      "[436,    10] train_loss: 0.0000 | val_loss: 0.4598\n",
      "[437,    10] train_loss: 0.0103 | val_loss: 0.4531\n",
      "[438,    10] train_loss: 0.0286 | val_loss: 0.4480\n",
      "[439,    10] train_loss: 0.1003 | val_loss: 0.4663\n",
      "[440,    10] train_loss: 0.0240 | val_loss: 0.3972\n",
      "[441,    10] train_loss: 0.0227 | val_loss: 0.4287\n",
      "[442,    10] train_loss: 0.0345 | val_loss: 0.3760\n",
      "[443,    10] train_loss: 0.0110 | val_loss: 0.4157\n",
      "[444,    10] train_loss: 0.0562 | val_loss: 0.4377\n",
      "[445,    10] train_loss: 0.0476 | val_loss: 0.4535\n",
      "[446,    10] train_loss: 0.0437 | val_loss: 0.4403\n",
      "[447,    10] train_loss: 0.0112 | val_loss: 0.4656\n",
      "[448,    10] train_loss: 0.0290 | val_loss: 0.3882\n",
      "[449,    10] train_loss: 0.0530 | val_loss: 0.4289\n",
      "[450,    10] train_loss: 0.0355 | val_loss: 0.4265\n",
      "[451,    10] train_loss: 0.0619 | val_loss: 0.4608\n",
      "Saving checkpoint 450\n",
      "[452,    10] train_loss: 0.0248 | val_loss: 0.3805\n",
      "[453,    10] train_loss: 0.0281 | val_loss: 0.4388\n",
      "[454,    10] train_loss: 0.0655 | val_loss: 0.3883\n",
      "[455,    10] train_loss: 0.0114 | val_loss: 0.3792\n",
      "[456,    10] train_loss: 0.0250 | val_loss: 0.3688\n",
      "[457,    10] train_loss: 0.0286 | val_loss: 0.3769\n",
      "[458,    10] train_loss: 0.0339 | val_loss: 0.3827\n",
      "[459,    10] train_loss: 0.0476 | val_loss: 0.3865\n",
      "[460,    10] train_loss: 0.0572 | val_loss: 0.3849\n",
      "[461,    10] train_loss: 0.1102 | val_loss: 0.4079\n",
      "[462,    10] train_loss: 0.0357 | val_loss: 0.3764\n",
      "[463,    10] train_loss: 0.0464 | val_loss: 0.3583\n",
      "[464,    10] train_loss: 0.0960 | val_loss: 0.3443\n",
      "[465,    10] train_loss: 0.0837 | val_loss: 0.3874\n",
      "[466,    10] train_loss: 0.0275 | val_loss: 0.3811\n",
      "[467,    10] train_loss: 0.0571 | val_loss: 0.4355\n",
      "[468,    10] train_loss: 0.0637 | val_loss: 0.4083\n",
      "[469,    10] train_loss: 0.0124 | val_loss: 0.4150\n",
      "[470,    10] train_loss: 0.0406 | val_loss: 0.4247\n",
      "[471,    10] train_loss: 0.0128 | val_loss: 0.4196\n",
      "[472,    10] train_loss: 0.0336 | val_loss: 0.4341\n",
      "[473,    10] train_loss: 0.0282 | val_loss: 0.3835\n",
      "[474,    10] train_loss: 0.0559 | val_loss: 0.3894\n",
      "[475,    10] train_loss: 0.0521 | val_loss: 0.3857\n",
      "[476,    10] train_loss: 0.0595 | val_loss: 0.3383\n",
      "[477,    10] train_loss: 0.0138 | val_loss: 0.3442\n",
      "[478,    10] train_loss: 0.0103 | val_loss: 0.3722\n",
      "[479,    10] train_loss: 0.0134 | val_loss: 0.3745\n",
      "[480,    10] train_loss: 0.0127 | val_loss: 0.3702\n",
      "[481,    10] train_loss: 0.0000 | val_loss: 0.3588\n",
      "[482,    10] train_loss: 0.0000 | val_loss: 0.3617\n",
      "[483,    10] train_loss: 0.0000 | val_loss: 0.3589\n",
      "[484,    10] train_loss: 0.0000 | val_loss: 0.3653\n",
      "[485,    10] train_loss: 0.0377 | val_loss: 0.3762\n",
      "[486,    10] train_loss: 0.0116 | val_loss: 0.3336\n",
      "[487,    10] train_loss: 0.0288 | val_loss: 0.3584\n",
      "[488,    10] train_loss: 0.0487 | val_loss: 0.3500\n",
      "[489,    10] train_loss: 0.0112 | val_loss: 0.3693\n",
      "[490,    10] train_loss: 0.0140 | val_loss: 0.3719\n",
      "[491,    10] train_loss: 0.0000 | val_loss: 0.3718\n",
      "[492,    10] train_loss: 0.0000 | val_loss: 0.3957\n",
      "[493,    10] train_loss: 0.0000 | val_loss: 0.4356\n",
      "[494,    10] train_loss: 0.0287 | val_loss: 0.4026\n",
      "[495,    10] train_loss: 0.0245 | val_loss: 0.4027\n",
      "[496,    10] train_loss: 0.0362 | val_loss: 0.3994\n",
      "[497,    10] train_loss: 0.0000 | val_loss: 0.3883\n",
      "[498,    10] train_loss: 0.0416 | val_loss: 0.4159\n",
      "[499,    10] train_loss: 0.1276 | val_loss: 0.3862\n",
      "[500,    10] train_loss: 0.0375 | val_loss: 0.3901\n",
      "[501,    10] train_loss: 0.0400 | val_loss: 0.3637\n",
      "Saving checkpoint 500\n",
      "[502,    10] train_loss: 0.0495 | val_loss: 0.3592\n",
      "[503,    10] train_loss: 0.0150 | val_loss: 0.3552\n",
      "[504,    10] train_loss: 0.0363 | val_loss: 0.3536\n",
      "[505,    10] train_loss: 0.0334 | val_loss: 0.3917\n",
      "[506,    10] train_loss: 0.0099 | val_loss: 0.3649\n",
      "[507,    10] train_loss: 0.0108 | val_loss: 0.3718\n",
      "[508,    10] train_loss: 0.0408 | val_loss: 0.3695\n",
      "[509,    10] train_loss: 0.0122 | val_loss: 0.4327\n",
      "[510,    10] train_loss: 0.0000 | val_loss: 0.4289\n",
      "[511,    10] train_loss: 0.0000 | val_loss: 0.4225\n",
      "[512,    10] train_loss: 0.0000 | val_loss: 0.4231\n",
      "[513,    10] train_loss: 0.0241 | val_loss: 0.3821\n",
      "[514,    10] train_loss: 0.0197 | val_loss: 0.3771\n",
      "[515,    10] train_loss: 0.0110 | val_loss: 0.3799\n",
      "[516,    10] train_loss: 0.0459 | val_loss: 0.3965\n",
      "[517,    10] train_loss: 0.0000 | val_loss: 0.4022\n",
      "[518,    10] train_loss: 0.0114 | val_loss: 0.3831\n",
      "[519,    10] train_loss: 0.0129 | val_loss: 0.3947\n",
      "[520,    10] train_loss: 0.0000 | val_loss: 0.3766\n",
      "[521,    10] train_loss: 0.0116 | val_loss: 0.3929\n",
      "[522,    10] train_loss: 0.0000 | val_loss: 0.3819\n",
      "[523,    10] train_loss: 0.0000 | val_loss: 0.3865\n",
      "[524,    10] train_loss: 0.0145 | val_loss: 0.4146\n",
      "[525,    10] train_loss: 0.0000 | val_loss: 0.3844\n",
      "[526,    10] train_loss: 0.0104 | val_loss: 0.3486\n",
      "[527,    10] train_loss: 0.0136 | val_loss: 0.3913\n",
      "[528,    10] train_loss: 0.0907 | val_loss: 0.4442\n",
      "[529,    10] train_loss: 0.0100 | val_loss: 0.4923\n",
      "[530,    10] train_loss: 0.0111 | val_loss: 0.4937\n",
      "[531,    10] train_loss: 0.0541 | val_loss: 0.4785\n",
      "[532,    10] train_loss: 0.0648 | val_loss: 0.4491\n",
      "[533,    10] train_loss: 0.0867 | val_loss: 0.3924\n",
      "[534,    10] train_loss: 0.0537 | val_loss: 0.3417\n",
      "[535,    10] train_loss: 0.0625 | val_loss: 0.3124\n",
      "[536,    10] train_loss: 0.0597 | val_loss: 0.3490\n",
      "[537,    10] train_loss: 0.0000 | val_loss: 0.3728\n",
      "[538,    10] train_loss: 0.0241 | val_loss: 0.3709\n",
      "[539,    10] train_loss: 0.0165 | val_loss: 0.3448\n",
      "[540,    10] train_loss: 0.0102 | val_loss: 0.3538\n",
      "[541,    10] train_loss: 0.0400 | val_loss: 0.3208\n",
      "[542,    10] train_loss: 0.0480 | val_loss: 0.3486\n",
      "[543,    10] train_loss: 0.0111 | val_loss: 0.3519\n",
      "[544,    10] train_loss: 0.0115 | val_loss: 0.3760\n",
      "[545,    10] train_loss: 0.0230 | val_loss: 0.4111\n",
      "[546,    10] train_loss: 0.1075 | val_loss: 0.4008\n",
      "[547,    10] train_loss: 0.1237 | val_loss: 0.3581\n",
      "[548,    10] train_loss: 0.0806 | val_loss: 0.3789\n",
      "[549,    10] train_loss: 0.1212 | val_loss: 0.3653\n",
      "[550,    10] train_loss: 0.0263 | val_loss: 0.3597\n",
      "[551,    10] train_loss: 0.0115 | val_loss: 0.3837\n",
      "Saving checkpoint 550\n",
      "[552,    10] train_loss: 0.0449 | val_loss: 0.4277\n",
      "[553,    10] train_loss: 0.0479 | val_loss: 0.4019\n",
      "[554,    10] train_loss: 0.1273 | val_loss: 0.3581\n",
      "[555,    10] train_loss: 0.0630 | val_loss: 0.3419\n",
      "[556,    10] train_loss: 0.0668 | val_loss: 0.3475\n",
      "[557,    10] train_loss: 0.0525 | val_loss: 0.3435\n",
      "[558,    10] train_loss: 0.0607 | val_loss: 0.3577\n",
      "[559,    10] train_loss: 0.0237 | val_loss: 0.3700\n",
      "[560,    10] train_loss: 0.0124 | val_loss: 0.3637\n",
      "[561,    10] train_loss: 0.0108 | val_loss: 0.3771\n",
      "[562,    10] train_loss: 0.0118 | val_loss: 0.3577\n",
      "[563,    10] train_loss: 0.0000 | val_loss: 0.3843\n",
      "[564,    10] train_loss: 0.0000 | val_loss: 0.3655\n",
      "[565,    10] train_loss: 0.0220 | val_loss: 0.3518\n",
      "[566,    10] train_loss: 0.0000 | val_loss: 0.3622\n",
      "[567,    10] train_loss: 0.0000 | val_loss: 0.3679\n",
      "[568,    10] train_loss: 0.0126 | val_loss: 0.3675\n",
      "[569,    10] train_loss: 0.0299 | val_loss: 0.3621\n",
      "[570,    10] train_loss: 0.0229 | val_loss: 0.3520\n",
      "[571,    10] train_loss: 0.0000 | val_loss: 0.3663\n",
      "[572,    10] train_loss: 0.0247 | val_loss: 0.3675\n",
      "[573,    10] train_loss: 0.0125 | val_loss: 0.3730\n",
      "[574,    10] train_loss: 0.0000 | val_loss: 0.3832\n",
      "[575,    10] train_loss: 0.0000 | val_loss: 0.3934\n",
      "[576,    10] train_loss: 0.0114 | val_loss: 0.3677\n",
      "[577,    10] train_loss: 0.0132 | val_loss: 0.3576\n",
      "[578,    10] train_loss: 0.0000 | val_loss: 0.3874\n",
      "[579,    10] train_loss: 0.0000 | val_loss: 0.3855\n",
      "[580,    10] train_loss: 0.0000 | val_loss: 0.3743\n",
      "[581,    10] train_loss: 0.0000 | val_loss: 0.3976\n",
      "[582,    10] train_loss: 0.0000 | val_loss: 0.3755\n",
      "[583,    10] train_loss: 0.0123 | val_loss: 0.3745\n",
      "[584,    10] train_loss: 0.0114 | val_loss: 0.3782\n",
      "[585,    10] train_loss: 0.0000 | val_loss: 0.3719\n",
      "[586,    10] train_loss: 0.0000 | val_loss: 0.4033\n",
      "[587,    10] train_loss: 0.0000 | val_loss: 0.3936\n",
      "[588,    10] train_loss: 0.0000 | val_loss: 0.3715\n",
      "[589,    10] train_loss: 0.0000 | val_loss: 0.3707\n",
      "[590,    10] train_loss: 0.0143 | val_loss: 0.3857\n",
      "[591,    10] train_loss: 0.0000 | val_loss: 0.3893\n",
      "[592,    10] train_loss: 0.0000 | val_loss: 0.3798\n",
      "[593,    10] train_loss: 0.0147 | val_loss: 0.3653\n",
      "[594,    10] train_loss: 0.0127 | val_loss: 0.4086\n",
      "[595,    10] train_loss: 0.0000 | val_loss: 0.3843\n",
      "[596,    10] train_loss: 0.0000 | val_loss: 0.3847\n",
      "[597,    10] train_loss: 0.0414 | val_loss: 0.3572\n",
      "[598,    10] train_loss: 0.0541 | val_loss: 0.3531\n",
      "[599,    10] train_loss: 0.0000 | val_loss: 0.3638\n",
      "[600,    10] train_loss: 0.0101 | val_loss: 0.3580\n",
      "[601,    10] train_loss: 0.0223 | val_loss: 0.3421\n",
      "Saving checkpoint 600\n",
      "[602,    10] train_loss: 0.0119 | val_loss: 0.3423\n",
      "[603,    10] train_loss: 0.0000 | val_loss: 0.3497\n",
      "[604,    10] train_loss: 0.0000 | val_loss: 0.3539\n",
      "[605,    10] train_loss: 0.0000 | val_loss: 0.3523\n",
      "[606,    10] train_loss: 0.0106 | val_loss: 0.3397\n",
      "[607,    10] train_loss: 0.0236 | val_loss: 0.3543\n",
      "[608,    10] train_loss: 0.0256 | val_loss: 0.3681\n",
      "[609,    10] train_loss: 0.0124 | val_loss: 0.3698\n",
      "[610,    10] train_loss: 0.0361 | val_loss: 0.3536\n",
      "[611,    10] train_loss: 0.0341 | val_loss: 0.3340\n",
      "[612,    10] train_loss: 0.0000 | val_loss: 0.3618\n",
      "[613,    10] train_loss: 0.0000 | val_loss: 0.3700\n",
      "[614,    10] train_loss: 0.0129 | val_loss: 0.3812\n",
      "[615,    10] train_loss: 0.0353 | val_loss: 0.3784\n",
      "[616,    10] train_loss: 0.0303 | val_loss: 0.3972\n",
      "[617,    10] train_loss: 0.0770 | val_loss: 0.4119\n",
      "[618,    10] train_loss: 0.0000 | val_loss: 0.3788\n",
      "[619,    10] train_loss: 0.0100 | val_loss: 0.3877\n",
      "[620,    10] train_loss: 0.0129 | val_loss: 0.3813\n",
      "[621,    10] train_loss: 0.0000 | val_loss: 0.3923\n",
      "[622,    10] train_loss: 0.0110 | val_loss: 0.3926\n",
      "[623,    10] train_loss: 0.0000 | val_loss: 0.3713\n",
      "[624,    10] train_loss: 0.0201 | val_loss: 0.3481\n",
      "[625,    10] train_loss: 0.0350 | val_loss: 0.3531\n",
      "[626,    10] train_loss: 0.0118 | val_loss: 0.3858\n",
      "[627,    10] train_loss: 0.0576 | val_loss: 0.3896\n",
      "[628,    10] train_loss: 0.0381 | val_loss: 0.3823\n",
      "[629,    10] train_loss: 0.0204 | val_loss: 0.3680\n",
      "[630,    10] train_loss: 0.0246 | val_loss: 0.3784\n",
      "[631,    10] train_loss: 0.0114 | val_loss: 0.3800\n",
      "[632,    10] train_loss: 0.0109 | val_loss: 0.4024\n",
      "[633,    10] train_loss: 0.0000 | val_loss: 0.4055\n",
      "[634,    10] train_loss: 0.0000 | val_loss: 0.3839\n",
      "[635,    10] train_loss: 0.0120 | val_loss: 0.4077\n",
      "[636,    10] train_loss: 0.0000 | val_loss: 0.3918\n",
      "[637,    10] train_loss: 0.0542 | val_loss: 0.3825\n",
      "[638,    10] train_loss: 0.0000 | val_loss: 0.3934\n",
      "[639,    10] train_loss: 0.0000 | val_loss: 0.3787\n",
      "[640,    10] train_loss: 0.0108 | val_loss: 0.3855\n",
      "[641,    10] train_loss: 0.0154 | val_loss: 0.4108\n",
      "[642,    10] train_loss: 0.0105 | val_loss: 0.3861\n",
      "[643,    10] train_loss: 0.0000 | val_loss: 0.3489\n",
      "[644,    10] train_loss: 0.0119 | val_loss: 0.3773\n",
      "[645,    10] train_loss: 0.0000 | val_loss: 0.3909\n",
      "[646,    10] train_loss: 0.0000 | val_loss: 0.3922\n",
      "[647,    10] train_loss: 0.0218 | val_loss: 0.3996\n",
      "[648,    10] train_loss: 0.0000 | val_loss: 0.4056\n",
      "[649,    10] train_loss: 0.0155 | val_loss: 0.4234\n",
      "[650,    10] train_loss: 0.0132 | val_loss: 0.4087\n",
      "[651,    10] train_loss: 0.0406 | val_loss: 0.3942\n",
      "Saving checkpoint 650\n",
      "[652,    10] train_loss: 0.0220 | val_loss: 0.3641\n",
      "[653,    10] train_loss: 0.0320 | val_loss: 0.3836\n",
      "[654,    10] train_loss: 0.0112 | val_loss: 0.3924\n",
      "[655,    10] train_loss: 0.0000 | val_loss: 0.3668\n",
      "[656,    10] train_loss: 0.0472 | val_loss: 0.3881\n",
      "[657,    10] train_loss: 0.0245 | val_loss: 0.3740\n",
      "[658,    10] train_loss: 0.0000 | val_loss: 0.3799\n",
      "[659,    10] train_loss: 0.0370 | val_loss: 0.3732\n",
      "[660,    10] train_loss: 0.0624 | val_loss: 0.4149\n",
      "[661,    10] train_loss: 0.0918 | val_loss: 0.3774\n",
      "[662,    10] train_loss: 0.0700 | val_loss: 0.3733\n",
      "[663,    10] train_loss: 0.0533 | val_loss: 0.4142\n",
      "[664,    10] train_loss: 0.0722 | val_loss: 0.3676\n",
      "[665,    10] train_loss: 0.0620 | val_loss: 0.3731\n",
      "[666,    10] train_loss: 0.0618 | val_loss: 0.3403\n",
      "[667,    10] train_loss: 0.0607 | val_loss: 0.3468\n",
      "[668,    10] train_loss: 0.0317 | val_loss: 0.3575\n",
      "[669,    10] train_loss: 0.0399 | val_loss: 0.3232\n",
      "[670,    10] train_loss: 0.0458 | val_loss: 0.3322\n",
      "[671,    10] train_loss: 0.0304 | val_loss: 0.3474\n",
      "[672,    10] train_loss: 0.0142 | val_loss: 0.3783\n",
      "[673,    10] train_loss: 0.0000 | val_loss: 0.4067\n",
      "[674,    10] train_loss: 0.0278 | val_loss: 0.3515\n",
      "[675,    10] train_loss: 0.0000 | val_loss: 0.3690\n",
      "[676,    10] train_loss: 0.0222 | val_loss: 0.3650\n",
      "[677,    10] train_loss: 0.0694 | val_loss: 0.3870\n",
      "[678,    10] train_loss: 0.0263 | val_loss: 0.3870\n",
      "[679,    10] train_loss: 0.0000 | val_loss: 0.3625\n",
      "[680,    10] train_loss: 0.0135 | val_loss: 0.3595\n",
      "[681,    10] train_loss: 0.0000 | val_loss: 0.3567\n",
      "[682,    10] train_loss: 0.0117 | val_loss: 0.3922\n",
      "[683,    10] train_loss: 0.0327 | val_loss: 0.3924\n",
      "[684,    10] train_loss: 0.0114 | val_loss: 0.4367\n",
      "[685,    10] train_loss: 0.0121 | val_loss: 0.4053\n",
      "[686,    10] train_loss: 0.0000 | val_loss: 0.4100\n",
      "[687,    10] train_loss: 0.0316 | val_loss: 0.4165\n",
      "[688,    10] train_loss: 0.0000 | val_loss: 0.3847\n",
      "[689,    10] train_loss: 0.0129 | val_loss: 0.3688\n",
      "[690,    10] train_loss: 0.0000 | val_loss: 0.4061\n",
      "[691,    10] train_loss: 0.0105 | val_loss: 0.4024\n",
      "[692,    10] train_loss: 0.0000 | val_loss: 0.3994\n",
      "[693,    10] train_loss: 0.0000 | val_loss: 0.4128\n",
      "[694,    10] train_loss: 0.0311 | val_loss: 0.4008\n",
      "[695,    10] train_loss: 0.0393 | val_loss: 0.4045\n",
      "[696,    10] train_loss: 0.0330 | val_loss: 0.4026\n",
      "[697,    10] train_loss: 0.0321 | val_loss: 0.3927\n",
      "[698,    10] train_loss: 0.0000 | val_loss: 0.3846\n",
      "[699,    10] train_loss: 0.0000 | val_loss: 0.3704\n",
      "[700,    10] train_loss: 0.0145 | val_loss: 0.3551\n",
      "[701,    10] train_loss: 0.0365 | val_loss: 0.3551\n",
      "Saving checkpoint 700\n",
      "[702,    10] train_loss: 0.0539 | val_loss: 0.3952\n",
      "[703,    10] train_loss: 0.1224 | val_loss: 0.4024\n",
      "[704,    10] train_loss: 0.0506 | val_loss: 0.3255\n",
      "[705,    10] train_loss: 0.0214 | val_loss: 0.4003\n",
      "[706,    10] train_loss: 0.0226 | val_loss: 0.4038\n",
      "[707,    10] train_loss: 0.0313 | val_loss: 0.3638\n",
      "[708,    10] train_loss: 0.0372 | val_loss: 0.3758\n",
      "[709,    10] train_loss: 0.0253 | val_loss: 0.3745\n",
      "[710,    10] train_loss: 0.0496 | val_loss: 0.3997\n",
      "[711,    10] train_loss: 0.0473 | val_loss: 0.4132\n",
      "[712,    10] train_loss: 0.0867 | val_loss: 0.4361\n",
      "[713,    10] train_loss: 0.0376 | val_loss: 0.3685\n",
      "[714,    10] train_loss: 0.0272 | val_loss: 0.3712\n",
      "[715,    10] train_loss: 0.0352 | val_loss: 0.3852\n",
      "[716,    10] train_loss: 0.0101 | val_loss: 0.4080\n",
      "[717,    10] train_loss: 0.0106 | val_loss: 0.4007\n",
      "[718,    10] train_loss: 0.0000 | val_loss: 0.3823\n",
      "[719,    10] train_loss: 0.0000 | val_loss: 0.3833\n",
      "[720,    10] train_loss: 0.0000 | val_loss: 0.4113\n",
      "[721,    10] train_loss: 0.0256 | val_loss: 0.4009\n",
      "[722,    10] train_loss: 0.0000 | val_loss: 0.3866\n",
      "[723,    10] train_loss: 0.0000 | val_loss: 0.3886\n",
      "[724,    10] train_loss: 0.0000 | val_loss: 0.3944\n",
      "[725,    10] train_loss: 0.0100 | val_loss: 0.3851\n",
      "[726,    10] train_loss: 0.0000 | val_loss: 0.4282\n",
      "[727,    10] train_loss: 0.0108 | val_loss: 0.3864\n",
      "[728,    10] train_loss: 0.0000 | val_loss: 0.4022\n",
      "[729,    10] train_loss: 0.0125 | val_loss: 0.3996\n",
      "[730,    10] train_loss: 0.0102 | val_loss: 0.4265\n",
      "[731,    10] train_loss: 0.0000 | val_loss: 0.4207\n",
      "[732,    10] train_loss: 0.0000 | val_loss: 0.4220\n",
      "[733,    10] train_loss: 0.0000 | val_loss: 0.3990\n",
      "[734,    10] train_loss: 0.0000 | val_loss: 0.4214\n",
      "[735,    10] train_loss: 0.0000 | val_loss: 0.4202\n",
      "[736,    10] train_loss: 0.0110 | val_loss: 0.4233\n",
      "[737,    10] train_loss: 0.0103 | val_loss: 0.4047\n",
      "[738,    10] train_loss: 0.0210 | val_loss: 0.4025\n",
      "[739,    10] train_loss: 0.0108 | val_loss: 0.4261\n",
      "[740,    10] train_loss: 0.0562 | val_loss: 0.4170\n",
      "[741,    10] train_loss: 0.0154 | val_loss: 0.4270\n",
      "[742,    10] train_loss: 0.0231 | val_loss: 0.4210\n",
      "[743,    10] train_loss: 0.0806 | val_loss: 0.4411\n",
      "[744,    10] train_loss: 0.0202 | val_loss: 0.4423\n",
      "[745,    10] train_loss: 0.0290 | val_loss: 0.4047\n",
      "[746,    10] train_loss: 0.0507 | val_loss: 0.3921\n",
      "[747,    10] train_loss: 0.0272 | val_loss: 0.3841\n",
      "[748,    10] train_loss: 0.0105 | val_loss: 0.4299\n",
      "[749,    10] train_loss: 0.0110 | val_loss: 0.3907\n",
      "[750,    10] train_loss: 0.0182 | val_loss: 0.3254\n",
      "[751,    10] train_loss: 0.0463 | val_loss: 0.3962\n",
      "Saving checkpoint 750\n",
      "[752,    10] train_loss: 0.0000 | val_loss: 0.4629\n",
      "[753,    10] train_loss: 0.0000 | val_loss: 0.3833\n",
      "[754,    10] train_loss: 0.0098 | val_loss: 0.3762\n",
      "[755,    10] train_loss: 0.0217 | val_loss: 0.3516\n",
      "[756,    10] train_loss: 0.0104 | val_loss: 0.3583\n",
      "[757,    10] train_loss: 0.0000 | val_loss: 0.3769\n",
      "[758,    10] train_loss: 0.0121 | val_loss: 0.3573\n",
      "[759,    10] train_loss: 0.0308 | val_loss: 0.3919\n",
      "[760,    10] train_loss: 0.0232 | val_loss: 0.3839\n",
      "[761,    10] train_loss: 0.0115 | val_loss: 0.3758\n",
      "[762,    10] train_loss: 0.0000 | val_loss: 0.3469\n",
      "[763,    10] train_loss: 0.0100 | val_loss: 0.3714\n",
      "[764,    10] train_loss: 0.0359 | val_loss: 0.4012\n",
      "[765,    10] train_loss: 0.0000 | val_loss: 0.3795\n",
      "[766,    10] train_loss: 0.0116 | val_loss: 0.3688\n",
      "[767,    10] train_loss: 0.0000 | val_loss: 0.3983\n",
      "[768,    10] train_loss: 0.0253 | val_loss: 0.3881\n",
      "[769,    10] train_loss: 0.0240 | val_loss: 0.4050\n",
      "[770,    10] train_loss: 0.0000 | val_loss: 0.3792\n",
      "[771,    10] train_loss: 0.0120 | val_loss: 0.3704\n",
      "[772,    10] train_loss: 0.0000 | val_loss: 0.3274\n",
      "[773,    10] train_loss: 0.0103 | val_loss: 0.3601\n",
      "[774,    10] train_loss: 0.0000 | val_loss: 0.3423\n",
      "[775,    10] train_loss: 0.0192 | val_loss: 0.3867\n",
      "[776,    10] train_loss: 0.0000 | val_loss: 0.4020\n",
      "[777,    10] train_loss: 0.0000 | val_loss: 0.3932\n",
      "[778,    10] train_loss: 0.0214 | val_loss: 0.3893\n",
      "[779,    10] train_loss: 0.0000 | val_loss: 0.3854\n",
      "[780,    10] train_loss: 0.0000 | val_loss: 0.3649\n",
      "[781,    10] train_loss: 0.0280 | val_loss: 0.3936\n",
      "[782,    10] train_loss: 0.0353 | val_loss: 0.3955\n",
      "[783,    10] train_loss: 0.0166 | val_loss: 0.4232\n",
      "[784,    10] train_loss: 0.0429 | val_loss: 0.3187\n",
      "[785,    10] train_loss: 0.0203 | val_loss: 0.3177\n",
      "[786,    10] train_loss: 0.0122 | val_loss: 0.3394\n",
      "[787,    10] train_loss: 0.0400 | val_loss: 0.3619\n",
      "[788,    10] train_loss: 0.0213 | val_loss: 0.3506\n",
      "[789,    10] train_loss: 0.0212 | val_loss: 0.3733\n",
      "[790,    10] train_loss: 0.0087 | val_loss: 0.3957\n",
      "[791,    10] train_loss: 0.0223 | val_loss: 0.4033\n",
      "[792,    10] train_loss: 0.0274 | val_loss: 0.3608\n",
      "[793,    10] train_loss: 0.0621 | val_loss: 0.3671\n",
      "[794,    10] train_loss: 0.0000 | val_loss: 0.3709\n",
      "[795,    10] train_loss: 0.0000 | val_loss: 0.3655\n",
      "[796,    10] train_loss: 0.0215 | val_loss: 0.3665\n",
      "[797,    10] train_loss: 0.0240 | val_loss: 0.3920\n",
      "[798,    10] train_loss: 0.0000 | val_loss: 0.3509\n",
      "[799,    10] train_loss: 0.0226 | val_loss: 0.3625\n",
      "[800,    10] train_loss: 0.0131 | val_loss: 0.3585\n",
      "[801,    10] train_loss: 0.0126 | val_loss: 0.3437\n",
      "Saving checkpoint 800\n",
      "[802,    10] train_loss: 0.0108 | val_loss: 0.3501\n",
      "[803,    10] train_loss: 0.0110 | val_loss: 0.3612\n",
      "[804,    10] train_loss: 0.0000 | val_loss: 0.3710\n",
      "[805,    10] train_loss: 0.0000 | val_loss: 0.3605\n",
      "[806,    10] train_loss: 0.0000 | val_loss: 0.3655\n",
      "[807,    10] train_loss: 0.0353 | val_loss: 0.3616\n",
      "[808,    10] train_loss: 0.0000 | val_loss: 0.3645\n",
      "[809,    10] train_loss: 0.0113 | val_loss: 0.4113\n",
      "[810,    10] train_loss: 0.0225 | val_loss: 0.4569\n",
      "[811,    10] train_loss: 0.0529 | val_loss: 0.4729\n",
      "[812,    10] train_loss: 0.0414 | val_loss: 0.3977\n",
      "[813,    10] train_loss: 0.0250 | val_loss: 0.3690\n",
      "[814,    10] train_loss: 0.0651 | val_loss: 0.3703\n",
      "[815,    10] train_loss: 0.0695 | val_loss: 0.3980\n",
      "[816,    10] train_loss: 0.0230 | val_loss: 0.4065\n",
      "[817,    10] train_loss: 0.0000 | val_loss: 0.3784\n",
      "[818,    10] train_loss: 0.0000 | val_loss: 0.3676\n",
      "[819,    10] train_loss: 0.0000 | val_loss: 0.3989\n",
      "[820,    10] train_loss: 0.0317 | val_loss: 0.3518\n",
      "[821,    10] train_loss: 0.0000 | val_loss: 0.3411\n",
      "[822,    10] train_loss: 0.0248 | val_loss: 0.3674\n",
      "[823,    10] train_loss: 0.0000 | val_loss: 0.3671\n",
      "[824,    10] train_loss: 0.0260 | val_loss: 0.3659\n",
      "[825,    10] train_loss: 0.0226 | val_loss: 0.3649\n",
      "[826,    10] train_loss: 0.0215 | val_loss: 0.3506\n",
      "[827,    10] train_loss: 0.0139 | val_loss: 0.3692\n",
      "[828,    10] train_loss: 0.0000 | val_loss: 0.3599\n",
      "[829,    10] train_loss: 0.0144 | val_loss: 0.3838\n",
      "[830,    10] train_loss: 0.0000 | val_loss: 0.3544\n",
      "[831,    10] train_loss: 0.0124 | val_loss: 0.3634\n",
      "[832,    10] train_loss: 0.0000 | val_loss: 0.3703\n",
      "[833,    10] train_loss: 0.0000 | val_loss: 0.3830\n",
      "[834,    10] train_loss: 0.0217 | val_loss: 0.3779\n",
      "[835,    10] train_loss: 0.0000 | val_loss: 0.3700\n",
      "[836,    10] train_loss: 0.0247 | val_loss: 0.3989\n",
      "[837,    10] train_loss: 0.0000 | val_loss: 0.3972\n",
      "[838,    10] train_loss: 0.0000 | val_loss: 0.3720\n",
      "[839,    10] train_loss: 0.0000 | val_loss: 0.4009\n",
      "[840,    10] train_loss: 0.0000 | val_loss: 0.3822\n",
      "[841,    10] train_loss: 0.0000 | val_loss: 0.3769\n",
      "[842,    10] train_loss: 0.0000 | val_loss: 0.3654\n",
      "[843,    10] train_loss: 0.0000 | val_loss: 0.3820\n",
      "[844,    10] train_loss: 0.0000 | val_loss: 0.3872\n",
      "[845,    10] train_loss: 0.0000 | val_loss: 0.4203\n",
      "[846,    10] train_loss: 0.0117 | val_loss: 0.4199\n",
      "[847,    10] train_loss: 0.0000 | val_loss: 0.4373\n",
      "[848,    10] train_loss: 0.0000 | val_loss: 0.4067\n",
      "[849,    10] train_loss: 0.0222 | val_loss: 0.4197\n",
      "[850,    10] train_loss: 0.0657 | val_loss: 0.3656\n",
      "[851,    10] train_loss: 0.0114 | val_loss: 0.3635\n",
      "Saving checkpoint 850\n",
      "[852,    10] train_loss: 0.0103 | val_loss: 0.3371\n",
      "[853,    10] train_loss: 0.0238 | val_loss: 0.3563\n",
      "[854,    10] train_loss: 0.0229 | val_loss: 0.3622\n",
      "[855,    10] train_loss: 0.0152 | val_loss: 0.3600\n",
      "[856,    10] train_loss: 0.0000 | val_loss: 0.4053\n",
      "[857,    10] train_loss: 0.0112 | val_loss: 0.3608\n",
      "[858,    10] train_loss: 0.0269 | val_loss: 0.3768\n",
      "[859,    10] train_loss: 0.0108 | val_loss: 0.3858\n",
      "[860,    10] train_loss: 0.0105 | val_loss: 0.4017\n",
      "[861,    10] train_loss: 0.0000 | val_loss: 0.4035\n",
      "[862,    10] train_loss: 0.0127 | val_loss: 0.4061\n",
      "[863,    10] train_loss: 0.0114 | val_loss: 0.4333\n",
      "[864,    10] train_loss: 0.0245 | val_loss: 0.4434\n",
      "[865,    10] train_loss: 0.0093 | val_loss: 0.4364\n",
      "[866,    10] train_loss: 0.0406 | val_loss: 0.4312\n",
      "[867,    10] train_loss: 0.0000 | val_loss: 0.4372\n",
      "[868,    10] train_loss: 0.0148 | val_loss: 0.4645\n",
      "[869,    10] train_loss: 0.0000 | val_loss: 0.4520\n",
      "[870,    10] train_loss: 0.0139 | val_loss: 0.4581\n",
      "[871,    10] train_loss: 0.0000 | val_loss: 0.4716\n",
      "[872,    10] train_loss: 0.0000 | val_loss: 0.4296\n",
      "[873,    10] train_loss: 0.0130 | val_loss: 0.4401\n",
      "[874,    10] train_loss: 0.0000 | val_loss: 0.4181\n",
      "[875,    10] train_loss: 0.0000 | val_loss: 0.3934\n",
      "[876,    10] train_loss: 0.0000 | val_loss: 0.3692\n",
      "[877,    10] train_loss: 0.0000 | val_loss: 0.3674\n",
      "[878,    10] train_loss: 0.0133 | val_loss: 0.3838\n",
      "[879,    10] train_loss: 0.0000 | val_loss: 0.3769\n",
      "[880,    10] train_loss: 0.0126 | val_loss: 0.3830\n",
      "[881,    10] train_loss: 0.0224 | val_loss: 0.4047\n",
      "[882,    10] train_loss: 0.0000 | val_loss: 0.4047\n",
      "[883,    10] train_loss: 0.0000 | val_loss: 0.4120\n",
      "[884,    10] train_loss: 0.0267 | val_loss: 0.3822\n",
      "[885,    10] train_loss: 0.0000 | val_loss: 0.3887\n",
      "[886,    10] train_loss: 0.0000 | val_loss: 0.4197\n",
      "[887,    10] train_loss: 0.0000 | val_loss: 0.4175\n",
      "[888,    10] train_loss: 0.0000 | val_loss: 0.4053\n",
      "[889,    10] train_loss: 0.0000 | val_loss: 0.3804\n",
      "[890,    10] train_loss: 0.0000 | val_loss: 0.3699\n",
      "[891,    10] train_loss: 0.0124 | val_loss: 0.4019\n",
      "[892,    10] train_loss: 0.0316 | val_loss: 0.4010\n",
      "[893,    10] train_loss: 0.0586 | val_loss: 0.3943\n",
      "[894,    10] train_loss: 0.0258 | val_loss: 0.3888\n",
      "[895,    10] train_loss: 0.0323 | val_loss: 0.4169\n",
      "[896,    10] train_loss: 0.0129 | val_loss: 0.3905\n",
      "[897,    10] train_loss: 0.0140 | val_loss: 0.3992\n",
      "[898,    10] train_loss: 0.0000 | val_loss: 0.3931\n",
      "[899,    10] train_loss: 0.0000 | val_loss: 0.4039\n",
      "[900,    10] train_loss: 0.0000 | val_loss: 0.4244\n",
      "[901,    10] train_loss: 0.0000 | val_loss: 0.3919\n",
      "Saving checkpoint 900\n",
      "[902,    10] train_loss: 0.0348 | val_loss: 0.4122\n",
      "[903,    10] train_loss: 0.0960 | val_loss: 0.4827\n",
      "[904,    10] train_loss: 0.0529 | val_loss: 0.3840\n",
      "[905,    10] train_loss: 0.0338 | val_loss: 0.3559\n",
      "[906,    10] train_loss: 0.0623 | val_loss: 0.3705\n",
      "[907,    10] train_loss: 0.0646 | val_loss: 0.3702\n",
      "[908,    10] train_loss: 0.0703 | val_loss: 0.3473\n",
      "[909,    10] train_loss: 0.0000 | val_loss: 0.3500\n",
      "[910,    10] train_loss: 0.0000 | val_loss: 0.3621\n",
      "[911,    10] train_loss: 0.0329 | val_loss: 0.3400\n",
      "[912,    10] train_loss: 0.0100 | val_loss: 0.3273\n",
      "[913,    10] train_loss: 0.0114 | val_loss: 0.3449\n",
      "[914,    10] train_loss: 0.0272 | val_loss: 0.3373\n",
      "[915,    10] train_loss: 0.0151 | val_loss: 0.3450\n",
      "[916,    10] train_loss: 0.0230 | val_loss: 0.3555\n",
      "[917,    10] train_loss: 0.0291 | val_loss: 0.3353\n",
      "[918,    10] train_loss: 0.0487 | val_loss: 0.3591\n",
      "[919,    10] train_loss: 0.0146 | val_loss: 0.3480\n",
      "[920,    10] train_loss: 0.0412 | val_loss: 0.3831\n",
      "[921,    10] train_loss: 0.0133 | val_loss: 0.4045\n",
      "[922,    10] train_loss: 0.0252 | val_loss: 0.4029\n",
      "[923,    10] train_loss: 0.0109 | val_loss: 0.3515\n",
      "[924,    10] train_loss: 0.0000 | val_loss: 0.3671\n",
      "[925,    10] train_loss: 0.0126 | val_loss: 0.3714\n",
      "[926,    10] train_loss: 0.0110 | val_loss: 0.3485\n",
      "[927,    10] train_loss: 0.0108 | val_loss: 0.3607\n",
      "[928,    10] train_loss: 0.0117 | val_loss: 0.3735\n",
      "[929,    10] train_loss: 0.0118 | val_loss: 0.3672\n",
      "[930,    10] train_loss: 0.0000 | val_loss: 0.3825\n",
      "[931,    10] train_loss: 0.0000 | val_loss: 0.3745\n",
      "[932,    10] train_loss: 0.0000 | val_loss: 0.3766\n",
      "[933,    10] train_loss: 0.0136 | val_loss: 0.3557\n",
      "[934,    10] train_loss: 0.0114 | val_loss: 0.3619\n",
      "[935,    10] train_loss: 0.0198 | val_loss: 0.3617\n",
      "[936,    10] train_loss: 0.0603 | val_loss: 0.3725\n",
      "[937,    10] train_loss: 0.0492 | val_loss: 0.3692\n",
      "[938,    10] train_loss: 0.0112 | val_loss: 0.3952\n",
      "[939,    10] train_loss: 0.0129 | val_loss: 0.3836\n",
      "[940,    10] train_loss: 0.0117 | val_loss: 0.3773\n",
      "[941,    10] train_loss: 0.0234 | val_loss: 0.3788\n",
      "[942,    10] train_loss: 0.0101 | val_loss: 0.4015\n",
      "[943,    10] train_loss: 0.0373 | val_loss: 0.3778\n",
      "[944,    10] train_loss: 0.0134 | val_loss: 0.3798\n",
      "[945,    10] train_loss: 0.0571 | val_loss: 0.3506\n",
      "[946,    10] train_loss: 0.0507 | val_loss: 0.3345\n",
      "[947,    10] train_loss: 0.0215 | val_loss: 0.3765\n",
      "[948,    10] train_loss: 0.0111 | val_loss: 0.3775\n",
      "[949,    10] train_loss: 0.0000 | val_loss: 0.3698\n",
      "[950,    10] train_loss: 0.0000 | val_loss: 0.4259\n",
      "[951,    10] train_loss: 0.0000 | val_loss: 0.3941\n",
      "Saving checkpoint 950\n",
      "[952,    10] train_loss: 0.0000 | val_loss: 0.3702\n",
      "[953,    10] train_loss: 0.0136 | val_loss: 0.3779\n",
      "[954,    10] train_loss: 0.0116 | val_loss: 0.3619\n",
      "[955,    10] train_loss: 0.0131 | val_loss: 0.3799\n",
      "[956,    10] train_loss: 0.0150 | val_loss: 0.4309\n",
      "[957,    10] train_loss: 0.0484 | val_loss: 0.4431\n",
      "[958,    10] train_loss: 0.0225 | val_loss: 0.4126\n",
      "[959,    10] train_loss: 0.0175 | val_loss: 0.4122\n",
      "[960,    10] train_loss: 0.0105 | val_loss: 0.3932\n",
      "[961,    10] train_loss: 0.0388 | val_loss: 0.3924\n",
      "[962,    10] train_loss: 0.0939 | val_loss: 0.3897\n",
      "[963,    10] train_loss: 0.0234 | val_loss: 0.4008\n",
      "[964,    10] train_loss: 0.0105 | val_loss: 0.3750\n",
      "[965,    10] train_loss: 0.0106 | val_loss: 0.3568\n",
      "[966,    10] train_loss: 0.0000 | val_loss: 0.3574\n",
      "[967,    10] train_loss: 0.0000 | val_loss: 0.3619\n",
      "[968,    10] train_loss: 0.0344 | val_loss: 0.3778\n",
      "[969,    10] train_loss: 0.0226 | val_loss: 0.3621\n",
      "[970,    10] train_loss: 0.0000 | val_loss: 0.4071\n",
      "[971,    10] train_loss: 0.0260 | val_loss: 0.3302\n",
      "[972,    10] train_loss: 0.0000 | val_loss: 0.3465\n",
      "[973,    10] train_loss: 0.0000 | val_loss: 0.3363\n",
      "[974,    10] train_loss: 0.0120 | val_loss: 0.3522\n",
      "[975,    10] train_loss: 0.0000 | val_loss: 0.3663\n",
      "[976,    10] train_loss: 0.0000 | val_loss: 0.3415\n",
      "[977,    10] train_loss: 0.0000 | val_loss: 0.3355\n",
      "[978,    10] train_loss: 0.0000 | val_loss: 0.3411\n",
      "[979,    10] train_loss: 0.0000 | val_loss: 0.3430\n",
      "[980,    10] train_loss: 0.0000 | val_loss: 0.3294\n",
      "[981,    10] train_loss: 0.0000 | val_loss: 0.3262\n",
      "[982,    10] train_loss: 0.0316 | val_loss: 0.3278\n",
      "[983,    10] train_loss: 0.0000 | val_loss: 0.3455\n",
      "[984,    10] train_loss: 0.0122 | val_loss: 0.3555\n",
      "[985,    10] train_loss: 0.0215 | val_loss: 0.3648\n",
      "[986,    10] train_loss: 0.0117 | val_loss: 0.3691\n",
      "[987,    10] train_loss: 0.0232 | val_loss: 0.3913\n",
      "[988,    10] train_loss: 0.0000 | val_loss: 0.3846\n",
      "[989,    10] train_loss: 0.0259 | val_loss: 0.3366\n",
      "[990,    10] train_loss: 0.0245 | val_loss: 0.3878\n",
      "[991,    10] train_loss: 0.0102 | val_loss: 0.3496\n",
      "[992,    10] train_loss: 0.0327 | val_loss: 0.3728\n",
      "[993,    10] train_loss: 0.0000 | val_loss: 0.3700\n",
      "[994,    10] train_loss: 0.0127 | val_loss: 0.3708\n",
      "[995,    10] train_loss: 0.0114 | val_loss: 0.3469\n",
      "[996,    10] train_loss: 0.0231 | val_loss: 0.3390\n",
      "[997,    10] train_loss: 0.0246 | val_loss: 0.3586\n",
      "[998,    10] train_loss: 0.0000 | val_loss: 0.3867\n",
      "[999,    10] train_loss: 0.0104 | val_loss: 0.3628\n",
      "[1000,    10] train_loss: 0.0115 | val_loss: 0.3614\n",
      "[1001,    10] train_loss: 0.0000 | val_loss: 0.3618\n",
      "Saving checkpoint 1000\n",
      "[1002,    10] train_loss: 0.0110 | val_loss: 0.3479\n",
      "[1003,    10] train_loss: 0.0106 | val_loss: 0.3657\n",
      "[1004,    10] train_loss: 0.0145 | val_loss: 0.4227\n",
      "[1005,    10] train_loss: 0.0000 | val_loss: 0.4460\n",
      "[1006,    10] train_loss: 0.0000 | val_loss: 0.4045\n",
      "[1007,    10] train_loss: 0.0085 | val_loss: 0.4116\n",
      "[1008,    10] train_loss: 0.0000 | val_loss: 0.3826\n",
      "[1009,    10] train_loss: 0.0242 | val_loss: 0.3817\n",
      "[1010,    10] train_loss: 0.0105 | val_loss: 0.4072\n",
      "[1011,    10] train_loss: 0.0000 | val_loss: 0.3960\n",
      "[1012,    10] train_loss: 0.0177 | val_loss: 0.3721\n",
      "[1013,    10] train_loss: 0.0324 | val_loss: 0.3991\n",
      "[1014,    10] train_loss: 0.0624 | val_loss: 0.3705\n",
      "[1015,    10] train_loss: 0.0667 | val_loss: 0.3618\n",
      "[1016,    10] train_loss: 0.0257 | val_loss: 0.4012\n",
      "[1017,    10] train_loss: 0.0000 | val_loss: 0.4266\n",
      "[1018,    10] train_loss: 0.0249 | val_loss: 0.3865\n",
      "[1019,    10] train_loss: 0.0000 | val_loss: 0.3680\n",
      "[1020,    10] train_loss: 0.0000 | val_loss: 0.3798\n",
      "[1021,    10] train_loss: 0.0126 | val_loss: 0.3989\n",
      "[1022,    10] train_loss: 0.0000 | val_loss: 0.3694\n",
      "[1023,    10] train_loss: 0.0108 | val_loss: 0.3795\n",
      "[1024,    10] train_loss: 0.0146 | val_loss: 0.3801\n",
      "[1025,    10] train_loss: 0.0000 | val_loss: 0.3609\n",
      "[1026,    10] train_loss: 0.0133 | val_loss: 0.3622\n",
      "[1027,    10] train_loss: 0.0000 | val_loss: 0.3680\n",
      "[1028,    10] train_loss: 0.0000 | val_loss: 0.3841\n",
      "[1029,    10] train_loss: 0.0000 | val_loss: 0.3712\n",
      "[1030,    10] train_loss: 0.0000 | val_loss: 0.3796\n",
      "[1031,    10] train_loss: 0.0000 | val_loss: 0.3576\n",
      "[1032,    10] train_loss: 0.0000 | val_loss: 0.3819\n",
      "[1033,    10] train_loss: 0.0112 | val_loss: 0.3819\n",
      "[1034,    10] train_loss: 0.0000 | val_loss: 0.4016\n",
      "[1035,    10] train_loss: 0.0000 | val_loss: 0.4032\n",
      "[1036,    10] train_loss: 0.0000 | val_loss: 0.3787\n",
      "[1037,    10] train_loss: 0.0000 | val_loss: 0.3829\n",
      "[1038,    10] train_loss: 0.0115 | val_loss: 0.3769\n",
      "[1039,    10] train_loss: 0.0141 | val_loss: 0.3774\n",
      "[1040,    10] train_loss: 0.0000 | val_loss: 0.3707\n",
      "[1041,    10] train_loss: 0.0000 | val_loss: 0.3588\n",
      "[1042,    10] train_loss: 0.0131 | val_loss: 0.3643\n",
      "[1043,    10] train_loss: 0.0000 | val_loss: 0.3704\n",
      "[1044,    10] train_loss: 0.0000 | val_loss: 0.3629\n",
      "[1045,    10] train_loss: 0.0000 | val_loss: 0.3804\n",
      "[1046,    10] train_loss: 0.0248 | val_loss: 0.4030\n",
      "[1047,    10] train_loss: 0.0000 | val_loss: 0.3553\n",
      "[1048,    10] train_loss: 0.0126 | val_loss: 0.3714\n",
      "[1049,    10] train_loss: 0.0000 | val_loss: 0.3773\n",
      "[1050,    10] train_loss: 0.0101 | val_loss: 0.3927\n",
      "[1051,    10] train_loss: 0.0185 | val_loss: 0.3681\n",
      "Saving checkpoint 1050\n",
      "[1052,    10] train_loss: 0.0000 | val_loss: 0.3864\n",
      "[1053,    10] train_loss: 0.0000 | val_loss: 0.3685\n",
      "[1054,    10] train_loss: 0.0000 | val_loss: 0.3804\n",
      "[1055,    10] train_loss: 0.0000 | val_loss: 0.3908\n",
      "[1056,    10] train_loss: 0.0000 | val_loss: 0.3764\n",
      "[1057,    10] train_loss: 0.0000 | val_loss: 0.3992\n",
      "[1058,    10] train_loss: 0.0000 | val_loss: 0.3879\n",
      "[1059,    10] train_loss: 0.0138 | val_loss: 0.3872\n",
      "[1060,    10] train_loss: 0.0000 | val_loss: 0.3770\n",
      "[1061,    10] train_loss: 0.0000 | val_loss: 0.3804\n",
      "[1062,    10] train_loss: 0.0000 | val_loss: 0.3745\n",
      "[1063,    10] train_loss: 0.0000 | val_loss: 0.3625\n",
      "[1064,    10] train_loss: 0.0000 | val_loss: 0.3782\n",
      "[1065,    10] train_loss: 0.0000 | val_loss: 0.3625\n",
      "[1066,    10] train_loss: 0.0000 | val_loss: 0.3556\n",
      "[1067,    10] train_loss: 0.0000 | val_loss: 0.3741\n",
      "[1068,    10] train_loss: 0.0000 | val_loss: 0.3849\n",
      "[1069,    10] train_loss: 0.0000 | val_loss: 0.3827\n",
      "[1070,    10] train_loss: 0.0000 | val_loss: 0.3635\n",
      "[1071,    10] train_loss: 0.0121 | val_loss: 0.3779\n",
      "[1072,    10] train_loss: 0.0000 | val_loss: 0.3749\n",
      "[1073,    10] train_loss: 0.0000 | val_loss: 0.3552\n",
      "[1074,    10] train_loss: 0.0102 | val_loss: 0.3487\n",
      "[1075,    10] train_loss: 0.0104 | val_loss: 0.3803\n",
      "[1076,    10] train_loss: 0.0116 | val_loss: 0.3862\n",
      "[1077,    10] train_loss: 0.0000 | val_loss: 0.3776\n",
      "[1078,    10] train_loss: 0.0104 | val_loss: 0.3880\n",
      "[1079,    10] train_loss: 0.0174 | val_loss: 0.4419\n",
      "[1080,    10] train_loss: 0.0000 | val_loss: 0.3840\n",
      "[1081,    10] train_loss: 0.0283 | val_loss: 0.3560\n",
      "[1082,    10] train_loss: 0.0121 | val_loss: 0.3769\n",
      "[1083,    10] train_loss: 0.0107 | val_loss: 0.3967\n",
      "[1084,    10] train_loss: 0.0000 | val_loss: 0.4088\n",
      "[1085,    10] train_loss: 0.0112 | val_loss: 0.4031\n",
      "[1086,    10] train_loss: 0.0000 | val_loss: 0.3939\n",
      "[1087,    10] train_loss: 0.0310 | val_loss: 0.3783\n",
      "[1088,    10] train_loss: 0.0338 | val_loss: 0.3790\n",
      "[1089,    10] train_loss: 0.0260 | val_loss: 0.3721\n",
      "[1090,    10] train_loss: 0.0542 | val_loss: 0.4156\n",
      "[1091,    10] train_loss: 0.0130 | val_loss: 0.3722\n",
      "[1092,    10] train_loss: 0.0128 | val_loss: 0.3747\n",
      "[1093,    10] train_loss: 0.0000 | val_loss: 0.3507\n",
      "[1094,    10] train_loss: 0.0221 | val_loss: 0.3383\n",
      "[1095,    10] train_loss: 0.0612 | val_loss: 0.3356\n",
      "[1096,    10] train_loss: 0.0250 | val_loss: 0.3525\n",
      "[1097,    10] train_loss: 0.0000 | val_loss: 0.4428\n",
      "[1098,    10] train_loss: 0.0378 | val_loss: 0.3884\n",
      "[1099,    10] train_loss: 0.0132 | val_loss: 0.3617\n",
      "[1100,    10] train_loss: 0.0265 | val_loss: 0.3554\n",
      "[1101,    10] train_loss: 0.0529 | val_loss: 0.3883\n",
      "Saving checkpoint 1100\n",
      "[1102,    10] train_loss: 0.0698 | val_loss: 0.3859\n",
      "[1103,    10] train_loss: 0.0567 | val_loss: 0.3487\n",
      "[1104,    10] train_loss: 0.0429 | val_loss: 0.4073\n",
      "[1105,    10] train_loss: 0.0000 | val_loss: 0.3793\n",
      "[1106,    10] train_loss: 0.0000 | val_loss: 0.4030\n",
      "[1107,    10] train_loss: 0.0139 | val_loss: 0.3698\n",
      "[1108,    10] train_loss: 0.0127 | val_loss: 0.3806\n",
      "[1109,    10] train_loss: 0.0143 | val_loss: 0.4438\n",
      "[1110,    10] train_loss: 0.0000 | val_loss: 0.3967\n",
      "[1111,    10] train_loss: 0.0000 | val_loss: 0.3887\n",
      "[1112,    10] train_loss: 0.0120 | val_loss: 0.3883\n",
      "[1113,    10] train_loss: 0.0000 | val_loss: 0.3900\n",
      "[1114,    10] train_loss: 0.0000 | val_loss: 0.3830\n",
      "[1115,    10] train_loss: 0.0000 | val_loss: 0.4098\n",
      "[1116,    10] train_loss: 0.0112 | val_loss: 0.3990\n",
      "[1117,    10] train_loss: 0.0000 | val_loss: 0.3855\n",
      "[1118,    10] train_loss: 0.0000 | val_loss: 0.3842\n",
      "[1119,    10] train_loss: 0.0000 | val_loss: 0.3896\n",
      "[1120,    10] train_loss: 0.0000 | val_loss: 0.3761\n",
      "[1121,    10] train_loss: 0.0120 | val_loss: 0.3663\n",
      "[1122,    10] train_loss: 0.0000 | val_loss: 0.3873\n",
      "[1123,    10] train_loss: 0.0000 | val_loss: 0.3711\n",
      "[1124,    10] train_loss: 0.0000 | val_loss: 0.3725\n",
      "[1125,    10] train_loss: 0.0000 | val_loss: 0.3591\n",
      "[1126,    10] train_loss: 0.0000 | val_loss: 0.3597\n",
      "[1127,    10] train_loss: 0.0000 | val_loss: 0.3628\n",
      "[1128,    10] train_loss: 0.0000 | val_loss: 0.3591\n",
      "[1129,    10] train_loss: 0.0000 | val_loss: 0.3833\n",
      "[1130,    10] train_loss: 0.0000 | val_loss: 0.3711\n",
      "[1131,    10] train_loss: 0.0000 | val_loss: 0.3537\n",
      "[1132,    10] train_loss: 0.0000 | val_loss: 0.3793\n",
      "[1133,    10] train_loss: 0.0122 | val_loss: 0.3590\n",
      "[1134,    10] train_loss: 0.0000 | val_loss: 0.4005\n",
      "[1135,    10] train_loss: 0.0000 | val_loss: 0.3998\n",
      "[1136,    10] train_loss: 0.0231 | val_loss: 0.4205\n",
      "[1137,    10] train_loss: 0.0297 | val_loss: 0.3939\n",
      "[1138,    10] train_loss: 0.0000 | val_loss: 0.3836\n",
      "[1139,    10] train_loss: 0.0122 | val_loss: 0.3895\n",
      "[1140,    10] train_loss: 0.0213 | val_loss: 0.3699\n",
      "[1141,    10] train_loss: 0.0293 | val_loss: 0.3983\n",
      "[1142,    10] train_loss: 0.0000 | val_loss: 0.4231\n",
      "[1143,    10] train_loss: 0.0392 | val_loss: 0.4446\n",
      "[1144,    10] train_loss: 0.0155 | val_loss: 0.4310\n",
      "[1145,    10] train_loss: 0.0238 | val_loss: 0.4825\n",
      "[1146,    10] train_loss: 0.0378 | val_loss: 0.4321\n",
      "[1147,    10] train_loss: 0.0379 | val_loss: 0.4475\n",
      "[1148,    10] train_loss: 0.0172 | val_loss: 0.4085\n",
      "[1149,    10] train_loss: 0.0131 | val_loss: 0.3982\n",
      "[1150,    10] train_loss: 0.0000 | val_loss: 0.3945\n",
      "[1151,    10] train_loss: 0.0000 | val_loss: 0.3942\n",
      "Saving checkpoint 1150\n",
      "[1152,    10] train_loss: 0.0000 | val_loss: 0.3967\n",
      "[1153,    10] train_loss: 0.0000 | val_loss: 0.3919\n",
      "[1154,    10] train_loss: 0.0352 | val_loss: 0.4034\n",
      "[1155,    10] train_loss: 0.0000 | val_loss: 0.3700\n",
      "[1156,    10] train_loss: 0.0000 | val_loss: 0.3805\n",
      "[1157,    10] train_loss: 0.0000 | val_loss: 0.3883\n",
      "[1158,    10] train_loss: 0.0109 | val_loss: 0.3493\n",
      "[1159,    10] train_loss: 0.0505 | val_loss: 0.3896\n",
      "[1160,    10] train_loss: 0.0000 | val_loss: 0.3941\n",
      "[1161,    10] train_loss: 0.0249 | val_loss: 0.3733\n",
      "[1162,    10] train_loss: 0.0000 | val_loss: 0.3546\n",
      "[1163,    10] train_loss: 0.0000 | val_loss: 0.3556\n",
      "[1164,    10] train_loss: 0.0000 | val_loss: 0.3629\n",
      "[1165,    10] train_loss: 0.0382 | val_loss: 0.3796\n",
      "[1166,    10] train_loss: 0.0771 | val_loss: 0.3956\n",
      "[1167,    10] train_loss: 0.0244 | val_loss: 0.3615\n",
      "[1168,    10] train_loss: 0.0127 | val_loss: 0.3713\n",
      "[1169,    10] train_loss: 0.0226 | val_loss: 0.3762\n",
      "[1170,    10] train_loss: 0.0000 | val_loss: 0.3964\n",
      "[1171,    10] train_loss: 0.0125 | val_loss: 0.3635\n",
      "[1172,    10] train_loss: 0.0000 | val_loss: 0.4020\n",
      "[1173,    10] train_loss: 0.0000 | val_loss: 0.3719\n",
      "[1174,    10] train_loss: 0.0000 | val_loss: 0.3882\n",
      "[1175,    10] train_loss: 0.0000 | val_loss: 0.3934\n",
      "[1176,    10] train_loss: 0.0541 | val_loss: 0.3724\n",
      "[1177,    10] train_loss: 0.0402 | val_loss: 0.3847\n",
      "[1178,    10] train_loss: 0.0179 | val_loss: 0.4134\n",
      "[1179,    10] train_loss: 0.0671 | val_loss: 0.3839\n",
      "[1180,    10] train_loss: 0.0136 | val_loss: 0.4003\n",
      "[1181,    10] train_loss: 0.0000 | val_loss: 0.3976\n",
      "[1182,    10] train_loss: 0.0230 | val_loss: 0.4057\n",
      "[1183,    10] train_loss: 0.0462 | val_loss: 0.4212\n",
      "[1184,    10] train_loss: 0.0240 | val_loss: 0.3909\n",
      "[1185,    10] train_loss: 0.0687 | val_loss: 0.4100\n",
      "[1186,    10] train_loss: 0.0120 | val_loss: 0.4773\n",
      "[1187,    10] train_loss: 0.0431 | val_loss: 0.4696\n",
      "[1188,    10] train_loss: 0.0273 | val_loss: 0.4107\n",
      "[1189,    10] train_loss: 0.0000 | val_loss: 0.4241\n",
      "[1190,    10] train_loss: 0.0103 | val_loss: 0.4166\n",
      "[1191,    10] train_loss: 0.0000 | val_loss: 0.3912\n",
      "[1192,    10] train_loss: 0.0000 | val_loss: 0.4239\n",
      "[1193,    10] train_loss: 0.0000 | val_loss: 0.4011\n",
      "[1194,    10] train_loss: 0.0000 | val_loss: 0.3991\n",
      "[1195,    10] train_loss: 0.0000 | val_loss: 0.4039\n",
      "[1196,    10] train_loss: 0.0124 | val_loss: 0.3933\n",
      "[1197,    10] train_loss: 0.0103 | val_loss: 0.3832\n",
      "[1198,    10] train_loss: 0.0118 | val_loss: 0.4205\n",
      "[1199,    10] train_loss: 0.0118 | val_loss: 0.4343\n",
      "[1200,    10] train_loss: 0.0000 | val_loss: 0.4351\n",
      "[1201,    10] train_loss: 0.0112 | val_loss: 0.4185\n",
      "Saving checkpoint 1200\n",
      "[1202,    10] train_loss: 0.0000 | val_loss: 0.4272\n",
      "[1203,    10] train_loss: 0.0000 | val_loss: 0.4380\n",
      "[1204,    10] train_loss: 0.0000 | val_loss: 0.4356\n",
      "[1205,    10] train_loss: 0.0000 | val_loss: 0.4433\n",
      "[1206,    10] train_loss: 0.0000 | val_loss: 0.4249\n",
      "[1207,    10] train_loss: 0.0125 | val_loss: 0.4205\n",
      "[1208,    10] train_loss: 0.0000 | val_loss: 0.4395\n",
      "[1209,    10] train_loss: 0.0000 | val_loss: 0.4334\n",
      "[1210,    10] train_loss: 0.0000 | val_loss: 0.4178\n",
      "[1211,    10] train_loss: 0.0000 | val_loss: 0.4319\n",
      "[1212,    10] train_loss: 0.0107 | val_loss: 0.4332\n",
      "[1213,    10] train_loss: 0.0000 | val_loss: 0.4462\n",
      "[1214,    10] train_loss: 0.0000 | val_loss: 0.4250\n",
      "[1215,    10] train_loss: 0.0356 | val_loss: 0.4391\n",
      "[1216,    10] train_loss: 0.0687 | val_loss: 0.4121\n",
      "[1217,    10] train_loss: 0.0130 | val_loss: 0.3804\n",
      "[1218,    10] train_loss: 0.0000 | val_loss: 0.3962\n",
      "[1219,    10] train_loss: 0.0149 | val_loss: 0.4205\n",
      "[1220,    10] train_loss: 0.0234 | val_loss: 0.4147\n",
      "[1221,    10] train_loss: 0.0000 | val_loss: 0.3886\n",
      "[1222,    10] train_loss: 0.0118 | val_loss: 0.3925\n",
      "[1223,    10] train_loss: 0.0000 | val_loss: 0.3862\n",
      "[1224,    10] train_loss: 0.0000 | val_loss: 0.3923\n",
      "[1225,    10] train_loss: 0.0000 | val_loss: 0.3987\n",
      "[1226,    10] train_loss: 0.0000 | val_loss: 0.4022\n",
      "[1227,    10] train_loss: 0.0000 | val_loss: 0.3955\n",
      "[1228,    10] train_loss: 0.0000 | val_loss: 0.3907\n",
      "[1229,    10] train_loss: 0.0000 | val_loss: 0.3853\n",
      "[1230,    10] train_loss: 0.0000 | val_loss: 0.4055\n",
      "[1231,    10] train_loss: 0.0000 | val_loss: 0.4090\n",
      "[1232,    10] train_loss: 0.0115 | val_loss: 0.3724\n",
      "[1233,    10] train_loss: 0.0000 | val_loss: 0.4036\n",
      "[1234,    10] train_loss: 0.0000 | val_loss: 0.3658\n",
      "[1235,    10] train_loss: 0.0123 | val_loss: 0.3695\n",
      "[1236,    10] train_loss: 0.0000 | val_loss: 0.3527\n",
      "[1237,    10] train_loss: 0.0000 | val_loss: 0.3622\n",
      "[1238,    10] train_loss: 0.0000 | val_loss: 0.3430\n",
      "[1239,    10] train_loss: 0.0000 | val_loss: 0.3635\n",
      "[1240,    10] train_loss: 0.0123 | val_loss: 0.3788\n",
      "[1241,    10] train_loss: 0.0000 | val_loss: 0.4018\n",
      "[1242,    10] train_loss: 0.0000 | val_loss: 0.3902\n",
      "[1243,    10] train_loss: 0.0000 | val_loss: 0.3684\n",
      "[1244,    10] train_loss: 0.0000 | val_loss: 0.3574\n",
      "[1245,    10] train_loss: 0.0000 | val_loss: 0.3658\n",
      "[1246,    10] train_loss: 0.0000 | val_loss: 0.3553\n",
      "[1247,    10] train_loss: 0.0000 | val_loss: 0.3684\n",
      "[1248,    10] train_loss: 0.0000 | val_loss: 0.3861\n",
      "[1249,    10] train_loss: 0.0000 | val_loss: 0.3599\n",
      "[1250,    10] train_loss: 0.0000 | val_loss: 0.3737\n",
      "[1251,    10] train_loss: 0.0000 | val_loss: 0.3873\n",
      "Saving checkpoint 1250\n",
      "[1252,    10] train_loss: 0.0000 | val_loss: 0.3671\n",
      "[1253,    10] train_loss: 0.0000 | val_loss: 0.3819\n",
      "[1254,    10] train_loss: 0.0000 | val_loss: 0.3768\n",
      "[1255,    10] train_loss: 0.0000 | val_loss: 0.3727\n",
      "[1256,    10] train_loss: 0.0000 | val_loss: 0.3647\n",
      "[1257,    10] train_loss: 0.0000 | val_loss: 0.3588\n",
      "[1258,    10] train_loss: 0.0000 | val_loss: 0.3492\n",
      "[1259,    10] train_loss: 0.0000 | val_loss: 0.3573\n",
      "[1260,    10] train_loss: 0.0000 | val_loss: 0.3557\n",
      "[1261,    10] train_loss: 0.0000 | val_loss: 0.3569\n",
      "[1262,    10] train_loss: 0.0000 | val_loss: 0.3705\n",
      "[1263,    10] train_loss: 0.0000 | val_loss: 0.3718\n",
      "[1264,    10] train_loss: 0.0000 | val_loss: 0.3932\n",
      "[1265,    10] train_loss: 0.0000 | val_loss: 0.3735\n",
      "[1266,    10] train_loss: 0.0000 | val_loss: 0.3852\n",
      "[1267,    10] train_loss: 0.0079 | val_loss: 0.3942\n",
      "[1268,    10] train_loss: 0.0301 | val_loss: 0.4087\n",
      "[1269,    10] train_loss: 0.0000 | val_loss: 0.3715\n",
      "[1270,    10] train_loss: 0.0109 | val_loss: 0.3915\n",
      "[1271,    10] train_loss: 0.0261 | val_loss: 0.3746\n",
      "[1272,    10] train_loss: 0.0000 | val_loss: 0.3668\n",
      "[1273,    10] train_loss: 0.0391 | val_loss: 0.3192\n",
      "[1274,    10] train_loss: 0.0708 | val_loss: 0.3737\n",
      "[1275,    10] train_loss: 0.0000 | val_loss: 0.3602\n",
      "[1276,    10] train_loss: 0.0561 | val_loss: 0.3577\n",
      "[1277,    10] train_loss: 0.0000 | val_loss: 0.3504\n",
      "[1278,    10] train_loss: 0.0000 | val_loss: 0.3536\n",
      "[1279,    10] train_loss: 0.0194 | val_loss: 0.3527\n",
      "[1280,    10] train_loss: 0.0281 | val_loss: 0.3448\n",
      "[1281,    10] train_loss: 0.0112 | val_loss: 0.3516\n",
      "[1282,    10] train_loss: 0.0115 | val_loss: 0.3839\n",
      "[1283,    10] train_loss: 0.0114 | val_loss: 0.3910\n",
      "[1284,    10] train_loss: 0.0000 | val_loss: 0.3671\n",
      "[1285,    10] train_loss: 0.0000 | val_loss: 0.3626\n",
      "[1286,    10] train_loss: 0.0000 | val_loss: 0.3710\n",
      "[1287,    10] train_loss: 0.0000 | val_loss: 0.4045\n",
      "[1288,    10] train_loss: 0.0000 | val_loss: 0.3563\n",
      "[1289,    10] train_loss: 0.0000 | val_loss: 0.3748\n",
      "[1290,    10] train_loss: 0.0101 | val_loss: 0.3926\n",
      "[1291,    10] train_loss: 0.0000 | val_loss: 0.3583\n",
      "[1292,    10] train_loss: 0.0000 | val_loss: 0.3518\n",
      "[1293,    10] train_loss: 0.0000 | val_loss: 0.3537\n",
      "[1294,    10] train_loss: 0.0000 | val_loss: 0.3440\n",
      "[1295,    10] train_loss: 0.0000 | val_loss: 0.3654\n",
      "[1296,    10] train_loss: 0.0000 | val_loss: 0.3605\n",
      "[1297,    10] train_loss: 0.0228 | val_loss: 0.3713\n",
      "[1298,    10] train_loss: 0.0000 | val_loss: 0.3638\n",
      "[1299,    10] train_loss: 0.0000 | val_loss: 0.3525\n",
      "[1300,    10] train_loss: 0.0000 | val_loss: 0.3466\n",
      "[1301,    10] train_loss: 0.0000 | val_loss: 0.3150\n",
      "Saving checkpoint 1300\n",
      "[1302,    10] train_loss: 0.0516 | val_loss: 0.3504\n",
      "[1303,    10] train_loss: 0.0265 | val_loss: 0.4056\n",
      "[1304,    10] train_loss: 0.0288 | val_loss: 0.3762\n",
      "[1305,    10] train_loss: 0.0113 | val_loss: 0.3821\n",
      "[1306,    10] train_loss: 0.0000 | val_loss: 0.3845\n",
      "[1307,    10] train_loss: 0.0000 | val_loss: 0.3741\n",
      "[1308,    10] train_loss: 0.0234 | val_loss: 0.3874\n",
      "[1309,    10] train_loss: 0.0000 | val_loss: 0.3880\n",
      "[1310,    10] train_loss: 0.0000 | val_loss: 0.3676\n",
      "[1311,    10] train_loss: 0.0000 | val_loss: 0.3910\n",
      "[1312,    10] train_loss: 0.0000 | val_loss: 0.3848\n",
      "[1313,    10] train_loss: 0.0000 | val_loss: 0.3982\n",
      "[1314,    10] train_loss: 0.0000 | val_loss: 0.4032\n",
      "[1315,    10] train_loss: 0.0000 | val_loss: 0.3967\n",
      "[1316,    10] train_loss: 0.0000 | val_loss: 0.3934\n",
      "[1317,    10] train_loss: 0.0000 | val_loss: 0.3771\n",
      "[1318,    10] train_loss: 0.0110 | val_loss: 0.4060\n",
      "[1319,    10] train_loss: 0.0000 | val_loss: 0.4102\n",
      "[1320,    10] train_loss: 0.0000 | val_loss: 0.3883\n",
      "[1321,    10] train_loss: 0.0000 | val_loss: 0.4184\n",
      "[1322,    10] train_loss: 0.0000 | val_loss: 0.3955\n",
      "[1323,    10] train_loss: 0.0000 | val_loss: 0.4025\n",
      "[1324,    10] train_loss: 0.0000 | val_loss: 0.3945\n",
      "[1325,    10] train_loss: 0.0000 | val_loss: 0.3917\n",
      "[1326,    10] train_loss: 0.0283 | val_loss: 0.4282\n",
      "[1327,    10] train_loss: 0.0116 | val_loss: 0.4065\n",
      "[1328,    10] train_loss: 0.0290 | val_loss: 0.4056\n",
      "[1329,    10] train_loss: 0.0269 | val_loss: 0.3882\n",
      "[1330,    10] train_loss: 0.0150 | val_loss: 0.4030\n",
      "[1331,    10] train_loss: 0.0000 | val_loss: 0.3882\n",
      "[1332,    10] train_loss: 0.0261 | val_loss: 0.4053\n",
      "[1333,    10] train_loss: 0.0000 | val_loss: 0.3912\n",
      "[1334,    10] train_loss: 0.0000 | val_loss: 0.3779\n",
      "[1335,    10] train_loss: 0.0106 | val_loss: 0.3778\n",
      "[1336,    10] train_loss: 0.0373 | val_loss: 0.4266\n",
      "[1337,    10] train_loss: 0.0000 | val_loss: 0.4683\n",
      "[1338,    10] train_loss: 0.0455 | val_loss: 0.4222\n",
      "[1339,    10] train_loss: 0.0272 | val_loss: 0.4338\n",
      "[1340,    10] train_loss: 0.0107 | val_loss: 0.4566\n",
      "[1341,    10] train_loss: 0.0000 | val_loss: 0.3906\n",
      "[1342,    10] train_loss: 0.0000 | val_loss: 0.4234\n",
      "[1343,    10] train_loss: 0.0000 | val_loss: 0.4212\n",
      "[1344,    10] train_loss: 0.0266 | val_loss: 0.4215\n",
      "[1345,    10] train_loss: 0.0125 | val_loss: 0.4023\n",
      "[1346,    10] train_loss: 0.0000 | val_loss: 0.3834\n",
      "[1347,    10] train_loss: 0.0264 | val_loss: 0.3673\n",
      "[1348,    10] train_loss: 0.0103 | val_loss: 0.3683\n",
      "[1349,    10] train_loss: 0.0129 | val_loss: 0.3961\n",
      "[1350,    10] train_loss: 0.0140 | val_loss: 0.3914\n",
      "[1351,    10] train_loss: 0.0112 | val_loss: 0.3748\n",
      "Saving checkpoint 1350\n",
      "[1352,    10] train_loss: 0.0000 | val_loss: 0.3715\n",
      "[1353,    10] train_loss: 0.0000 | val_loss: 0.3714\n",
      "[1354,    10] train_loss: 0.0000 | val_loss: 0.3800\n",
      "[1355,    10] train_loss: 0.0000 | val_loss: 0.4039\n",
      "[1356,    10] train_loss: 0.0119 | val_loss: 0.3710\n",
      "[1357,    10] train_loss: 0.0000 | val_loss: 0.3846\n",
      "[1358,    10] train_loss: 0.0295 | val_loss: 0.3900\n",
      "[1359,    10] train_loss: 0.0000 | val_loss: 0.3983\n",
      "[1360,    10] train_loss: 0.0271 | val_loss: 0.3622\n",
      "[1361,    10] train_loss: 0.0000 | val_loss: 0.3509\n",
      "[1362,    10] train_loss: 0.0000 | val_loss: 0.3275\n",
      "[1363,    10] train_loss: 0.0000 | val_loss: 0.3437\n",
      "[1364,    10] train_loss: 0.0121 | val_loss: 0.3348\n",
      "[1365,    10] train_loss: 0.0124 | val_loss: 0.3461\n",
      "[1366,    10] train_loss: 0.0341 | val_loss: 0.3284\n",
      "[1367,    10] train_loss: 0.0000 | val_loss: 0.3822\n",
      "[1368,    10] train_loss: 0.0251 | val_loss: 0.3989\n",
      "[1369,    10] train_loss: 0.0000 | val_loss: 0.3819\n",
      "[1370,    10] train_loss: 0.0801 | val_loss: 0.3509\n",
      "[1371,    10] train_loss: 0.0852 | val_loss: 0.3812\n",
      "[1372,    10] train_loss: 0.0402 | val_loss: 0.4252\n",
      "[1373,    10] train_loss: 0.0110 | val_loss: 0.4732\n",
      "[1374,    10] train_loss: 0.0000 | val_loss: 0.4239\n",
      "[1375,    10] train_loss: 0.0000 | val_loss: 0.4239\n",
      "[1376,    10] train_loss: 0.0000 | val_loss: 0.4270\n",
      "[1377,    10] train_loss: 0.0000 | val_loss: 0.4289\n",
      "[1378,    10] train_loss: 0.0122 | val_loss: 0.4401\n",
      "[1379,    10] train_loss: 0.0000 | val_loss: 0.4164\n",
      "[1380,    10] train_loss: 0.0000 | val_loss: 0.4462\n",
      "[1381,    10] train_loss: 0.0108 | val_loss: 0.4082\n",
      "[1382,    10] train_loss: 0.0000 | val_loss: 0.4228\n",
      "[1383,    10] train_loss: 0.0000 | val_loss: 0.4313\n",
      "[1384,    10] train_loss: 0.0000 | val_loss: 0.4541\n",
      "[1385,    10] train_loss: 0.0000 | val_loss: 0.4382\n",
      "[1386,    10] train_loss: 0.0000 | val_loss: 0.4457\n",
      "[1387,    10] train_loss: 0.0000 | val_loss: 0.4419\n",
      "[1388,    10] train_loss: 0.0000 | val_loss: 0.4075\n",
      "[1389,    10] train_loss: 0.0000 | val_loss: 0.4426\n",
      "[1390,    10] train_loss: 0.0102 | val_loss: 0.4538\n",
      "[1391,    10] train_loss: 0.0000 | val_loss: 0.4688\n",
      "[1392,    10] train_loss: 0.0000 | val_loss: 0.4303\n",
      "[1393,    10] train_loss: 0.0000 | val_loss: 0.4407\n",
      "[1394,    10] train_loss: 0.0000 | val_loss: 0.4649\n",
      "[1395,    10] train_loss: 0.0118 | val_loss: 0.4509\n",
      "[1396,    10] train_loss: 0.0674 | val_loss: 0.4126\n",
      "[1397,    10] train_loss: 0.0226 | val_loss: 0.4221\n",
      "[1398,    10] train_loss: 0.0382 | val_loss: 0.3800\n",
      "[1399,    10] train_loss: 0.0000 | val_loss: 0.3376\n",
      "[1400,    10] train_loss: 0.0300 | val_loss: 0.3637\n",
      "[1401,    10] train_loss: 0.0000 | val_loss: 0.3611\n",
      "Saving checkpoint 1400\n",
      "[1402,    10] train_loss: 0.0247 | val_loss: 0.3477\n",
      "[1403,    10] train_loss: 0.0000 | val_loss: 0.3400\n",
      "[1404,    10] train_loss: 0.0000 | val_loss: 0.3387\n",
      "[1405,    10] train_loss: 0.0000 | val_loss: 0.3411\n",
      "[1406,    10] train_loss: 0.0000 | val_loss: 0.3406\n",
      "[1407,    10] train_loss: 0.0000 | val_loss: 0.3334\n",
      "[1408,    10] train_loss: 0.0142 | val_loss: 0.3595\n",
      "[1409,    10] train_loss: 0.0000 | val_loss: 0.3539\n",
      "[1410,    10] train_loss: 0.0190 | val_loss: 0.3549\n",
      "[1411,    10] train_loss: 0.0791 | val_loss: 0.3384\n",
      "[1412,    10] train_loss: 0.0000 | val_loss: 0.3347\n",
      "[1413,    10] train_loss: 0.0115 | val_loss: 0.3790\n",
      "[1414,    10] train_loss: 0.0000 | val_loss: 0.3629\n",
      "[1415,    10] train_loss: 0.0000 | val_loss: 0.3762\n",
      "[1416,    10] train_loss: 0.0000 | val_loss: 0.3735\n",
      "[1417,    10] train_loss: 0.0000 | val_loss: 0.3651\n",
      "[1418,    10] train_loss: 0.0000 | val_loss: 0.3562\n",
      "[1419,    10] train_loss: 0.0138 | val_loss: 0.3438\n",
      "[1420,    10] train_loss: 0.0000 | val_loss: 0.3465\n",
      "[1421,    10] train_loss: 0.0000 | val_loss: 0.3525\n",
      "[1422,    10] train_loss: 0.0000 | val_loss: 0.3700\n",
      "[1423,    10] train_loss: 0.0127 | val_loss: 0.3717\n",
      "[1424,    10] train_loss: 0.0133 | val_loss: 0.3652\n",
      "[1425,    10] train_loss: 0.0000 | val_loss: 0.3984\n",
      "[1426,    10] train_loss: 0.0089 | val_loss: 0.3506\n",
      "[1427,    10] train_loss: 0.0000 | val_loss: 0.3369\n",
      "[1428,    10] train_loss: 0.0091 | val_loss: 0.3686\n",
      "[1429,    10] train_loss: 0.0507 | val_loss: 0.3388\n",
      "[1430,    10] train_loss: 0.0514 | val_loss: 0.3405\n",
      "[1431,    10] train_loss: 0.0000 | val_loss: 0.3961\n",
      "[1432,    10] train_loss: 0.0252 | val_loss: 0.4113\n",
      "[1433,    10] train_loss: 0.0275 | val_loss: 0.3674\n",
      "[1434,    10] train_loss: 0.0294 | val_loss: 0.3497\n",
      "[1435,    10] train_loss: 0.0519 | val_loss: 0.3805\n",
      "[1436,    10] train_loss: 0.0303 | val_loss: 0.3648\n",
      "[1437,    10] train_loss: 0.0112 | val_loss: 0.3912\n",
      "[1438,    10] train_loss: 0.0000 | val_loss: 0.4003\n",
      "[1439,    10] train_loss: 0.0229 | val_loss: 0.4012\n",
      "[1440,    10] train_loss: 0.0000 | val_loss: 0.3899\n",
      "[1441,    10] train_loss: 0.0000 | val_loss: 0.4097\n",
      "[1442,    10] train_loss: 0.0000 | val_loss: 0.3911\n",
      "[1443,    10] train_loss: 0.0000 | val_loss: 0.3872\n",
      "[1444,    10] train_loss: 0.0104 | val_loss: 0.3910\n",
      "[1445,    10] train_loss: 0.0103 | val_loss: 0.3816\n",
      "[1446,    10] train_loss: 0.0000 | val_loss: 0.4043\n",
      "[1447,    10] train_loss: 0.0000 | val_loss: 0.3940\n",
      "[1448,    10] train_loss: 0.0000 | val_loss: 0.4146\n",
      "[1449,    10] train_loss: 0.0000 | val_loss: 0.3811\n",
      "[1450,    10] train_loss: 0.0104 | val_loss: 0.3668\n",
      "[1451,    10] train_loss: 0.0316 | val_loss: 0.3501\n",
      "Saving checkpoint 1450\n",
      "[1452,    10] train_loss: 0.0000 | val_loss: 0.3617\n",
      "[1453,    10] train_loss: 0.0000 | val_loss: 0.3395\n",
      "[1454,    10] train_loss: 0.0093 | val_loss: 0.3311\n",
      "[1455,    10] train_loss: 0.0123 | val_loss: 0.3252\n",
      "[1456,    10] train_loss: 0.0864 | val_loss: 0.3546\n",
      "[1457,    10] train_loss: 0.0231 | val_loss: 0.3674\n",
      "[1458,    10] train_loss: 0.0317 | val_loss: 0.3953\n",
      "[1459,    10] train_loss: 0.0000 | val_loss: 0.4204\n",
      "[1460,    10] train_loss: 0.0000 | val_loss: 0.3831\n",
      "[1461,    10] train_loss: 0.0000 | val_loss: 0.4239\n",
      "[1462,    10] train_loss: 0.0000 | val_loss: 0.3764\n",
      "[1463,    10] train_loss: 0.0107 | val_loss: 0.3644\n",
      "[1464,    10] train_loss: 0.0000 | val_loss: 0.3767\n",
      "[1465,    10] train_loss: 0.0000 | val_loss: 0.3792\n",
      "[1466,    10] train_loss: 0.0000 | val_loss: 0.3779\n",
      "[1467,    10] train_loss: 0.0000 | val_loss: 0.3598\n",
      "[1468,    10] train_loss: 0.0000 | val_loss: 0.3713\n",
      "[1469,    10] train_loss: 0.0000 | val_loss: 0.3472\n",
      "[1470,    10] train_loss: 0.0105 | val_loss: 0.3627\n",
      "[1471,    10] train_loss: 0.0102 | val_loss: 0.3560\n",
      "[1472,    10] train_loss: 0.0000 | val_loss: 0.3817\n",
      "[1473,    10] train_loss: 0.0118 | val_loss: 0.3784\n",
      "[1474,    10] train_loss: 0.0152 | val_loss: 0.3759\n",
      "[1475,    10] train_loss: 0.0000 | val_loss: 0.3699\n",
      "[1476,    10] train_loss: 0.0000 | val_loss: 0.3557\n",
      "[1477,    10] train_loss: 0.0000 | val_loss: 0.3602\n",
      "[1478,    10] train_loss: 0.0000 | val_loss: 0.3570\n",
      "[1479,    10] train_loss: 0.0000 | val_loss: 0.3807\n",
      "[1480,    10] train_loss: 0.0329 | val_loss: 0.3680\n",
      "[1481,    10] train_loss: 0.0101 | val_loss: 0.3706\n",
      "[1482,    10] train_loss: 0.0000 | val_loss: 0.3300\n",
      "[1483,    10] train_loss: 0.0000 | val_loss: 0.3051\n",
      "[1484,    10] train_loss: 0.0000 | val_loss: 0.3292\n",
      "[1485,    10] train_loss: 0.0244 | val_loss: 0.3531\n",
      "[1486,    10] train_loss: 0.0154 | val_loss: 0.3890\n",
      "[1487,    10] train_loss: 0.0000 | val_loss: 0.4164\n",
      "[1488,    10] train_loss: 0.0125 | val_loss: 0.4063\n",
      "[1489,    10] train_loss: 0.0000 | val_loss: 0.3958\n",
      "[1490,    10] train_loss: 0.0000 | val_loss: 0.4124\n",
      "[1491,    10] train_loss: 0.0000 | val_loss: 0.3886\n",
      "[1492,    10] train_loss: 0.0000 | val_loss: 0.4005\n",
      "[1493,    10] train_loss: 0.0000 | val_loss: 0.4051\n",
      "[1494,    10] train_loss: 0.0000 | val_loss: 0.4106\n",
      "[1495,    10] train_loss: 0.0000 | val_loss: 0.4066\n",
      "[1496,    10] train_loss: 0.0000 | val_loss: 0.3672\n",
      "[1497,    10] train_loss: 0.0118 | val_loss: 0.3557\n",
      "[1498,    10] train_loss: 0.0000 | val_loss: 0.3707\n",
      "[1499,    10] train_loss: 0.0000 | val_loss: 0.3716\n",
      "[1500,    10] train_loss: 0.0102 | val_loss: 0.3708\n",
      "Total train time: 319.3416044751803min\n",
      "Evaluating model...\n",
      "Reference (or Train) Loss: 0.3091\n",
      "Reference size: (126, 128)\n",
      "Test (or Query) Loss: 0.0286\n",
      "Test (or Query) size: (9530, 128)\n",
      "Training kNN classifier with k=1\n",
      "1NN test accuracy: 0.3391\n",
      "Training kNN classifier with k=3\n",
      "3NN test accuracy: 0.2838\n",
      "\n",
      "Per label 3NN test accuracy:\n",
      "0\t0.31\n",
      "1\t0.62\n",
      "2\t0.75\n",
      "3\t0.46\n",
      "4\t0.50\n",
      "5\t0.32\n",
      "6\t0.15\n",
      "7\t0.42\n",
      "8\t0.71\n",
      "9\t0.45\n",
      "10\t1.00\n",
      "11\t0.32\n",
      "12\t0.80\n",
      "13\t0.27\n",
      "14\t0.00\n",
      "15\t0.33\n",
      "16\t0.33\n",
      "17\t0.23\n",
      "18\t0.22\n",
      "19\t0.00\n",
      "20\t0.28\n",
      "21\t0.50\n",
      "22\t0.00\n",
      "23\t0.01\n",
      "24\t0.40\n",
      "25\t0.00\n",
      "26\t0.15\n",
      "27\t0.00\n",
      "28\t0.26\n",
      "29\t0.14\n",
      "30\t0.12\n",
      "31\t0.00\n",
      "32\t0.56\n",
      "33\t0.29\n",
      "34\t0.10\n",
      "35\t0.34\n",
      "36\t0.74\n",
      "37\t0.00\n",
      "38\t0.64\n",
      "39\t0.09\n",
      "40\t0.11\n",
      "41\t0.17\n",
      "42\t0.00\n",
      "43\t0.01\n",
      "44\t0.77\n",
      "45\t0.00\n",
      "46\t0.32\n",
      "47\t0.04\n",
      "48\t0.00\n",
      "49\t0.50\n",
      "50\t0.00\n",
      "51\t0.12\n",
      "52\t0.19\n",
      "53\t0.00\n",
      "54\t0.00\n",
      "55\t0.52\n",
      "56\t0.99\n",
      "57\t0.39\n",
      "58\t0.04\n",
      "59\t0.47\n",
      "61\t0.06\n",
      "62\t0.00\n",
      "63\t0.10\n",
      "\n",
      "Printing Confusion Matrix:\n",
      "[[ 26   1   7 ...   0   0   1]\n",
      " [  3  75   0 ...   0   0   0]\n",
      " [  2   0 157 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   7   0   0]\n",
      " [ 52   3   3 ...   0   0   4]\n",
      " [  9   6   0 ...   0   0  25]]\n",
      "{'1NN_acc': 0.3391, '3NN_acc': 0.2838, 'label_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63]), 'knn_class': array([0.3095, 0.625 , 0.7548, 0.4557, 0.5048, 0.3161, 0.1502, 0.4202,\n",
      "       0.7133, 0.445 , 1.    , 0.3153, 0.8049, 0.2667, 0.    , 0.3344,\n",
      "       0.3333, 0.2333, 0.2206, 0.    , 0.2836, 0.5047, 0.    , 0.0149,\n",
      "       0.3957, 0.    , 0.1477, 0.    , 0.2579, 0.1398, 0.1231, 0.    ,\n",
      "       0.5644, 0.2871, 0.1042, 0.3419, 0.7361, 0.    , 0.6396, 0.0884,\n",
      "       0.1068, 0.1667, 0.    , 0.0119, 0.7692, 0.    , 0.3176, 0.0396,\n",
      "       0.    , 0.5   , 0.    , 0.1242, 0.1946, 0.    , 0.    , 0.5244,\n",
      "       0.9888, 0.3946, 0.0385, 0.4706, 0.0648, 0.    , 0.102 ]), 'knn_conf': array([[ 26,   1,   7, ...,   0,   0,   1],\n",
      "       [  3,  75,   0, ...,   0,   0,   0],\n",
      "       [  2,   0, 157, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  0,   0,   0, ...,   7,   0,   0],\n",
      "       [ 52,   3,   3, ...,   0,   0,   4],\n",
      "       [  9,   6,   0, ...,   0,   0,  25]]), 'train_loss': 0.0}\n",
      "Saving model...\n",
      "Finished\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid loss ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 1499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid loss 0.37082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfresh-shadow-29\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/closed_sets_8_ids_double_color_batch2/runs/mhd81vuy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./8_ids_double_colors_batch2_sample_num_max/wandb/run-20231020_112239-mhd81vuy/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "epochs_to_test = [1500,2000]\n",
    "for n in epochs_to_test: \n",
    "    for i in range(len(files)):\n",
    "        #train file path\n",
    "        train_file = root+r'/'+files[i]\n",
    "        wandb_name = os.path.basename(root)\n",
    "        # initilize and make new dir for run\n",
    "        #run_num = '0'+str(i) #I've decided this makes it harder\n",
    "        run_str = os.path.basename(files[i])[36:-4]\n",
    "        run_dir_name = run_str+'/'\n",
    "        if not os.path.exists(run_dir_name):\n",
    "            os.mkdir(run_dir_name)\n",
    "\n",
    "        split_parts = run_str.rsplit('_', 1)\n",
    "        # Check if there is at least one underscore in the string\n",
    "        if len(split_parts) > 1:\n",
    "            # Get the substring after the last underscore\n",
    "            num_images = split_parts[1]\n",
    "            num_ids = split_parts[-1]\n",
    "        else:\n",
    "            # Handle the case where there are no underscores in the string\n",
    "            num_images = run_str\n",
    "\n",
    "        \n",
    "        ##---------- Initilize new config .yml for new training file---------------\n",
    "\n",
    "        #open config yaml to update experiment params\n",
    "        with open('/home/lmeyers/ReID_complete/reid_template.yml', 'r') as fo:\n",
    "            config = yaml.safe_load(fo)\n",
    "        \n",
    "        #Update params\n",
    "        config['model_settings']['num_labels']= run_str[0]\n",
    "        print('Num labels ',run_str[0])\n",
    "\n",
    "        #Check if batch size needs to be updated\n",
    "        df = pd.read_csv(train_file)\n",
    "        if config['data_settings']['batch_size'] > len(df):\n",
    "            config['data_settings']['batch_size'] = len(df)\n",
    "            print('Updated batch to contain all Data. Size = ',len(df))\n",
    "        \n",
    "        #Testing a differnt num epochs\n",
    "        config['train_settings']['num_epochs'] = n\n",
    "\n",
    "        #Set GPU num for parralel training\n",
    "        config['train_settings']['gpu'] = 0 \n",
    "\n",
    "        #updating datafiles\n",
    "        config['data_settings']['datafiles']['train']=train_file\n",
    "        config['data_settings']['datafiles']['reference']= reference_file\n",
    "\n",
    "\n",
    "        #config['data_settings']['datafiles']['train']=train_csv\n",
    "        config['data_settings']['datafiles']['test'] = test_file\n",
    "        config['data_settings']['datafiles']['valid']= valid_file \n",
    "        config['data_settings']['datafiles']['query']= test_file\n",
    "\n",
    "        #update Model path\n",
    "        config['model_settings']['model_path'] = './'+run_dir_name+run_str+'.pth'\n",
    "\n",
    "        #update wandb_project_name\n",
    "        config['train_settings']['wandb_project_name'] = wandb_name\n",
    "        config['train_settings']['wandb_dir_path'] = '/home/lmeyers/ReID_complete/few_shot_experiments/'+ run_dir_name #this should make a seperate wandb folder for runs\n",
    "\n",
    "        #save yml\n",
    "        new_yml_file = './'+run_dir_name+run_str+'.yml'\n",
    "        with open(new_yml_file, 'w') as fo:\n",
    "                yaml.dump(config,fo)   \n",
    "\n",
    "        #---------- actually run training too--------------\n",
    "        !python /home/lmeyers/ReID_complete/pytorch_train_and_eval_reid.py --config_file {new_yml_file}\n",
    "\n",
    "        with open('/home/lmeyers/ReID_complete/results.pkl','rb') as fi:\n",
    "            results = pickle.load(fi)  \n",
    "        \n",
    "        # Write out run summary to results tracking document\n",
    "        results_df = pd.read_csv(config['eval_settings']['results_file'])\n",
    "        results_df.loc[len(results_df)] = {'run_str': run_str,'num_ids':num_ids,'num_images_per_id':num_images,'total_training_images':len(pd.read_csv(train_file)),'num_epochs':config['train_settings']['num_epochs'],'train_loss':results['train_loss'],'1NN':results['1NN_acc'],'3NN':results['3NN_acc'],'training_file':train_file,'reference_file':reference_file,'query_file':test_file}\n",
    "        results_df.to_csv(config['eval_settings']['results_file'],index=False)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3c3300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed_sets_max_ids_batch1\n",
      "closed_sets_max_ids_batch2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# here we can specify what we want to train. If we want everything, remove max, it should work\n",
    "directory = '/home/gsantiago/summer_bee_data/closed_sets_max*'\n",
    "closed_set_directory = '/home/gsantiago/summer_bee_data/closed_test_'\n",
    "closed_test = \"/home/gsantiago/summer_bee_data/closed_test_\"\n",
    "\n",
    "model_path = '/home/gsantiago/ReID_model_training/model_path/'\n",
    "for path in glob(directory):\n",
    "    \n",
    "    \n",
    "    batch_number = path.split('_')[-1]\n",
    "    \n",
    "    all_csv_directories = path+'/*'\n",
    "    full_dir_name = path.split('/')[-1]\n",
    "#     print(full_dir_name)\n",
    "#     continue\n",
    "    type_of_split = full_dir_name.replace('closed_sets', '').replace(batch_number,'')\n",
    "    #open_set_for_test = open_sets+\"open\"+type_of_split\n",
    "\n",
    "    #print(batch_number)\n",
    "    \n",
    "    closed_for_this_test= closed_test+  batch_number+'/*'\n",
    "    \n",
    "#     if(batch_number == 'batch1'):\n",
    "        \n",
    "#         #open_set_for_test = open_set_for_test+'batch2/'+\"summer_bee_dataset_open_train_bee_balanced_batch2_sample_num_max.csv\"\n",
    "#     else:\n",
    "#         #open_set_for_test = open_set_for_test+'batch1/'+\"summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv\"\n",
    "        \n",
    "#     print(open_set_for_test)\n",
    "    \n",
    "    with open('./pytorch_train_and_eval_reid.yml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    for train_csv in glob(all_csv_directories):\n",
    "        #print('train_csv')\n",
    "        #print(train_csv)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #changing train folder\n",
    "#         print(closed_for_this_test)\n",
    "#         print(glob(closed_for_this_test))\n",
    "        train_df = pd.read_csv(train_csv)\n",
    "        num_labels = train_df['ID'].nunique()\n",
    "        #print(num_labels)\n",
    "        \n",
    "        #batch setting\n",
    "        config['data_settings']['batch_size']= 64\n",
    "        \n",
    "        #updating labels\n",
    "        \n",
    "        config['model_settings']['num_labels']=num_labels\n",
    "        \n",
    "        #updating datafiles\n",
    "        config['data_settings']['datafiles']['train']=train_csv\n",
    "        config['data_settings']['datafiles']['reference']= train_csv\n",
    "  \n",
    "\n",
    "        #config['data_settings']['datafiles']['train']=train_csv\n",
    "        config['data_settings']['datafiles']['test'] = glob(closed_for_this_test)[0]\n",
    "        config['data_settings']['datafiles']['valid']= glob(closed_for_this_test)[0]\n",
    "        config['data_settings']['datafiles']['query']= glob(closed_for_this_test)[0]\n",
    "        \n",
    "        model_directory =(model_path+\"closed/\"+full_dir_name+'/')\n",
    "        \n",
    "        if not os.path.exists(model_directory):\n",
    "            os.makedirs(model_directory)\n",
    "        config['model_settings']['model_path']= model_directory\n",
    "        \n",
    "        config_name = train_csv.split('/')[-1].replace('.csv', '')\n",
    "        print(config['data_settings']['datafiles'])\n",
    "\n",
    "        new_yml_file = \"./different_yml_configs/closed/\"+config_name+'_config.yml'\n",
    "        output_file = \"./all_outputs/\"+(new_yml_file.split('/')[-1].replace('_config.yml', '_output.txt'))\n",
    "       \n",
    "        with open(new_yml_file, 'w') as f:\n",
    "            yaml.dump(config,f)\n",
    "        \n",
    "        !python pytorch_train_and_eval_reid.py --config_file {new_yml_file} > {output_file} \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f014d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d2bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13c236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c1bc2ca",
   "metadata": {},
   "source": [
    "# open set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_csv\n",
      "64\n",
      "2023-10-15 22:44:31.603382: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-15 22:44:32.942356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriel-santiago21\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/gsantiago/ReID_model_training/wandb/run-20231015_224436-pfstr74p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdaily-plant-25\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open/runs/pfstr74p\u001b[0m\n",
      "/home/gsantiago/ReID_model_training/pytorch_train_and_eval_reid.py:77: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  knn_class[k] = np.round(np.sum(knn_pred[mask]==test_labels[mask])/np.sum(mask),4)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.005 MB of 0.012 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.14135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdaily-plant-25\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open/runs/pfstr74p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231015_224436-pfstr74p/logs\u001b[0m\n",
      "train_csv\n",
      "64\n",
      "2023-10-15 23:53:43.592262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-15 23:53:45.135061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriel-santiago21\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/gsantiago/ReID_model_training/wandb/run-20231015_235349-b64kuzyj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mefficient-voice-26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open/runs/b64kuzyj\u001b[0m\n",
      "/home/gsantiago/ReID_model_training/pytorch_train_and_eval_reid.py:77: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  knn_class[k] = np.round(np.sum(knn_pred[mask]==test_labels[mask])/np.sum(mask),4)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train loss 0.16833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mefficient-voice-26\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open/runs/b64kuzyj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231015_235349-b64kuzyj/logs\u001b[0m\n",
      "train_csv\n",
      "64\n",
      "2023-10-16 00:45:50.898888: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-16 00:45:52.091201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriel-santiago21\u001b[0m (\u001b[33mmeyers_luke_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/gsantiago/ReID_model_training/wandb/run-20231016_004555-9myro3ut\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-voice-27\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/meyers_luke_lab/ReID_Full_dataset_open/runs/9myro3ut\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# here we can specify what we want to train. If we want everything, remove max, it should work\n",
    "directory = '/home/gsantiago/summer_bee_data/open_sets/open_max*'\n",
    "open_set_directory = '/home/gsantiago/summer_bee_data/open_sets/'\n",
    "open_test = \"/home/gsantiago/summer_bee_data/open_sets/\"\n",
    "\n",
    "model_path = '/home/gsantiago/ReID_model_training/model_path/'\n",
    "for path in glob(directory):\n",
    "    \n",
    "    #print(path)\n",
    "    batch_number = path.split('_')[-1]\n",
    "    #print(batch_number)\n",
    "    \n",
    "    all_csv_directories = path+'/*'\n",
    "    #print(glob(all_csv_directories))\n",
    "    full_dir_name = path.split('/')[-1]\n",
    "    #print(full_dir_name)\n",
    "    type_of_split = full_dir_name.replace(batch_number,'')\n",
    "    #print(\"type_of_split\")\n",
    "    #print(type_of_split)\n",
    "   \n",
    "\n",
    "    #print(batch_number)\n",
    "    \n",
    "    #open_for_this_test= open_test+  batch_number+'/*'\n",
    "    \n",
    "    if(batch_number == 'batch1'):\n",
    "        \n",
    "        open_set_for_test = open_test+type_of_split+'batch2/'+\"summer_bee_dataset_open_train_bee_balanced_batch2_sample_num_max.csv\"\n",
    "        \n",
    "    else:\n",
    "        open_set_for_test = open_test+type_of_split+'batch1/'+\"summer_bee_dataset_open_train_bee_balanced_batch1_sample_num_max.csv\"\n",
    "        \n",
    "    #print(open_set_for_test)\n",
    "    \n",
    "    with open('./pytorch_train_and_eval_reid.yml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    #print(glob(all_csv_directories))\n",
    "    for train_csv in glob(all_csv_directories):\n",
    "        print('train_csv')\n",
    "        #print(train_csv)\n",
    "\n",
    "\n",
    "        # optional, skipping  the finished cvs\n",
    "        \n",
    "        #changing train folder\n",
    "        #print(\"open_set_for_test\")\n",
    "        #print(open_set_for_test)\n",
    "        #print(glob(open_set_for_test))\n",
    "        train_df = pd.read_csv(train_csv)\n",
    "        num_labels = train_df['ID'].nunique()\n",
    "        print(num_labels)\n",
    "        \n",
    "        #batch setting\n",
    "        config['data_settings']['batch_size']= 64\n",
    "        \n",
    "        #updating labels\n",
    "        \n",
    "        config['model_settings']['num_labels']=num_labels\n",
    "        \n",
    "        #updating datafiles\n",
    "        config['data_settings']['datafiles']['train']=train_csv\n",
    "        config['data_settings']['datafiles']['test'] = open_set_for_test\n",
    "        config['data_settings']['datafiles']['valid']= open_set_for_test\n",
    "        config['data_settings']['datafiles']['reference']= train_csv\n",
    "        config['data_settings']['datafiles']['query']= open_set_for_test\n",
    "        \n",
    "        \n",
    "                \n",
    "        model_directory =(model_path+\"open/\"+full_dir_name+'/')\n",
    "        train_model_directory = model_directory+'train/'\n",
    "        eval_model_directory = model_directory +'eval/'\n",
    "        \n",
    "        if not os.path.exists(model_directory):\n",
    "            os.makedirs(model_directory)\n",
    "            os.makedirs(train_model_directory)\n",
    "            os.makedirs(eval_model_directory)\n",
    "            \n",
    "        #sample size for model, saved as name\n",
    "        \n",
    "        sample_num = train_csv.split('_')[-1].replace(\".csv\",'_samples.pth')\n",
    "            \n",
    "        config['model_settings']['model_path']= train_model_directory+sample_num\n",
    "        config['eval_settings']['model_path'] = eval_model_directory +sample_num\n",
    "        \n",
    "\n",
    "        \n",
    "        config_name = train_csv.split('/')[-1].replace('.csv', '')\n",
    "        #print(config['data_settings']['datafiles'])\n",
    "\n",
    "        new_yml_file = \"./different_yml_configs/open/\"+config_name+'_config.yml'\n",
    "        output_file = \"./all_outputs/\"+(new_yml_file.split('/')[-1].replace('_config.yml', '_output.txt'))\n",
    "       \n",
    "        with open(new_yml_file, 'w') as f:\n",
    "            yaml.dump(config,f)\n",
    "        \n",
    "        !python pytorch_train_and_eval_reid.py --config_file {new_yml_file} > {output_file} \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ec5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
